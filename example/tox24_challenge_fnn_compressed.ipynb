{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Tox 24 challenge - see how deepFPlearn performs\n",
    "\n",
    "We are doing the following steps\n",
    "- load challenge data: training and test datasets\n",
    "- remove duplicated SMILES with different target values\n",
    "- scale the target value to the range [0, 1]\n",
    "- use the whole set of SMILES (test and train substances), generate 2048 bit binary molecular fingerprints, train a specific autoencoder for compressing 2048 bit binary molecular fingerprints into 256 bit vectors with less zeros\n",
    "- use the trained specific autoencoder to encode the 2048 bit fingerprints of the training substances\n",
    "- train a regression model with this data \n",
    "- use the trained autoencoder to encode the test substances, use the regression model to predict the scaled target values\n",
    "- reverse the scaling of the target values\n",
    "- submit the predictions"
   ],
   "id": "f39d8e00d450f205"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Train the autoencoder\n",
    "\n",
    "For this load train and test datasets first to get the full set of molecular structures. Store all structures again in a .csv file."
   ],
   "id": "f468abce82a41b0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T07:43:23.899811Z",
     "start_time": "2024-08-08T07:43:23.749563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.concat([pd.read_csv('data/tox24_challenge_train.csv'),\n",
    "           pd.read_csv('data/tox24_challenge_test.csv')],\n",
    "          ignore_index=True).to_csv('data/tox24_challenge_smiles_all.csv', index=False)"
   ],
   "id": "488cc2fdb31b71b5",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Adjust all options for training the autoencoder",
   "id": "e1f61e746f7bd1c6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T08:16:06.760381Z",
     "start_time": "2024-08-08T08:16:06.753340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dfpl import options\n",
    "\n",
    "opts = options.Options(\n",
    "    inputFile='data/tox24_challenge_smiles_all.csv',\n",
    "    outputDir='data/output/',\n",
    "    ecModelDir='data/output/AE_encoder/',\n",
    "    ecWeightsFile='',\n",
    "    type='smiles',\n",
    "    fpType='topological',\n",
    "    fpSize=2048,\n",
    "    encFPSize=256,\n",
    "    verbose=2,\n",
    "    trainAC=True,\n",
    "    aeActivationFunction='tanh',\n",
    "    aeEpochs=3000,\n",
    "    aeBatchSize=52,\n",
    "    aeLearningRate=0.004123771070856377,\n",
    "    aeLearningRateDecay=0.05465859583974732,\n",
    "    trainFNN=False,\n",
    "    wabTracking=True,\n",
    ")\n"
   ],
   "id": "830f69a695117692",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Allow tracking the training in Weights & Biases.\n",
    "\n",
    "This requires a Weights & Biases account and at least the free plan. Feel free to comment this code cell."
   ],
   "id": "b8f05091d7d36b4d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T08:16:16.445708Z",
     "start_time": "2024-08-08T08:16:12.470752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "\n",
    "if opts.wabTracking:\n",
    "    wandb.init(project=f\"tox_24\",\n",
    "               entity=\"dfpl_regression\",\n",
    "               config=vars(opts))"
   ],
   "id": "321e393564597d7f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mmai00fti\u001B[0m (\u001B[33mdfpl_regression\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.17.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/hertelj/git-hertelj/deepFPlearn/example/wandb/run-20240808_101613-817oeo01</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dfpl_regression/tox_24/runs/817oeo01' target=\"_blank\">fluent-lake-2</a></strong> to <a href='https://wandb.ai/dfpl_regression/tox_24' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/dfpl_regression/tox_24' target=\"_blank\">https://wandb.ai/dfpl_regression/tox_24</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/dfpl_regression/tox_24/runs/817oeo01' target=\"_blank\">https://wandb.ai/dfpl_regression/tox_24/runs/817oeo01</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load the training data and generate fingerprints.",
   "id": "b473706eafb7d90f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T08:16:27.950509Z",
     "start_time": "2024-08-08T08:16:27.677496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dfpl import fingerprint as fp\n",
    "\n",
    "df = fp.importDataFile(opts.inputFile, import_function=fp.importCSV, fp_size=opts.fpSize)"
   ],
   "id": "3b4d4ab290c67aff",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Train the autoencoder",
   "id": "51e594de4eb47fe6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T08:17:30.665054Z",
     "start_time": "2024-08-08T08:17:30.317694Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dfpl import utils\n",
    "\n",
    "utils.createDirectory(opts.outputDir)\n",
    "\n",
    "from dfpl import autoencoder as ac\n",
    "# opts.trainAC=False\n",
    "if opts.trainAC:\n",
    "    # train an autoencoder on the full feature matrix\n",
    "    encoder = ac.train_full_ac(df, opts)"
   ],
   "id": "3433c8f1b647d6f6",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Update the options for training the regression model with compressed features.",
   "id": "efe4e9f05a9cb933"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T08:19:26.538207Z",
     "start_time": "2024-08-08T08:19:26.533084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "opts = options.Options(\n",
    "    inputFile='data/tox24_challenge_train.csv',\n",
    "    outputDir='data/output/',\n",
    "    ecModelDir='data/output/AE_encoder/',\n",
    "    ecWeightsFile='',\n",
    "    type='smiles',\n",
    "    fpType='topological',\n",
    "    fpSize=2048,\n",
    "    encFPSize=256,\n",
    "    verbose=2,\n",
    "    trainFNN=True,\n",
    "    compressFeatures=True,\n",
    "    kFolds=5,\n",
    "    testSize=0.2,\n",
    "    optimizer=\"SGD\",\n",
    "    lossFunction=\"mse\",\n",
    "    epochs=5000,\n",
    "    batchSize=56,\n",
    "    activationFunction=\"tanh\",\n",
    "    dropout=0.15657883016344468,\n",
    "    learningRate=0.017935022040821466,\n",
    "    l2reg=0.009308121424156192,\n",
    "    fnnType=\"REG\",\n",
    "    enableMultiLabel=False,\n",
    "    wabTarget=\"activity\",\n",
    ")\n"
   ],
   "id": "1e8b262fc474dfca",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T08:19:30.947452Z",
     "start_time": "2024-08-08T08:19:30.410082Z"
    }
   },
   "cell_type": "code",
   "source": "df = fp.importDataFile(opts.inputFile, import_function=fp.importCSV, fp_size=opts.fpSize)",
   "id": "da3b909acb03f733",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T08:19:33.166906Z",
     "start_time": "2024-08-08T08:19:32.962406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "if opts.compressFeatures:\n",
    "    # load trained model for autoencoder\n",
    "    encoder = keras.models.load_model(opts.ecModelDir)\n",
    "\n",
    "    # compress the fingerprints using the autoencoder\n",
    "    df = ac.compress_fingerprints(df, encoder)"
   ],
   "id": "b132021657300b35",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 821us/step\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Scale the target values to [0,1]",
   "id": "b7b1d0964575ca82"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T08:19:36.008727Z",
     "start_time": "2024-08-08T08:19:36.001818Z"
    }
   },
   "cell_type": "code",
   "source": "df.columns",
   "id": "b42ef4c461b0e3e1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SMILES', 'activity', 'fp', 'fpcompressed'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T08:19:39.184037Z",
     "start_time": "2024-08-08T08:19:39.175984Z"
    }
   },
   "cell_type": "code",
   "source": [
    "unscaled_target = df['activity'].to_numpy().reshape(-1,1)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(unscaled_target)\n",
    "scaled_target = scaler.transform(unscaled_target)\n",
    "df = df.drop('activity', axis=1)\n",
    "df = pd.concat([df, pd.DataFrame(scaled_target, columns=['activity'])], axis=1)"
   ],
   "id": "4056aed7e8294160",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now train the regression model",
   "id": "ddc875717f5798bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T08:19:50.860027Z",
     "start_time": "2024-08-08T08:19:50.853376Z"
    }
   },
   "cell_type": "code",
   "source": "opts.inputFile",
   "id": "83885dd3791332c8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/tox24_challenge_train.csv'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T08:20:31.350257Z",
     "start_time": "2024-08-08T08:20:00.333016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dfpl import single_label_model as sl\n",
    "\n",
    "if opts.trainFNN:\n",
    "    sl.train_single_label_models(df=df, opts=opts)"
   ],
   "id": "6da9acabdf2079d0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hertelj/build/local/miniforge3/envs/dfpl/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "15/15 - 0s - loss: 4.7379 - rmse: 0.8089 - mse: 0.6544 - mae: 0.6171 - val_loss: 4.1314 - val_rmse: 0.4196 - val_mse: 0.1761 - val_mae: 0.3554 - 489ms/epoch - 33ms/step\n",
      "Epoch 2/5000\n",
      "15/15 - 0s - loss: 3.9217 - rmse: 0.3363 - mse: 0.1131 - mae: 0.2753 - val_loss: 3.6763 - val_rmse: 0.2385 - val_mse: 0.0569 - val_mae: 0.1968 - 39ms/epoch - 3ms/step\n",
      "Epoch 3/5000\n",
      "15/15 - 0s - loss: 3.5263 - rmse: 0.2512 - mse: 0.0631 - mae: 0.2038 - val_loss: 3.3366 - val_rmse: 0.2491 - val_mse: 0.0621 - val_mae: 0.1901 - 41ms/epoch - 3ms/step\n",
      "Epoch 4/5000\n",
      "15/15 - 0s - loss: 3.1784 - rmse: 0.2236 - mse: 0.0500 - mae: 0.1846 - val_loss: 3.0031 - val_rmse: 0.2203 - val_mse: 0.0485 - val_mae: 0.1848 - 52ms/epoch - 3ms/step\n",
      "Epoch 5/5000\n",
      "15/15 - 0s - loss: 2.8651 - rmse: 0.2080 - mse: 0.0433 - mae: 0.1751 - val_loss: 2.7125 - val_rmse: 0.2195 - val_mse: 0.0482 - val_mae: 0.1834 - 38ms/epoch - 3ms/step\n",
      "Epoch 6/5000\n",
      "15/15 - 0s - loss: 2.5859 - rmse: 0.2038 - mse: 0.0415 - mae: 0.1710 - val_loss: 2.4502 - val_rmse: 0.2191 - val_mse: 0.0480 - val_mae: 0.1789 - 36ms/epoch - 2ms/step\n",
      "Epoch 7/5000\n",
      "15/15 - 0s - loss: 2.3333 - rmse: 0.1980 - mse: 0.0392 - mae: 0.1626 - val_loss: 2.2134 - val_rmse: 0.2181 - val_mse: 0.0476 - val_mae: 0.1790 - 37ms/epoch - 2ms/step\n",
      "Epoch 8/5000\n",
      "15/15 - 0s - loss: 2.1060 - rmse: 0.1938 - mse: 0.0376 - mae: 0.1613 - val_loss: 1.9995 - val_rmse: 0.2159 - val_mse: 0.0466 - val_mae: 0.1793 - 38ms/epoch - 3ms/step\n",
      "Epoch 9/5000\n",
      "15/15 - 0s - loss: 1.9012 - rmse: 0.1901 - mse: 0.0362 - mae: 0.1561 - val_loss: 1.8074 - val_rmse: 0.2155 - val_mse: 0.0464 - val_mae: 0.1796 - 40ms/epoch - 3ms/step\n",
      "Epoch 10/5000\n",
      "\n",
      "Epoch 10: val_loss improved from inf to 1.63537, saving model to data/output/activity_single-labeled_Fold-1.model.weights.hdf5\n",
      "15/15 - 0s - loss: 1.7178 - rmse: 0.1898 - mse: 0.0360 - mae: 0.1563 - val_loss: 1.6354 - val_rmse: 0.2180 - val_mse: 0.0475 - val_mae: 0.1762 - 47ms/epoch - 3ms/step\n",
      "Epoch 11/5000\n",
      "15/15 - 0s - loss: 1.5513 - rmse: 0.1864 - mse: 0.0347 - mae: 0.1533 - val_loss: 1.4783 - val_rmse: 0.2154 - val_mse: 0.0464 - val_mae: 0.1749 - 41ms/epoch - 3ms/step\n",
      "Epoch 12/5000\n",
      "15/15 - 0s - loss: 1.4028 - rmse: 0.1875 - mse: 0.0352 - mae: 0.1532 - val_loss: 1.3380 - val_rmse: 0.2159 - val_mse: 0.0466 - val_mae: 0.1771 - 53ms/epoch - 4ms/step\n",
      "Epoch 13/5000\n",
      "15/15 - 0s - loss: 1.2670 - rmse: 0.1832 - mse: 0.0336 - mae: 0.1508 - val_loss: 1.2111 - val_rmse: 0.2154 - val_mse: 0.0464 - val_mae: 0.1764 - 47ms/epoch - 3ms/step\n",
      "Epoch 14/5000\n",
      "15/15 - 0s - loss: 1.1457 - rmse: 0.1823 - mse: 0.0332 - mae: 0.1497 - val_loss: 1.0972 - val_rmse: 0.2164 - val_mse: 0.0468 - val_mae: 0.1753 - 41ms/epoch - 3ms/step\n",
      "Epoch 15/5000\n",
      "15/15 - 0s - loss: 1.0366 - rmse: 0.1824 - mse: 0.0333 - mae: 0.1496 - val_loss: 0.9934 - val_rmse: 0.2145 - val_mse: 0.0460 - val_mae: 0.1779 - 47ms/epoch - 3ms/step\n",
      "Epoch 16/5000\n",
      "15/15 - 0s - loss: 0.9386 - rmse: 0.1837 - mse: 0.0337 - mae: 0.1514 - val_loss: 0.9003 - val_rmse: 0.2138 - val_mse: 0.0457 - val_mae: 0.1764 - 42ms/epoch - 3ms/step\n",
      "Epoch 17/5000\n",
      "15/15 - 0s - loss: 0.8495 - rmse: 0.1823 - mse: 0.0332 - mae: 0.1499 - val_loss: 0.8171 - val_rmse: 0.2148 - val_mse: 0.0461 - val_mae: 0.1754 - 50ms/epoch - 3ms/step\n",
      "Epoch 18/5000\n",
      "15/15 - 0s - loss: 0.7695 - rmse: 0.1818 - mse: 0.0330 - mae: 0.1488 - val_loss: 0.7411 - val_rmse: 0.2133 - val_mse: 0.0455 - val_mae: 0.1770 - 59ms/epoch - 4ms/step\n",
      "Epoch 19/5000\n",
      "15/15 - 0s - loss: 0.6971 - rmse: 0.1807 - mse: 0.0327 - mae: 0.1494 - val_loss: 0.6732 - val_rmse: 0.2134 - val_mse: 0.0456 - val_mae: 0.1753 - 40ms/epoch - 3ms/step\n",
      "Epoch 20/5000\n",
      "\n",
      "Epoch 20: val_loss improved from 1.63537 to 0.61187, saving model to data/output/activity_single-labeled_Fold-1.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.6320 - rmse: 0.1798 - mse: 0.0323 - mae: 0.1462 - val_loss: 0.6119 - val_rmse: 0.2131 - val_mse: 0.0454 - val_mae: 0.1748 - 57ms/epoch - 4ms/step\n",
      "Epoch 21/5000\n",
      "15/15 - 0s - loss: 0.5735 - rmse: 0.1795 - mse: 0.0322 - mae: 0.1469 - val_loss: 0.5573 - val_rmse: 0.2146 - val_mse: 0.0461 - val_mae: 0.1755 - 38ms/epoch - 3ms/step\n",
      "Epoch 22/5000\n",
      "15/15 - 0s - loss: 0.5206 - rmse: 0.1795 - mse: 0.0322 - mae: 0.1479 - val_loss: 0.5066 - val_rmse: 0.2127 - val_mse: 0.0452 - val_mae: 0.1765 - 33ms/epoch - 2ms/step\n",
      "Epoch 23/5000\n",
      "15/15 - 0s - loss: 0.4722 - rmse: 0.1770 - mse: 0.0313 - mae: 0.1452 - val_loss: 0.4623 - val_rmse: 0.2137 - val_mse: 0.0457 - val_mae: 0.1779 - 29ms/epoch - 2ms/step\n",
      "Epoch 24/5000\n",
      "15/15 - 0s - loss: 0.4304 - rmse: 0.1796 - mse: 0.0323 - mae: 0.1468 - val_loss: 0.4217 - val_rmse: 0.2133 - val_mse: 0.0455 - val_mae: 0.1765 - 31ms/epoch - 2ms/step\n",
      "Epoch 25/5000\n",
      "15/15 - 0s - loss: 0.3916 - rmse: 0.1789 - mse: 0.0320 - mae: 0.1467 - val_loss: 0.3865 - val_rmse: 0.2160 - val_mse: 0.0467 - val_mae: 0.1749 - 39ms/epoch - 3ms/step\n",
      "Epoch 26/5000\n",
      "15/15 - 0s - loss: 0.3563 - rmse: 0.1774 - mse: 0.0315 - mae: 0.1460 - val_loss: 0.3524 - val_rmse: 0.2132 - val_mse: 0.0455 - val_mae: 0.1752 - 43ms/epoch - 3ms/step\n",
      "Epoch 27/5000\n",
      "15/15 - 0s - loss: 0.3241 - rmse: 0.1753 - mse: 0.0307 - mae: 0.1435 - val_loss: 0.3225 - val_rmse: 0.2128 - val_mse: 0.0453 - val_mae: 0.1746 - 37ms/epoch - 2ms/step\n",
      "Epoch 28/5000\n",
      "15/15 - 0s - loss: 0.2971 - rmse: 0.1789 - mse: 0.0320 - mae: 0.1481 - val_loss: 0.2961 - val_rmse: 0.2132 - val_mse: 0.0454 - val_mae: 0.1747 - 31ms/epoch - 2ms/step\n",
      "Epoch 29/5000\n",
      "15/15 - 0s - loss: 0.2706 - rmse: 0.1760 - mse: 0.0310 - mae: 0.1448 - val_loss: 0.2717 - val_rmse: 0.2122 - val_mse: 0.0450 - val_mae: 0.1763 - 31ms/epoch - 2ms/step\n",
      "Epoch 30/5000\n",
      "\n",
      "Epoch 30: val_loss improved from 0.61187 to 0.25020, saving model to data/output/activity_single-labeled_Fold-1.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.2481 - rmse: 0.1771 - mse: 0.0314 - mae: 0.1455 - val_loss: 0.2502 - val_rmse: 0.2126 - val_mse: 0.0452 - val_mae: 0.1748 - 33ms/epoch - 2ms/step\n",
      "Epoch 31/5000\n",
      "15/15 - 0s - loss: 0.2268 - rmse: 0.1754 - mse: 0.0308 - mae: 0.1435 - val_loss: 0.2312 - val_rmse: 0.2139 - val_mse: 0.0457 - val_mae: 0.1744 - 32ms/epoch - 2ms/step\n",
      "Epoch 32/5000\n",
      "15/15 - 0s - loss: 0.2083 - rmse: 0.1759 - mse: 0.0309 - mae: 0.1450 - val_loss: 0.2132 - val_rmse: 0.2131 - val_mse: 0.0454 - val_mae: 0.1752 - 31ms/epoch - 2ms/step\n",
      "Epoch 33/5000\n",
      "15/15 - 0s - loss: 0.1912 - rmse: 0.1751 - mse: 0.0307 - mae: 0.1439 - val_loss: 0.1992 - val_rmse: 0.2172 - val_mse: 0.0472 - val_mae: 0.1836 - 31ms/epoch - 2ms/step\n",
      "Epoch 34/5000\n",
      "15/15 - 0s - loss: 0.1778 - rmse: 0.1797 - mse: 0.0323 - mae: 0.1492 - val_loss: 0.1835 - val_rmse: 0.2140 - val_mse: 0.0458 - val_mae: 0.1757 - 30ms/epoch - 2ms/step\n",
      "Epoch 35/5000\n",
      "15/15 - 0s - loss: 0.1621 - rmse: 0.1738 - mse: 0.0302 - mae: 0.1440 - val_loss: 0.1718 - val_rmse: 0.2167 - val_mse: 0.0469 - val_mae: 0.1746 - 30ms/epoch - 2ms/step\n",
      "Epoch 36/5000\n",
      "15/15 - 0s - loss: 0.1503 - rmse: 0.1753 - mse: 0.0307 - mae: 0.1436 - val_loss: 0.1587 - val_rmse: 0.2130 - val_mse: 0.0454 - val_mae: 0.1761 - 36ms/epoch - 2ms/step\n",
      "Epoch 37/5000\n",
      "15/15 - 0s - loss: 0.1391 - rmse: 0.1748 - mse: 0.0306 - mae: 0.1426 - val_loss: 0.1484 - val_rmse: 0.2134 - val_mse: 0.0455 - val_mae: 0.1775 - 35ms/epoch - 2ms/step\n",
      "Epoch 38/5000\n",
      "15/15 - 0s - loss: 0.1289 - rmse: 0.1744 - mse: 0.0304 - mae: 0.1440 - val_loss: 0.1390 - val_rmse: 0.2138 - val_mse: 0.0457 - val_mae: 0.1743 - 38ms/epoch - 3ms/step\n",
      "Epoch 39/5000\n",
      "15/15 - 0s - loss: 0.1195 - rmse: 0.1734 - mse: 0.0301 - mae: 0.1436 - val_loss: 0.1304 - val_rmse: 0.2134 - val_mse: 0.0455 - val_mae: 0.1743 - 32ms/epoch - 2ms/step\n",
      "Epoch 40/5000\n",
      "\n",
      "Epoch 40: val_loss improved from 0.25020 to 0.12280, saving model to data/output/activity_single-labeled_Fold-1.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.1116 - rmse: 0.1738 - mse: 0.0302 - mae: 0.1433 - val_loss: 0.1228 - val_rmse: 0.2134 - val_mse: 0.0455 - val_mae: 0.1756 - 32ms/epoch - 2ms/step\n",
      "Epoch 41/5000\n",
      "15/15 - 0s - loss: 0.1048 - rmse: 0.1753 - mse: 0.0307 - mae: 0.1437 - val_loss: 0.1157 - val_rmse: 0.2129 - val_mse: 0.0453 - val_mae: 0.1765 - 31ms/epoch - 2ms/step\n",
      "Epoch 42/5000\n",
      "15/15 - 0s - loss: 0.0980 - rmse: 0.1747 - mse: 0.0305 - mae: 0.1432 - val_loss: 0.1093 - val_rmse: 0.2125 - val_mse: 0.0452 - val_mae: 0.1755 - 29ms/epoch - 2ms/step\n",
      "Epoch 43/5000\n",
      "15/15 - 0s - loss: 0.0916 - rmse: 0.1735 - mse: 0.0301 - mae: 0.1423 - val_loss: 0.1032 - val_rmse: 0.2115 - val_mse: 0.0448 - val_mae: 0.1751 - 30ms/epoch - 2ms/step\n",
      "Epoch 44/5000\n",
      "15/15 - 0s - loss: 0.0872 - rmse: 0.1765 - mse: 0.0311 - mae: 0.1462 - val_loss: 0.0983 - val_rmse: 0.2119 - val_mse: 0.0449 - val_mae: 0.1762 - 28ms/epoch - 2ms/step\n",
      "Epoch 45/5000\n",
      "15/15 - 0s - loss: 0.0815 - rmse: 0.1736 - mse: 0.0302 - mae: 0.1429 - val_loss: 0.0942 - val_rmse: 0.2129 - val_mse: 0.0453 - val_mae: 0.1757 - 30ms/epoch - 2ms/step\n",
      "Epoch 46/5000\n",
      "15/15 - 0s - loss: 0.0768 - rmse: 0.1726 - mse: 0.0298 - mae: 0.1402 - val_loss: 0.0899 - val_rmse: 0.2123 - val_mse: 0.0451 - val_mae: 0.1762 - 29ms/epoch - 2ms/step\n",
      "Epoch 47/5000\n",
      "15/15 - 0s - loss: 0.0737 - rmse: 0.1749 - mse: 0.0306 - mae: 0.1435 - val_loss: 0.0861 - val_rmse: 0.2123 - val_mse: 0.0451 - val_mae: 0.1753 - 34ms/epoch - 2ms/step\n",
      "Epoch 48/5000\n",
      "15/15 - 0s - loss: 0.0701 - rmse: 0.1750 - mse: 0.0306 - mae: 0.1445 - val_loss: 0.0832 - val_rmse: 0.2134 - val_mse: 0.0456 - val_mae: 0.1735 - 33ms/epoch - 2ms/step\n",
      "Epoch 49/5000\n",
      "15/15 - 0s - loss: 0.0668 - rmse: 0.1746 - mse: 0.0305 - mae: 0.1442 - val_loss: 0.0795 - val_rmse: 0.2117 - val_mse: 0.0448 - val_mae: 0.1725 - 35ms/epoch - 2ms/step\n",
      "Epoch 50/5000\n",
      "\n",
      "Epoch 50: val_loss improved from 0.12280 to 0.07724, saving model to data/output/activity_single-labeled_Fold-1.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0631 - rmse: 0.1721 - mse: 0.0296 - mae: 0.1414 - val_loss: 0.0772 - val_rmse: 0.2126 - val_mse: 0.0452 - val_mae: 0.1754 - 35ms/epoch - 2ms/step\n",
      "Epoch 51/5000\n",
      "15/15 - 0s - loss: 0.0604 - rmse: 0.1717 - mse: 0.0295 - mae: 0.1406 - val_loss: 0.0753 - val_rmse: 0.2140 - val_mse: 0.0458 - val_mae: 0.1742 - 34ms/epoch - 2ms/step\n",
      "Epoch 52/5000\n",
      "15/15 - 0s - loss: 0.0585 - rmse: 0.1731 - mse: 0.0300 - mae: 0.1431 - val_loss: 0.0721 - val_rmse: 0.2117 - val_mse: 0.0448 - val_mae: 0.1747 - 51ms/epoch - 3ms/step\n",
      "Epoch 53/5000\n",
      "15/15 - 0s - loss: 0.0561 - rmse: 0.1719 - mse: 0.0295 - mae: 0.1410 - val_loss: 0.0718 - val_rmse: 0.2153 - val_mse: 0.0464 - val_mae: 0.1746 - 47ms/epoch - 3ms/step\n",
      "Epoch 54/5000\n",
      "15/15 - 0s - loss: 0.0540 - rmse: 0.1715 - mse: 0.0294 - mae: 0.1404 - val_loss: 0.0696 - val_rmse: 0.2146 - val_mse: 0.0460 - val_mae: 0.1745 - 34ms/epoch - 2ms/step\n",
      "Epoch 55/5000\n",
      "15/15 - 0s - loss: 0.0529 - rmse: 0.1732 - mse: 0.0300 - mae: 0.1430 - val_loss: 0.0688 - val_rmse: 0.2163 - val_mse: 0.0468 - val_mae: 0.1749 - 35ms/epoch - 2ms/step\n",
      "Epoch 56/5000\n",
      "15/15 - 0s - loss: 0.0512 - rmse: 0.1730 - mse: 0.0299 - mae: 0.1417 - val_loss: 0.0661 - val_rmse: 0.2136 - val_mse: 0.0456 - val_mae: 0.1731 - 30ms/epoch - 2ms/step\n",
      "Epoch 57/5000\n",
      "15/15 - 0s - loss: 0.0496 - rmse: 0.1725 - mse: 0.0297 - mae: 0.1426 - val_loss: 0.0641 - val_rmse: 0.2120 - val_mse: 0.0450 - val_mae: 0.1742 - 35ms/epoch - 2ms/step\n",
      "Epoch 58/5000\n",
      "15/15 - 0s - loss: 0.0482 - rmse: 0.1717 - mse: 0.0295 - mae: 0.1411 - val_loss: 0.0644 - val_rmse: 0.2152 - val_mse: 0.0463 - val_mae: 0.1744 - 37ms/epoch - 2ms/step\n",
      "Epoch 59/5000\n",
      "15/15 - 0s - loss: 0.0466 - rmse: 0.1703 - mse: 0.0290 - mae: 0.1396 - val_loss: 0.0621 - val_rmse: 0.2126 - val_mse: 0.0452 - val_mae: 0.1753 - 34ms/epoch - 2ms/step\n",
      "Epoch 60/5000\n",
      "\n",
      "Epoch 60: val_loss improved from 0.07724 to 0.06120, saving model to data/output/activity_single-labeled_Fold-1.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0460 - rmse: 0.1717 - mse: 0.0295 - mae: 0.1412 - val_loss: 0.0612 - val_rmse: 0.2126 - val_mse: 0.0452 - val_mae: 0.1734 - 45ms/epoch - 3ms/step\n",
      "Epoch 61/5000\n",
      "15/15 - 0s - loss: 0.0451 - rmse: 0.1714 - mse: 0.0294 - mae: 0.1402 - val_loss: 0.0602 - val_rmse: 0.2120 - val_mse: 0.0450 - val_mae: 0.1749 - 40ms/epoch - 3ms/step\n",
      "Epoch 62/5000\n",
      "15/15 - 0s - loss: 0.0438 - rmse: 0.1701 - mse: 0.0289 - mae: 0.1389 - val_loss: 0.0596 - val_rmse: 0.2125 - val_mse: 0.0452 - val_mae: 0.1767 - 39ms/epoch - 3ms/step\n",
      "Epoch 63/5000\n",
      "15/15 - 0s - loss: 0.0438 - rmse: 0.1725 - mse: 0.0298 - mae: 0.1416 - val_loss: 0.0592 - val_rmse: 0.2134 - val_mse: 0.0455 - val_mae: 0.1784 - 42ms/epoch - 3ms/step\n",
      "Epoch 64/5000\n",
      "15/15 - 0s - loss: 0.0429 - rmse: 0.1720 - mse: 0.0296 - mae: 0.1413 - val_loss: 0.0580 - val_rmse: 0.2120 - val_mse: 0.0449 - val_mae: 0.1760 - 47ms/epoch - 3ms/step\n",
      "Epoch 65/5000\n",
      "15/15 - 0s - loss: 0.0418 - rmse: 0.1705 - mse: 0.0291 - mae: 0.1407 - val_loss: 0.0577 - val_rmse: 0.2127 - val_mse: 0.0452 - val_mae: 0.1771 - 42ms/epoch - 3ms/step\n",
      "Epoch 66/5000\n",
      "15/15 - 0s - loss: 0.0410 - rmse: 0.1696 - mse: 0.0288 - mae: 0.1384 - val_loss: 0.0574 - val_rmse: 0.2130 - val_mse: 0.0454 - val_mae: 0.1727 - 40ms/epoch - 3ms/step\n",
      "Epoch 67/5000\n",
      "15/15 - 0s - loss: 0.0407 - rmse: 0.1696 - mse: 0.0288 - mae: 0.1377 - val_loss: 0.0582 - val_rmse: 0.2158 - val_mse: 0.0465 - val_mae: 0.1751 - 37ms/epoch - 2ms/step\n",
      "Epoch 68/5000\n",
      "15/15 - 0s - loss: 0.0400 - rmse: 0.1692 - mse: 0.0286 - mae: 0.1388 - val_loss: 0.0570 - val_rmse: 0.2143 - val_mse: 0.0459 - val_mae: 0.1741 - 39ms/epoch - 3ms/step\n",
      "Epoch 69/5000\n",
      "15/15 - 0s - loss: 0.0392 - rmse: 0.1681 - mse: 0.0283 - mae: 0.1381 - val_loss: 0.0559 - val_rmse: 0.2125 - val_mse: 0.0451 - val_mae: 0.1761 - 59ms/epoch - 4ms/step\n",
      "Epoch 70/5000\n",
      "\n",
      "Epoch 70: val_loss improved from 0.06120 to 0.05570, saving model to data/output/activity_single-labeled_Fold-1.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0399 - rmse: 0.1713 - mse: 0.0293 - mae: 0.1400 - val_loss: 0.0557 - val_rmse: 0.2128 - val_mse: 0.0453 - val_mae: 0.1733 - 57ms/epoch - 4ms/step\n",
      "Epoch 71/5000\n",
      "15/15 - 0s - loss: 0.0394 - rmse: 0.1705 - mse: 0.0291 - mae: 0.1394 - val_loss: 0.0574 - val_rmse: 0.2173 - val_mse: 0.0472 - val_mae: 0.1746 - 43ms/epoch - 3ms/step\n",
      "Epoch 72/5000\n",
      "15/15 - 0s - loss: 0.0393 - rmse: 0.1713 - mse: 0.0293 - mae: 0.1415 - val_loss: 0.0554 - val_rmse: 0.2134 - val_mse: 0.0455 - val_mae: 0.1731 - 43ms/epoch - 3ms/step\n",
      "Epoch 73/5000\n",
      "15/15 - 0s - loss: 0.0381 - rmse: 0.1683 - mse: 0.0283 - mae: 0.1379 - val_loss: 0.0546 - val_rmse: 0.2120 - val_mse: 0.0449 - val_mae: 0.1750 - 58ms/epoch - 4ms/step\n",
      "Epoch 74/5000\n",
      "15/15 - 0s - loss: 0.0379 - rmse: 0.1683 - mse: 0.0283 - mae: 0.1374 - val_loss: 0.0546 - val_rmse: 0.2126 - val_mse: 0.0452 - val_mae: 0.1738 - 41ms/epoch - 3ms/step\n",
      "Epoch 75/5000\n",
      "15/15 - 0s - loss: 0.0385 - rmse: 0.1708 - mse: 0.0292 - mae: 0.1396 - val_loss: 0.0535 - val_rmse: 0.2106 - val_mse: 0.0443 - val_mae: 0.1726 - 43ms/epoch - 3ms/step\n",
      "Epoch 76/5000\n",
      "15/15 - 0s - loss: 0.0379 - rmse: 0.1698 - mse: 0.0288 - mae: 0.1384 - val_loss: 0.0551 - val_rmse: 0.2147 - val_mse: 0.0461 - val_mae: 0.1737 - 58ms/epoch - 4ms/step\n",
      "Epoch 77/5000\n",
      "15/15 - 0s - loss: 0.0377 - rmse: 0.1699 - mse: 0.0289 - mae: 0.1391 - val_loss: 0.0547 - val_rmse: 0.2144 - val_mse: 0.0460 - val_mae: 0.1724 - 75ms/epoch - 5ms/step\n",
      "Epoch 78/5000\n",
      "15/15 - 0s - loss: 0.0374 - rmse: 0.1690 - mse: 0.0286 - mae: 0.1386 - val_loss: 0.0543 - val_rmse: 0.2133 - val_mse: 0.0455 - val_mae: 0.1725 - 40ms/epoch - 3ms/step\n",
      "Epoch 79/5000\n",
      "15/15 - 0s - loss: 0.0373 - rmse: 0.1691 - mse: 0.0286 - mae: 0.1376 - val_loss: 0.0542 - val_rmse: 0.2133 - val_mse: 0.0455 - val_mae: 0.1741 - 43ms/epoch - 3ms/step\n",
      "Epoch 80/5000\n",
      "\n",
      "Epoch 80: val_loss improved from 0.05570 to 0.05288, saving model to data/output/activity_single-labeled_Fold-1.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0370 - rmse: 0.1686 - mse: 0.0284 - mae: 0.1375 - val_loss: 0.0529 - val_rmse: 0.2109 - val_mse: 0.0445 - val_mae: 0.1729 - 66ms/epoch - 4ms/step\n",
      "Epoch 81/5000\n",
      "15/15 - 0s - loss: 0.0365 - rmse: 0.1677 - mse: 0.0281 - mae: 0.1366 - val_loss: 0.0535 - val_rmse: 0.2123 - val_mse: 0.0451 - val_mae: 0.1754 - 42ms/epoch - 3ms/step\n",
      "Epoch 82/5000\n",
      "15/15 - 0s - loss: 0.0369 - rmse: 0.1688 - mse: 0.0285 - mae: 0.1376 - val_loss: 0.0541 - val_rmse: 0.2138 - val_mse: 0.0457 - val_mae: 0.1741 - 40ms/epoch - 3ms/step\n",
      "Epoch 83/5000\n",
      "15/15 - 0s - loss: 0.0367 - rmse: 0.1686 - mse: 0.0284 - mae: 0.1381 - val_loss: 0.0532 - val_rmse: 0.2123 - val_mse: 0.0451 - val_mae: 0.1737 - 38ms/epoch - 3ms/step\n",
      "Epoch 84/5000\n",
      "15/15 - 0s - loss: 0.0368 - rmse: 0.1693 - mse: 0.0287 - mae: 0.1385 - val_loss: 0.0527 - val_rmse: 0.2111 - val_mse: 0.0446 - val_mae: 0.1738 - 44ms/epoch - 3ms/step\n",
      "Epoch 85/5000\n",
      "15/15 - 0s - loss: 0.0371 - rmse: 0.1704 - mse: 0.0290 - mae: 0.1392 - val_loss: 0.0529 - val_rmse: 0.2117 - val_mse: 0.0448 - val_mae: 0.1751 - 49ms/epoch - 3ms/step\n",
      "Epoch 86/5000\n",
      "15/15 - 0s - loss: 0.0367 - rmse: 0.1690 - mse: 0.0286 - mae: 0.1376 - val_loss: 0.0531 - val_rmse: 0.2122 - val_mse: 0.0450 - val_mae: 0.1763 - 47ms/epoch - 3ms/step\n",
      "Epoch 87/5000\n",
      "15/15 - 0s - loss: 0.0364 - rmse: 0.1685 - mse: 0.0284 - mae: 0.1384 - val_loss: 0.0525 - val_rmse: 0.2112 - val_mse: 0.0446 - val_mae: 0.1736 - 51ms/epoch - 3ms/step\n",
      "Epoch 88/5000\n",
      "15/15 - 0s - loss: 0.0359 - rmse: 0.1676 - mse: 0.0281 - mae: 0.1371 - val_loss: 0.0523 - val_rmse: 0.2107 - val_mse: 0.0444 - val_mae: 0.1745 - 30ms/epoch - 2ms/step\n",
      "Epoch 89/5000\n",
      "15/15 - 0s - loss: 0.0360 - rmse: 0.1676 - mse: 0.0281 - mae: 0.1366 - val_loss: 0.0534 - val_rmse: 0.2134 - val_mse: 0.0455 - val_mae: 0.1739 - 30ms/epoch - 2ms/step\n",
      "Epoch 90/5000\n",
      "\n",
      "Epoch 90: val_loss improved from 0.05288 to 0.05246, saving model to data/output/activity_single-labeled_Fold-1.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0364 - rmse: 0.1691 - mse: 0.0286 - mae: 0.1383 - val_loss: 0.0525 - val_rmse: 0.2114 - val_mse: 0.0447 - val_mae: 0.1750 - 32ms/epoch - 2ms/step\n",
      "Epoch 91/5000\n",
      "15/15 - 0s - loss: 0.0359 - rmse: 0.1675 - mse: 0.0280 - mae: 0.1363 - val_loss: 0.0534 - val_rmse: 0.2135 - val_mse: 0.0456 - val_mae: 0.1775 - 44ms/epoch - 3ms/step\n",
      "Epoch 92/5000\n",
      "15/15 - 0s - loss: 0.0359 - rmse: 0.1676 - mse: 0.0281 - mae: 0.1363 - val_loss: 0.0526 - val_rmse: 0.2119 - val_mse: 0.0449 - val_mae: 0.1735 - 37ms/epoch - 2ms/step\n",
      "Epoch 93/5000\n",
      "15/15 - 0s - loss: 0.0353 - rmse: 0.1661 - mse: 0.0276 - mae: 0.1357 - val_loss: 0.0526 - val_rmse: 0.2119 - val_mse: 0.0449 - val_mae: 0.1724 - 32ms/epoch - 2ms/step\n",
      "Epoch 94/5000\n",
      "15/15 - 0s - loss: 0.0359 - rmse: 0.1681 - mse: 0.0283 - mae: 0.1379 - val_loss: 0.0518 - val_rmse: 0.2102 - val_mse: 0.0442 - val_mae: 0.1728 - 35ms/epoch - 2ms/step\n",
      "Epoch 95/5000\n",
      "15/15 - 0s - loss: 0.0355 - rmse: 0.1668 - mse: 0.0278 - mae: 0.1366 - val_loss: 0.0528 - val_rmse: 0.2124 - val_mse: 0.0451 - val_mae: 0.1742 - 30ms/epoch - 2ms/step\n",
      "Epoch 96/5000\n",
      "15/15 - 0s - loss: 0.0357 - rmse: 0.1673 - mse: 0.0280 - mae: 0.1357 - val_loss: 0.0533 - val_rmse: 0.2137 - val_mse: 0.0457 - val_mae: 0.1739 - 27ms/epoch - 2ms/step\n",
      "Epoch 97/5000\n",
      "15/15 - 0s - loss: 0.0351 - rmse: 0.1660 - mse: 0.0275 - mae: 0.1360 - val_loss: 0.0517 - val_rmse: 0.2102 - val_mse: 0.0442 - val_mae: 0.1723 - 32ms/epoch - 2ms/step\n",
      "Epoch 98/5000\n",
      "15/15 - 0s - loss: 0.0354 - rmse: 0.1666 - mse: 0.0278 - mae: 0.1364 - val_loss: 0.0527 - val_rmse: 0.2123 - val_mse: 0.0451 - val_mae: 0.1730 - 29ms/epoch - 2ms/step\n",
      "Epoch 99/5000\n",
      "15/15 - 0s - loss: 0.0364 - rmse: 0.1697 - mse: 0.0288 - mae: 0.1381 - val_loss: 0.0521 - val_rmse: 0.2111 - val_mse: 0.0446 - val_mae: 0.1736 - 28ms/epoch - 2ms/step\n",
      "Epoch 100/5000\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.05246\n",
      "15/15 - 0s - loss: 0.0356 - rmse: 0.1675 - mse: 0.0281 - mae: 0.1372 - val_loss: 0.0526 - val_rmse: 0.2123 - val_mse: 0.0451 - val_mae: 0.1764 - 30ms/epoch - 2ms/step\n",
      "Epoch 101/5000\n",
      "15/15 - 0s - loss: 0.0353 - rmse: 0.1665 - mse: 0.0277 - mae: 0.1357 - val_loss: 0.0530 - val_rmse: 0.2133 - val_mse: 0.0455 - val_mae: 0.1757 - 30ms/epoch - 2ms/step\n",
      "Epoch 102/5000\n",
      "15/15 - 0s - loss: 0.0359 - rmse: 0.1683 - mse: 0.0283 - mae: 0.1369 - val_loss: 0.0525 - val_rmse: 0.2119 - val_mse: 0.0449 - val_mae: 0.1750 - 32ms/epoch - 2ms/step\n",
      "Epoch 103/5000\n",
      "15/15 - 0s - loss: 0.0357 - rmse: 0.1676 - mse: 0.0281 - mae: 0.1365 - val_loss: 0.0533 - val_rmse: 0.2140 - val_mse: 0.0458 - val_mae: 0.1730 - 30ms/epoch - 2ms/step\n",
      "Epoch 104/5000\n",
      "15/15 - 0s - loss: 0.0352 - rmse: 0.1664 - mse: 0.0277 - mae: 0.1361 - val_loss: 0.0562 - val_rmse: 0.2207 - val_mse: 0.0487 - val_mae: 0.1759 - 30ms/epoch - 2ms/step\n",
      "Epoch 105/5000\n",
      "15/15 - 0s - loss: 0.0360 - rmse: 0.1687 - mse: 0.0285 - mae: 0.1370 - val_loss: 0.0535 - val_rmse: 0.2145 - val_mse: 0.0460 - val_mae: 0.1741 - 34ms/epoch - 2ms/step\n",
      "Epoch 106/5000\n",
      "15/15 - 0s - loss: 0.0353 - rmse: 0.1665 - mse: 0.0277 - mae: 0.1357 - val_loss: 0.0532 - val_rmse: 0.2136 - val_mse: 0.0456 - val_mae: 0.1736 - 42ms/epoch - 3ms/step\n",
      "Epoch 107/5000\n",
      "15/15 - 0s - loss: 0.0356 - rmse: 0.1676 - mse: 0.0281 - mae: 0.1371 - val_loss: 0.0537 - val_rmse: 0.2149 - val_mse: 0.0462 - val_mae: 0.1743 - 35ms/epoch - 2ms/step\n",
      "Epoch 108/5000\n",
      "15/15 - 0s - loss: 0.0345 - rmse: 0.1646 - mse: 0.0271 - mae: 0.1350 - val_loss: 0.0514 - val_rmse: 0.2097 - val_mse: 0.0440 - val_mae: 0.1732 - 38ms/epoch - 3ms/step\n",
      "Epoch 109/5000\n",
      "15/15 - 0s - loss: 0.0357 - rmse: 0.1680 - mse: 0.0282 - mae: 0.1367 - val_loss: 0.0531 - val_rmse: 0.2135 - val_mse: 0.0456 - val_mae: 0.1766 - 39ms/epoch - 3ms/step\n",
      "Epoch 110/5000\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.05246\n",
      "15/15 - 0s - loss: 0.0352 - rmse: 0.1663 - mse: 0.0277 - mae: 0.1350 - val_loss: 0.0530 - val_rmse: 0.2135 - val_mse: 0.0456 - val_mae: 0.1730 - 33ms/epoch - 2ms/step\n",
      "Epoch 111/5000\n",
      "15/15 - 0s - loss: 0.0348 - rmse: 0.1656 - mse: 0.0274 - mae: 0.1348 - val_loss: 0.0520 - val_rmse: 0.2109 - val_mse: 0.0445 - val_mae: 0.1732 - 30ms/epoch - 2ms/step\n",
      "Epoch 112/5000\n",
      "15/15 - 0s - loss: 0.0354 - rmse: 0.1670 - mse: 0.0279 - mae: 0.1364 - val_loss: 0.0527 - val_rmse: 0.2126 - val_mse: 0.0452 - val_mae: 0.1739 - 42ms/epoch - 3ms/step\n",
      "Epoch 113/5000\n",
      "15/15 - 0s - loss: 0.0353 - rmse: 0.1667 - mse: 0.0278 - mae: 0.1347 - val_loss: 0.0531 - val_rmse: 0.2137 - val_mse: 0.0457 - val_mae: 0.1721 - 37ms/epoch - 2ms/step\n",
      "Epoch 114/5000\n",
      "15/15 - 0s - loss: 0.0354 - rmse: 0.1673 - mse: 0.0280 - mae: 0.1357 - val_loss: 0.0520 - val_rmse: 0.2109 - val_mse: 0.0445 - val_mae: 0.1725 - 38ms/epoch - 3ms/step\n",
      "Epoch 115/5000\n",
      "15/15 - 0s - loss: 0.0357 - rmse: 0.1678 - mse: 0.0282 - mae: 0.1361 - val_loss: 0.0532 - val_rmse: 0.2139 - val_mse: 0.0458 - val_mae: 0.1731 - 39ms/epoch - 3ms/step\n",
      "Epoch 116/5000\n",
      "15/15 - 0s - loss: 0.0351 - rmse: 0.1666 - mse: 0.0278 - mae: 0.1368 - val_loss: 0.0522 - val_rmse: 0.2118 - val_mse: 0.0449 - val_mae: 0.1719 - 38ms/epoch - 3ms/step\n",
      "Epoch 117/5000\n",
      "15/15 - 0s - loss: 0.0350 - rmse: 0.1660 - mse: 0.0275 - mae: 0.1350 - val_loss: 0.0535 - val_rmse: 0.2144 - val_mse: 0.0460 - val_mae: 0.1738 - 34ms/epoch - 2ms/step\n",
      "Epoch 118/5000\n",
      "15/15 - 0s - loss: 0.0349 - rmse: 0.1658 - mse: 0.0275 - mae: 0.1346 - val_loss: 0.0527 - val_rmse: 0.2127 - val_mse: 0.0452 - val_mae: 0.1748 - 31ms/epoch - 2ms/step\n",
      "Epoch 119/5000\n",
      "15/15 - 0s - loss: 0.0353 - rmse: 0.1670 - mse: 0.0279 - mae: 0.1359 - val_loss: 0.0532 - val_rmse: 0.2139 - val_mse: 0.0458 - val_mae: 0.1769 - 29ms/epoch - 2ms/step\n",
      "Epoch 120/5000\n",
      "\n",
      "Epoch 120: val_loss improved from 0.05246 to 0.05218, saving model to data/output/activity_single-labeled_Fold-1.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0348 - rmse: 0.1656 - mse: 0.0274 - mae: 0.1352 - val_loss: 0.0522 - val_rmse: 0.2117 - val_mse: 0.0448 - val_mae: 0.1753 - 50ms/epoch - 3ms/step\n",
      "Epoch 121/5000\n",
      "15/15 - 0s - loss: 0.0347 - rmse: 0.1649 - mse: 0.0272 - mae: 0.1338 - val_loss: 0.0545 - val_rmse: 0.2168 - val_mse: 0.0470 - val_mae: 0.1754 - 36ms/epoch - 2ms/step\n",
      "Epoch 122/5000\n",
      "15/15 - 0s - loss: 0.0360 - rmse: 0.1691 - mse: 0.0286 - mae: 0.1376 - val_loss: 0.0526 - val_rmse: 0.2127 - val_mse: 0.0452 - val_mae: 0.1753 - 51ms/epoch - 3ms/step\n",
      "Epoch 123/5000\n",
      "15/15 - 0s - loss: 0.0346 - rmse: 0.1651 - mse: 0.0272 - mae: 0.1342 - val_loss: 0.0518 - val_rmse: 0.2109 - val_mse: 0.0445 - val_mae: 0.1715 - 43ms/epoch - 3ms/step\n",
      "Epoch 124/5000\n",
      "15/15 - 0s - loss: 0.0349 - rmse: 0.1657 - mse: 0.0275 - mae: 0.1341 - val_loss: 0.0539 - val_rmse: 0.2155 - val_mse: 0.0464 - val_mae: 0.1725 - 36ms/epoch - 2ms/step\n",
      "Epoch 125/5000\n",
      "15/15 - 0s - loss: 0.0355 - rmse: 0.1677 - mse: 0.0281 - mae: 0.1371 - val_loss: 0.0530 - val_rmse: 0.2137 - val_mse: 0.0457 - val_mae: 0.1769 - 38ms/epoch - 3ms/step\n",
      "Epoch 126/5000\n",
      "15/15 - 0s - loss: 0.0352 - rmse: 0.1667 - mse: 0.0278 - mae: 0.1362 - val_loss: 0.0539 - val_rmse: 0.2155 - val_mse: 0.0464 - val_mae: 0.1740 - 38ms/epoch - 3ms/step\n",
      "Epoch 127/5000\n",
      "15/15 - 0s - loss: 0.0354 - rmse: 0.1673 - mse: 0.0280 - mae: 0.1357 - val_loss: 0.0517 - val_rmse: 0.2107 - val_mse: 0.0444 - val_mae: 0.1726 - 38ms/epoch - 3ms/step\n",
      "Epoch 128/5000\n",
      "Restoring model weights from the end of the best epoch: 108.\n",
      "15/15 - 0s - loss: 0.0352 - rmse: 0.1668 - mse: 0.0278 - mae: 0.1361 - val_loss: 0.0523 - val_rmse: 0.2119 - val_mse: 0.0449 - val_mae: 0.1752 - 38ms/epoch - 3ms/step\n",
      "Epoch 128: early stopping\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hertelj/build/local/miniforge3/envs/dfpl/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "15/15 - 0s - loss: 4.4430 - rmse: 0.5841 - mse: 0.3412 - mae: 0.4423 - val_loss: 4.0425 - val_rmse: 0.2901 - val_mse: 0.0842 - val_mae: 0.2371 - 377ms/epoch - 25ms/step\n",
      "Epoch 2/5000\n",
      "15/15 - 0s - loss: 3.8774 - rmse: 0.2685 - mse: 0.0721 - mae: 0.2169 - val_loss: 3.6760 - val_rmse: 0.2545 - val_mse: 0.0648 - val_mae: 0.2128 - 32ms/epoch - 2ms/step\n",
      "Epoch 3/5000\n",
      "15/15 - 0s - loss: 3.5052 - rmse: 0.2268 - mse: 0.0514 - mae: 0.1864 - val_loss: 3.3199 - val_rmse: 0.2356 - val_mse: 0.0555 - val_mae: 0.1905 - 35ms/epoch - 2ms/step\n",
      "Epoch 4/5000\n",
      "15/15 - 0s - loss: 3.1607 - rmse: 0.2057 - mse: 0.0423 - mae: 0.1690 - val_loss: 2.9894 - val_rmse: 0.2113 - val_mse: 0.0446 - val_mae: 0.1783 - 52ms/epoch - 3ms/step\n",
      "Epoch 5/5000\n",
      "15/15 - 0s - loss: 2.8503 - rmse: 0.1945 - mse: 0.0378 - mae: 0.1578 - val_loss: 2.6997 - val_rmse: 0.2103 - val_mse: 0.0442 - val_mae: 0.1758 - 37ms/epoch - 2ms/step\n",
      "Epoch 6/5000\n",
      "15/15 - 0s - loss: 2.5744 - rmse: 0.1960 - mse: 0.0384 - mae: 0.1603 - val_loss: 2.4375 - val_rmse: 0.2077 - val_mse: 0.0431 - val_mae: 0.1739 - 35ms/epoch - 2ms/step\n",
      "Epoch 7/5000\n",
      "15/15 - 0s - loss: 2.3228 - rmse: 0.1903 - mse: 0.0362 - mae: 0.1558 - val_loss: 2.2002 - val_rmse: 0.2031 - val_mse: 0.0413 - val_mae: 0.1661 - 46ms/epoch - 3ms/step\n",
      "Epoch 8/5000\n",
      "15/15 - 0s - loss: 2.0960 - rmse: 0.1851 - mse: 0.0342 - mae: 0.1496 - val_loss: 1.9880 - val_rmse: 0.2032 - val_mse: 0.0413 - val_mae: 0.1696 - 35ms/epoch - 2ms/step\n",
      "Epoch 9/5000\n",
      "15/15 - 0s - loss: 1.8946 - rmse: 0.1882 - mse: 0.0354 - mae: 0.1531 - val_loss: 1.7964 - val_rmse: 0.2025 - val_mse: 0.0410 - val_mae: 0.1691 - 34ms/epoch - 2ms/step\n",
      "Epoch 10/5000\n",
      "\n",
      "Epoch 10: val_loss improved from inf to 1.62299, saving model to data/output/activity_single-labeled_Fold-2.model.weights.hdf5\n",
      "15/15 - 0s - loss: 1.7103 - rmse: 0.1838 - mse: 0.0338 - mae: 0.1502 - val_loss: 1.6230 - val_rmse: 0.2000 - val_mse: 0.0400 - val_mae: 0.1655 - 40ms/epoch - 3ms/step\n",
      "Epoch 11/5000\n",
      "15/15 - 0s - loss: 1.5454 - rmse: 0.1831 - mse: 0.0335 - mae: 0.1480 - val_loss: 1.4675 - val_rmse: 0.1998 - val_mse: 0.0399 - val_mae: 0.1658 - 43ms/epoch - 3ms/step\n",
      "Epoch 12/5000\n",
      "15/15 - 0s - loss: 1.3975 - rmse: 0.1847 - mse: 0.0341 - mae: 0.1505 - val_loss: 1.3278 - val_rmse: 0.2007 - val_mse: 0.0403 - val_mae: 0.1661 - 47ms/epoch - 3ms/step\n",
      "Epoch 13/5000\n",
      "15/15 - 0s - loss: 1.2630 - rmse: 0.1823 - mse: 0.0332 - mae: 0.1499 - val_loss: 1.2013 - val_rmse: 0.1999 - val_mse: 0.0400 - val_mae: 0.1651 - 43ms/epoch - 3ms/step\n",
      "Epoch 14/5000\n",
      "15/15 - 0s - loss: 1.1426 - rmse: 0.1826 - mse: 0.0334 - mae: 0.1482 - val_loss: 1.0876 - val_rmse: 0.2004 - val_mse: 0.0402 - val_mae: 0.1682 - 55ms/epoch - 4ms/step\n",
      "Epoch 15/5000\n",
      "15/15 - 0s - loss: 1.0335 - rmse: 0.1815 - mse: 0.0329 - mae: 0.1487 - val_loss: 0.9850 - val_rmse: 0.2001 - val_mse: 0.0400 - val_mae: 0.1649 - 39ms/epoch - 3ms/step\n",
      "Epoch 16/5000\n",
      "15/15 - 0s - loss: 0.9366 - rmse: 0.1844 - mse: 0.0340 - mae: 0.1510 - val_loss: 0.8924 - val_rmse: 0.2002 - val_mse: 0.0401 - val_mae: 0.1667 - 52ms/epoch - 3ms/step\n",
      "Epoch 17/5000\n",
      "15/15 - 0s - loss: 0.8472 - rmse: 0.1817 - mse: 0.0330 - mae: 0.1473 - val_loss: 0.8088 - val_rmse: 0.1995 - val_mse: 0.0398 - val_mae: 0.1658 - 34ms/epoch - 2ms/step\n",
      "Epoch 18/5000\n",
      "15/15 - 0s - loss: 0.7671 - rmse: 0.1801 - mse: 0.0324 - mae: 0.1462 - val_loss: 0.7337 - val_rmse: 0.1997 - val_mse: 0.0399 - val_mae: 0.1669 - 47ms/epoch - 3ms/step\n",
      "Epoch 19/5000\n",
      "15/15 - 0s - loss: 0.6960 - rmse: 0.1823 - mse: 0.0332 - mae: 0.1495 - val_loss: 0.6666 - val_rmse: 0.2015 - val_mse: 0.0406 - val_mae: 0.1668 - 35ms/epoch - 2ms/step\n",
      "Epoch 20/5000\n",
      "\n",
      "Epoch 20: val_loss improved from 1.62299 to 0.60537, saving model to data/output/activity_single-labeled_Fold-2.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.6303 - rmse: 0.1794 - mse: 0.0322 - mae: 0.1469 - val_loss: 0.6054 - val_rmse: 0.2009 - val_mse: 0.0403 - val_mae: 0.1679 - 37ms/epoch - 2ms/step\n",
      "Epoch 21/5000\n",
      "15/15 - 0s - loss: 0.5718 - rmse: 0.1786 - mse: 0.0319 - mae: 0.1449 - val_loss: 0.5507 - val_rmse: 0.2016 - val_mse: 0.0406 - val_mae: 0.1671 - 34ms/epoch - 2ms/step\n",
      "Epoch 22/5000\n",
      "15/15 - 0s - loss: 0.5201 - rmse: 0.1813 - mse: 0.0329 - mae: 0.1488 - val_loss: 0.5008 - val_rmse: 0.2013 - val_mse: 0.0405 - val_mae: 0.1694 - 47ms/epoch - 3ms/step\n",
      "Epoch 23/5000\n",
      "15/15 - 0s - loss: 0.4724 - rmse: 0.1803 - mse: 0.0325 - mae: 0.1467 - val_loss: 0.4557 - val_rmse: 0.2002 - val_mse: 0.0401 - val_mae: 0.1676 - 50ms/epoch - 3ms/step\n",
      "Epoch 24/5000\n",
      "15/15 - 0s - loss: 0.4286 - rmse: 0.1770 - mse: 0.0313 - mae: 0.1451 - val_loss: 0.4158 - val_rmse: 0.2009 - val_mse: 0.0403 - val_mae: 0.1673 - 41ms/epoch - 3ms/step\n",
      "Epoch 25/5000\n",
      "15/15 - 0s - loss: 0.3903 - rmse: 0.1776 - mse: 0.0315 - mae: 0.1444 - val_loss: 0.3798 - val_rmse: 0.2017 - val_mse: 0.0407 - val_mae: 0.1692 - 37ms/epoch - 2ms/step\n",
      "Epoch 26/5000\n",
      "15/15 - 0s - loss: 0.3566 - rmse: 0.1802 - mse: 0.0325 - mae: 0.1478 - val_loss: 0.3470 - val_rmse: 0.2016 - val_mse: 0.0407 - val_mae: 0.1677 - 39ms/epoch - 3ms/step\n",
      "Epoch 27/5000\n",
      "15/15 - 0s - loss: 0.3243 - rmse: 0.1773 - mse: 0.0314 - mae: 0.1454 - val_loss: 0.3171 - val_rmse: 0.2005 - val_mse: 0.0402 - val_mae: 0.1677 - 48ms/epoch - 3ms/step\n",
      "Epoch 28/5000\n",
      "15/15 - 0s - loss: 0.2963 - rmse: 0.1777 - mse: 0.0316 - mae: 0.1453 - val_loss: 0.2907 - val_rmse: 0.2010 - val_mse: 0.0404 - val_mae: 0.1672 - 65ms/epoch - 4ms/step\n",
      "Epoch 29/5000\n",
      "15/15 - 0s - loss: 0.2708 - rmse: 0.1774 - mse: 0.0315 - mae: 0.1445 - val_loss: 0.2671 - val_rmse: 0.2021 - val_mse: 0.0409 - val_mae: 0.1702 - 31ms/epoch - 2ms/step\n",
      "Epoch 30/5000\n",
      "\n",
      "Epoch 30: val_loss improved from 0.60537 to 0.24611, saving model to data/output/activity_single-labeled_Fold-2.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.2481 - rmse: 0.1778 - mse: 0.0316 - mae: 0.1464 - val_loss: 0.2461 - val_rmse: 0.2034 - val_mse: 0.0414 - val_mae: 0.1670 - 35ms/epoch - 2ms/step\n",
      "Epoch 31/5000\n",
      "15/15 - 0s - loss: 0.2277 - rmse: 0.1787 - mse: 0.0320 - mae: 0.1462 - val_loss: 0.2260 - val_rmse: 0.2021 - val_mse: 0.0408 - val_mae: 0.1708 - 29ms/epoch - 2ms/step\n",
      "Epoch 32/5000\n",
      "15/15 - 0s - loss: 0.2086 - rmse: 0.1774 - mse: 0.0315 - mae: 0.1469 - val_loss: 0.2082 - val_rmse: 0.2013 - val_mse: 0.0405 - val_mae: 0.1686 - 32ms/epoch - 2ms/step\n",
      "Epoch 33/5000\n",
      "15/15 - 0s - loss: 0.1917 - rmse: 0.1768 - mse: 0.0312 - mae: 0.1446 - val_loss: 0.1925 - val_rmse: 0.2013 - val_mse: 0.0405 - val_mae: 0.1680 - 29ms/epoch - 2ms/step\n",
      "Epoch 34/5000\n",
      "15/15 - 0s - loss: 0.1763 - rmse: 0.1756 - mse: 0.0308 - mae: 0.1432 - val_loss: 0.1784 - val_rmse: 0.2017 - val_mse: 0.0407 - val_mae: 0.1688 - 60ms/epoch - 4ms/step\n",
      "Epoch 35/5000\n",
      "15/15 - 0s - loss: 0.1629 - rmse: 0.1765 - mse: 0.0312 - mae: 0.1451 - val_loss: 0.1655 - val_rmse: 0.2017 - val_mse: 0.0407 - val_mae: 0.1669 - 39ms/epoch - 3ms/step\n",
      "Epoch 36/5000\n",
      "15/15 - 0s - loss: 0.1506 - rmse: 0.1763 - mse: 0.0311 - mae: 0.1448 - val_loss: 0.1544 - val_rmse: 0.2027 - val_mse: 0.0411 - val_mae: 0.1704 - 40ms/epoch - 3ms/step\n",
      "Epoch 37/5000\n",
      "15/15 - 0s - loss: 0.1399 - rmse: 0.1771 - mse: 0.0314 - mae: 0.1438 - val_loss: 0.1440 - val_rmse: 0.2028 - val_mse: 0.0411 - val_mae: 0.1708 - 41ms/epoch - 3ms/step\n",
      "Epoch 38/5000\n",
      "15/15 - 0s - loss: 0.1297 - rmse: 0.1766 - mse: 0.0312 - mae: 0.1451 - val_loss: 0.1345 - val_rmse: 0.2027 - val_mse: 0.0411 - val_mae: 0.1669 - 39ms/epoch - 3ms/step\n",
      "Epoch 39/5000\n",
      "15/15 - 0s - loss: 0.1201 - rmse: 0.1748 - mse: 0.0306 - mae: 0.1424 - val_loss: 0.1255 - val_rmse: 0.2014 - val_mse: 0.0406 - val_mae: 0.1687 - 37ms/epoch - 2ms/step\n",
      "Epoch 40/5000\n",
      "\n",
      "Epoch 40: val_loss improved from 0.24611 to 0.11792, saving model to data/output/activity_single-labeled_Fold-2.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.1118 - rmse: 0.1740 - mse: 0.0303 - mae: 0.1426 - val_loss: 0.1179 - val_rmse: 0.2014 - val_mse: 0.0406 - val_mae: 0.1677 - 61ms/epoch - 4ms/step\n",
      "Epoch 41/5000\n",
      "15/15 - 0s - loss: 0.1047 - rmse: 0.1748 - mse: 0.0305 - mae: 0.1431 - val_loss: 0.1110 - val_rmse: 0.2014 - val_mse: 0.0406 - val_mae: 0.1686 - 38ms/epoch - 3ms/step\n",
      "Epoch 42/5000\n",
      "15/15 - 0s - loss: 0.0989 - rmse: 0.1768 - mse: 0.0313 - mae: 0.1451 - val_loss: 0.1054 - val_rmse: 0.2028 - val_mse: 0.0411 - val_mae: 0.1663 - 35ms/epoch - 2ms/step\n",
      "Epoch 43/5000\n",
      "15/15 - 0s - loss: 0.0924 - rmse: 0.1754 - mse: 0.0308 - mae: 0.1439 - val_loss: 0.0992 - val_rmse: 0.2016 - val_mse: 0.0406 - val_mae: 0.1683 - 38ms/epoch - 3ms/step\n",
      "Epoch 44/5000\n",
      "15/15 - 0s - loss: 0.0870 - rmse: 0.1753 - mse: 0.0307 - mae: 0.1442 - val_loss: 0.0948 - val_rmse: 0.2030 - val_mse: 0.0412 - val_mae: 0.1677 - 37ms/epoch - 2ms/step\n",
      "Epoch 45/5000\n",
      "15/15 - 0s - loss: 0.0822 - rmse: 0.1750 - mse: 0.0306 - mae: 0.1430 - val_loss: 0.0904 - val_rmse: 0.2029 - val_mse: 0.0412 - val_mae: 0.1695 - 35ms/epoch - 2ms/step\n",
      "Epoch 46/5000\n",
      "15/15 - 0s - loss: 0.0776 - rmse: 0.1741 - mse: 0.0303 - mae: 0.1426 - val_loss: 0.0861 - val_rmse: 0.2027 - val_mse: 0.0411 - val_mae: 0.1671 - 34ms/epoch - 2ms/step\n",
      "Epoch 47/5000\n",
      "15/15 - 0s - loss: 0.0747 - rmse: 0.1774 - mse: 0.0315 - mae: 0.1454 - val_loss: 0.0817 - val_rmse: 0.2012 - val_mse: 0.0405 - val_mae: 0.1685 - 38ms/epoch - 3ms/step\n",
      "Epoch 48/5000\n",
      "15/15 - 0s - loss: 0.0705 - rmse: 0.1754 - mse: 0.0308 - mae: 0.1427 - val_loss: 0.0785 - val_rmse: 0.2014 - val_mse: 0.0406 - val_mae: 0.1684 - 36ms/epoch - 2ms/step\n",
      "Epoch 49/5000\n",
      "15/15 - 0s - loss: 0.0671 - rmse: 0.1749 - mse: 0.0306 - mae: 0.1433 - val_loss: 0.0756 - val_rmse: 0.2017 - val_mse: 0.0407 - val_mae: 0.1675 - 35ms/epoch - 2ms/step\n",
      "Epoch 50/5000\n",
      "\n",
      "Epoch 50: val_loss improved from 0.11792 to 0.07331, saving model to data/output/activity_single-labeled_Fold-2.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0640 - rmse: 0.1741 - mse: 0.0303 - mae: 0.1426 - val_loss: 0.0733 - val_rmse: 0.2028 - val_mse: 0.0411 - val_mae: 0.1679 - 43ms/epoch - 3ms/step\n",
      "Epoch 51/5000\n",
      "15/15 - 0s - loss: 0.0613 - rmse: 0.1739 - mse: 0.0302 - mae: 0.1423 - val_loss: 0.0702 - val_rmse: 0.2012 - val_mse: 0.0405 - val_mae: 0.1685 - 37ms/epoch - 2ms/step\n",
      "Epoch 52/5000\n",
      "15/15 - 0s - loss: 0.0594 - rmse: 0.1753 - mse: 0.0307 - mae: 0.1429 - val_loss: 0.0701 - val_rmse: 0.2063 - val_mse: 0.0426 - val_mae: 0.1742 - 36ms/epoch - 2ms/step\n",
      "Epoch 53/5000\n",
      "15/15 - 0s - loss: 0.0574 - rmse: 0.1754 - mse: 0.0308 - mae: 0.1430 - val_loss: 0.0663 - val_rmse: 0.2018 - val_mse: 0.0407 - val_mae: 0.1681 - 37ms/epoch - 2ms/step\n",
      "Epoch 54/5000\n",
      "15/15 - 0s - loss: 0.0558 - rmse: 0.1761 - mse: 0.0310 - mae: 0.1449 - val_loss: 0.0649 - val_rmse: 0.2028 - val_mse: 0.0411 - val_mae: 0.1692 - 37ms/epoch - 2ms/step\n",
      "Epoch 55/5000\n",
      "15/15 - 0s - loss: 0.0542 - rmse: 0.1762 - mse: 0.0311 - mae: 0.1437 - val_loss: 0.0632 - val_rmse: 0.2022 - val_mse: 0.0409 - val_mae: 0.1669 - 42ms/epoch - 3ms/step\n",
      "Epoch 56/5000\n",
      "15/15 - 0s - loss: 0.0515 - rmse: 0.1730 - mse: 0.0299 - mae: 0.1418 - val_loss: 0.0618 - val_rmse: 0.2026 - val_mse: 0.0410 - val_mae: 0.1670 - 40ms/epoch - 3ms/step\n",
      "Epoch 57/5000\n",
      "15/15 - 0s - loss: 0.0505 - rmse: 0.1743 - mse: 0.0304 - mae: 0.1427 - val_loss: 0.0597 - val_rmse: 0.2008 - val_mse: 0.0403 - val_mae: 0.1665 - 53ms/epoch - 4ms/step\n",
      "Epoch 58/5000\n",
      "15/15 - 0s - loss: 0.0488 - rmse: 0.1730 - mse: 0.0299 - mae: 0.1417 - val_loss: 0.0590 - val_rmse: 0.2018 - val_mse: 0.0407 - val_mae: 0.1690 - 37ms/epoch - 2ms/step\n",
      "Epoch 59/5000\n",
      "15/15 - 0s - loss: 0.0478 - rmse: 0.1729 - mse: 0.0299 - mae: 0.1408 - val_loss: 0.0584 - val_rmse: 0.2027 - val_mse: 0.0411 - val_mae: 0.1688 - 38ms/epoch - 3ms/step\n",
      "Epoch 60/5000\n",
      "\n",
      "Epoch 60: val_loss improved from 0.07331 to 0.05862, saving model to data/output/activity_single-labeled_Fold-2.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0464 - rmse: 0.1720 - mse: 0.0296 - mae: 0.1397 - val_loss: 0.0586 - val_rmse: 0.2059 - val_mse: 0.0424 - val_mae: 0.1684 - 39ms/epoch - 3ms/step\n",
      "Epoch 61/5000\n",
      "15/15 - 0s - loss: 0.0460 - rmse: 0.1737 - mse: 0.0302 - mae: 0.1424 - val_loss: 0.0570 - val_rmse: 0.2040 - val_mse: 0.0416 - val_mae: 0.1670 - 33ms/epoch - 2ms/step\n",
      "Epoch 62/5000\n",
      "15/15 - 0s - loss: 0.0449 - rmse: 0.1727 - mse: 0.0298 - mae: 0.1404 - val_loss: 0.0553 - val_rmse: 0.2014 - val_mse: 0.0406 - val_mae: 0.1665 - 37ms/epoch - 2ms/step\n",
      "Epoch 63/5000\n",
      "15/15 - 0s - loss: 0.0445 - rmse: 0.1737 - mse: 0.0302 - mae: 0.1404 - val_loss: 0.0560 - val_rmse: 0.2053 - val_mse: 0.0421 - val_mae: 0.1718 - 43ms/epoch - 3ms/step\n",
      "Epoch 64/5000\n",
      "15/15 - 0s - loss: 0.0438 - rmse: 0.1735 - mse: 0.0301 - mae: 0.1416 - val_loss: 0.0540 - val_rmse: 0.2015 - val_mse: 0.0406 - val_mae: 0.1670 - 38ms/epoch - 3ms/step\n",
      "Epoch 65/5000\n",
      "15/15 - 0s - loss: 0.0425 - rmse: 0.1714 - mse: 0.0294 - mae: 0.1399 - val_loss: 0.0536 - val_rmse: 0.2021 - val_mse: 0.0408 - val_mae: 0.1652 - 51ms/epoch - 3ms/step\n",
      "Epoch 66/5000\n",
      "15/15 - 0s - loss: 0.0426 - rmse: 0.1737 - mse: 0.0302 - mae: 0.1434 - val_loss: 0.0528 - val_rmse: 0.2018 - val_mse: 0.0407 - val_mae: 0.1698 - 64ms/epoch - 4ms/step\n",
      "Epoch 67/5000\n",
      "15/15 - 0s - loss: 0.0415 - rmse: 0.1719 - mse: 0.0295 - mae: 0.1398 - val_loss: 0.0526 - val_rmse: 0.2021 - val_mse: 0.0409 - val_mae: 0.1687 - 43ms/epoch - 3ms/step\n",
      "Epoch 68/5000\n",
      "15/15 - 0s - loss: 0.0411 - rmse: 0.1715 - mse: 0.0294 - mae: 0.1409 - val_loss: 0.0537 - val_rmse: 0.2055 - val_mse: 0.0422 - val_mae: 0.1674 - 44ms/epoch - 3ms/step\n",
      "Epoch 69/5000\n",
      "15/15 - 0s - loss: 0.0411 - rmse: 0.1726 - mse: 0.0298 - mae: 0.1412 - val_loss: 0.0541 - val_rmse: 0.2075 - val_mse: 0.0430 - val_mae: 0.1683 - 35ms/epoch - 2ms/step\n",
      "Epoch 70/5000\n",
      "\n",
      "Epoch 70: val_loss improved from 0.05862 to 0.05157, saving model to data/output/activity_single-labeled_Fold-2.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0407 - rmse: 0.1727 - mse: 0.0298 - mae: 0.1409 - val_loss: 0.0516 - val_rmse: 0.2022 - val_mse: 0.0409 - val_mae: 0.1665 - 43ms/epoch - 3ms/step\n",
      "Epoch 71/5000\n",
      "15/15 - 0s - loss: 0.0399 - rmse: 0.1714 - mse: 0.0294 - mae: 0.1405 - val_loss: 0.0513 - val_rmse: 0.2024 - val_mse: 0.0410 - val_mae: 0.1681 - 37ms/epoch - 2ms/step\n",
      "Epoch 72/5000\n",
      "15/15 - 0s - loss: 0.0394 - rmse: 0.1704 - mse: 0.0291 - mae: 0.1385 - val_loss: 0.0508 - val_rmse: 0.2014 - val_mse: 0.0406 - val_mae: 0.1653 - 38ms/epoch - 3ms/step\n",
      "Epoch 73/5000\n",
      "15/15 - 0s - loss: 0.0395 - rmse: 0.1718 - mse: 0.0295 - mae: 0.1393 - val_loss: 0.0506 - val_rmse: 0.2019 - val_mse: 0.0408 - val_mae: 0.1681 - 36ms/epoch - 2ms/step\n",
      "Epoch 74/5000\n",
      "15/15 - 0s - loss: 0.0388 - rmse: 0.1703 - mse: 0.0290 - mae: 0.1391 - val_loss: 0.0509 - val_rmse: 0.2030 - val_mse: 0.0412 - val_mae: 0.1678 - 34ms/epoch - 2ms/step\n",
      "Epoch 75/5000\n",
      "15/15 - 0s - loss: 0.0384 - rmse: 0.1696 - mse: 0.0288 - mae: 0.1379 - val_loss: 0.0504 - val_rmse: 0.2021 - val_mse: 0.0408 - val_mae: 0.1663 - 34ms/epoch - 2ms/step\n",
      "Epoch 76/5000\n",
      "15/15 - 0s - loss: 0.0382 - rmse: 0.1693 - mse: 0.0287 - mae: 0.1380 - val_loss: 0.0509 - val_rmse: 0.2039 - val_mse: 0.0416 - val_mae: 0.1688 - 38ms/epoch - 3ms/step\n",
      "Epoch 77/5000\n",
      "15/15 - 0s - loss: 0.0382 - rmse: 0.1703 - mse: 0.0290 - mae: 0.1399 - val_loss: 0.0503 - val_rmse: 0.2028 - val_mse: 0.0411 - val_mae: 0.1690 - 28ms/epoch - 2ms/step\n",
      "Epoch 78/5000\n",
      "15/15 - 0s - loss: 0.0383 - rmse: 0.1707 - mse: 0.0291 - mae: 0.1398 - val_loss: 0.0503 - val_rmse: 0.2033 - val_mse: 0.0413 - val_mae: 0.1687 - 26ms/epoch - 2ms/step\n",
      "Epoch 79/5000\n",
      "15/15 - 0s - loss: 0.0378 - rmse: 0.1698 - mse: 0.0288 - mae: 0.1381 - val_loss: 0.0502 - val_rmse: 0.2032 - val_mse: 0.0413 - val_mae: 0.1669 - 28ms/epoch - 2ms/step\n",
      "Epoch 80/5000\n",
      "\n",
      "Epoch 80: val_loss improved from 0.05157 to 0.04949, saving model to data/output/activity_single-labeled_Fold-2.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0374 - rmse: 0.1689 - mse: 0.0285 - mae: 0.1384 - val_loss: 0.0495 - val_rmse: 0.2016 - val_mse: 0.0407 - val_mae: 0.1659 - 32ms/epoch - 2ms/step\n",
      "Epoch 81/5000\n",
      "15/15 - 0s - loss: 0.0379 - rmse: 0.1704 - mse: 0.0290 - mae: 0.1390 - val_loss: 0.0498 - val_rmse: 0.2026 - val_mse: 0.0410 - val_mae: 0.1674 - 32ms/epoch - 2ms/step\n",
      "Epoch 82/5000\n",
      "15/15 - 0s - loss: 0.0373 - rmse: 0.1693 - mse: 0.0287 - mae: 0.1390 - val_loss: 0.0499 - val_rmse: 0.2033 - val_mse: 0.0413 - val_mae: 0.1669 - 36ms/epoch - 2ms/step\n",
      "Epoch 83/5000\n",
      "15/15 - 0s - loss: 0.0374 - rmse: 0.1697 - mse: 0.0288 - mae: 0.1385 - val_loss: 0.0497 - val_rmse: 0.2027 - val_mse: 0.0411 - val_mae: 0.1656 - 34ms/epoch - 2ms/step\n",
      "Epoch 84/5000\n",
      "15/15 - 0s - loss: 0.0372 - rmse: 0.1690 - mse: 0.0286 - mae: 0.1377 - val_loss: 0.0496 - val_rmse: 0.2025 - val_mse: 0.0410 - val_mae: 0.1659 - 41ms/epoch - 3ms/step\n",
      "Epoch 85/5000\n",
      "15/15 - 0s - loss: 0.0369 - rmse: 0.1686 - mse: 0.0284 - mae: 0.1371 - val_loss: 0.0502 - val_rmse: 0.2044 - val_mse: 0.0418 - val_mae: 0.1698 - 44ms/epoch - 3ms/step\n",
      "Epoch 86/5000\n",
      "15/15 - 0s - loss: 0.0374 - rmse: 0.1703 - mse: 0.0290 - mae: 0.1389 - val_loss: 0.0495 - val_rmse: 0.2027 - val_mse: 0.0411 - val_mae: 0.1672 - 44ms/epoch - 3ms/step\n",
      "Epoch 87/5000\n",
      "15/15 - 0s - loss: 0.0371 - rmse: 0.1695 - mse: 0.0287 - mae: 0.1380 - val_loss: 0.0492 - val_rmse: 0.2022 - val_mse: 0.0409 - val_mae: 0.1675 - 46ms/epoch - 3ms/step\n",
      "Epoch 88/5000\n",
      "15/15 - 0s - loss: 0.0369 - rmse: 0.1692 - mse: 0.0286 - mae: 0.1390 - val_loss: 0.0494 - val_rmse: 0.2029 - val_mse: 0.0412 - val_mae: 0.1661 - 52ms/epoch - 3ms/step\n",
      "Epoch 89/5000\n",
      "15/15 - 0s - loss: 0.0367 - rmse: 0.1688 - mse: 0.0285 - mae: 0.1374 - val_loss: 0.0497 - val_rmse: 0.2035 - val_mse: 0.0414 - val_mae: 0.1669 - 39ms/epoch - 3ms/step\n",
      "Epoch 90/5000\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.04949\n",
      "15/15 - 0s - loss: 0.0371 - rmse: 0.1701 - mse: 0.0289 - mae: 0.1383 - val_loss: 0.0496 - val_rmse: 0.2037 - val_mse: 0.0415 - val_mae: 0.1685 - 39ms/epoch - 3ms/step\n",
      "Epoch 91/5000\n",
      "15/15 - 0s - loss: 0.0368 - rmse: 0.1693 - mse: 0.0287 - mae: 0.1379 - val_loss: 0.0489 - val_rmse: 0.2021 - val_mse: 0.0408 - val_mae: 0.1661 - 37ms/epoch - 2ms/step\n",
      "Epoch 92/5000\n",
      "15/15 - 0s - loss: 0.0367 - rmse: 0.1691 - mse: 0.0286 - mae: 0.1376 - val_loss: 0.0496 - val_rmse: 0.2038 - val_mse: 0.0415 - val_mae: 0.1685 - 38ms/epoch - 3ms/step\n",
      "Epoch 93/5000\n",
      "15/15 - 0s - loss: 0.0366 - rmse: 0.1688 - mse: 0.0285 - mae: 0.1368 - val_loss: 0.0489 - val_rmse: 0.2021 - val_mse: 0.0408 - val_mae: 0.1665 - 56ms/epoch - 4ms/step\n",
      "Epoch 94/5000\n",
      "15/15 - 0s - loss: 0.0366 - rmse: 0.1690 - mse: 0.0286 - mae: 0.1383 - val_loss: 0.0493 - val_rmse: 0.2033 - val_mse: 0.0413 - val_mae: 0.1657 - 47ms/epoch - 3ms/step\n",
      "Epoch 95/5000\n",
      "15/15 - 0s - loss: 0.0364 - rmse: 0.1688 - mse: 0.0285 - mae: 0.1380 - val_loss: 0.0493 - val_rmse: 0.2033 - val_mse: 0.0413 - val_mae: 0.1679 - 34ms/epoch - 2ms/step\n",
      "Epoch 96/5000\n",
      "15/15 - 0s - loss: 0.0368 - rmse: 0.1694 - mse: 0.0287 - mae: 0.1378 - val_loss: 0.0492 - val_rmse: 0.2026 - val_mse: 0.0411 - val_mae: 0.1648 - 32ms/epoch - 2ms/step\n",
      "Epoch 97/5000\n",
      "15/15 - 0s - loss: 0.0360 - rmse: 0.1671 - mse: 0.0279 - mae: 0.1359 - val_loss: 0.0494 - val_rmse: 0.2033 - val_mse: 0.0413 - val_mae: 0.1675 - 33ms/epoch - 2ms/step\n",
      "Epoch 98/5000\n",
      "15/15 - 0s - loss: 0.0362 - rmse: 0.1680 - mse: 0.0282 - mae: 0.1371 - val_loss: 0.0498 - val_rmse: 0.2046 - val_mse: 0.0419 - val_mae: 0.1677 - 35ms/epoch - 2ms/step\n",
      "Epoch 99/5000\n",
      "15/15 - 0s - loss: 0.0372 - rmse: 0.1710 - mse: 0.0292 - mae: 0.1391 - val_loss: 0.0500 - val_rmse: 0.2049 - val_mse: 0.0420 - val_mae: 0.1697 - 32ms/epoch - 2ms/step\n",
      "Epoch 100/5000\n",
      "\n",
      "Epoch 100: val_loss improved from 0.04949 to 0.04923, saving model to data/output/activity_single-labeled_Fold-2.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0372 - rmse: 0.1711 - mse: 0.0293 - mae: 0.1405 - val_loss: 0.0492 - val_rmse: 0.2031 - val_mse: 0.0412 - val_mae: 0.1676 - 36ms/epoch - 2ms/step\n",
      "Epoch 101/5000\n",
      "15/15 - 0s - loss: 0.0361 - rmse: 0.1675 - mse: 0.0281 - mae: 0.1353 - val_loss: 0.0487 - val_rmse: 0.2019 - val_mse: 0.0407 - val_mae: 0.1645 - 31ms/epoch - 2ms/step\n",
      "Epoch 102/5000\n",
      "15/15 - 0s - loss: 0.0364 - rmse: 0.1691 - mse: 0.0286 - mae: 0.1383 - val_loss: 0.0495 - val_rmse: 0.2040 - val_mse: 0.0416 - val_mae: 0.1687 - 35ms/epoch - 2ms/step\n",
      "Epoch 103/5000\n",
      "15/15 - 0s - loss: 0.0373 - rmse: 0.1715 - mse: 0.0294 - mae: 0.1397 - val_loss: 0.0498 - val_rmse: 0.2048 - val_mse: 0.0419 - val_mae: 0.1689 - 41ms/epoch - 3ms/step\n",
      "Epoch 104/5000\n",
      "15/15 - 0s - loss: 0.0368 - rmse: 0.1699 - mse: 0.0289 - mae: 0.1375 - val_loss: 0.0494 - val_rmse: 0.2037 - val_mse: 0.0415 - val_mae: 0.1664 - 29ms/epoch - 2ms/step\n",
      "Epoch 105/5000\n",
      "15/15 - 0s - loss: 0.0367 - rmse: 0.1695 - mse: 0.0287 - mae: 0.1375 - val_loss: 0.0501 - val_rmse: 0.2052 - val_mse: 0.0421 - val_mae: 0.1685 - 31ms/epoch - 2ms/step\n",
      "Epoch 106/5000\n",
      "15/15 - 0s - loss: 0.0362 - rmse: 0.1683 - mse: 0.0283 - mae: 0.1375 - val_loss: 0.0489 - val_rmse: 0.2026 - val_mse: 0.0411 - val_mae: 0.1672 - 31ms/epoch - 2ms/step\n",
      "Epoch 107/5000\n",
      "15/15 - 0s - loss: 0.0357 - rmse: 0.1671 - mse: 0.0279 - mae: 0.1365 - val_loss: 0.0493 - val_rmse: 0.2035 - val_mse: 0.0414 - val_mae: 0.1674 - 31ms/epoch - 2ms/step\n",
      "Epoch 108/5000\n",
      "15/15 - 0s - loss: 0.0357 - rmse: 0.1666 - mse: 0.0278 - mae: 0.1358 - val_loss: 0.0493 - val_rmse: 0.2033 - val_mse: 0.0413 - val_mae: 0.1655 - 34ms/epoch - 2ms/step\n",
      "Epoch 109/5000\n",
      "15/15 - 0s - loss: 0.0358 - rmse: 0.1668 - mse: 0.0278 - mae: 0.1353 - val_loss: 0.0497 - val_rmse: 0.2044 - val_mse: 0.0418 - val_mae: 0.1678 - 32ms/epoch - 2ms/step\n",
      "Epoch 110/5000\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.04923\n",
      "15/15 - 0s - loss: 0.0362 - rmse: 0.1682 - mse: 0.0283 - mae: 0.1372 - val_loss: 0.0501 - val_rmse: 0.2054 - val_mse: 0.0422 - val_mae: 0.1686 - 31ms/epoch - 2ms/step\n",
      "Epoch 111/5000\n",
      "15/15 - 0s - loss: 0.0356 - rmse: 0.1661 - mse: 0.0276 - mae: 0.1344 - val_loss: 0.0493 - val_rmse: 0.2033 - val_mse: 0.0413 - val_mae: 0.1665 - 32ms/epoch - 2ms/step\n",
      "Epoch 112/5000\n",
      "15/15 - 0s - loss: 0.0357 - rmse: 0.1667 - mse: 0.0278 - mae: 0.1359 - val_loss: 0.0494 - val_rmse: 0.2038 - val_mse: 0.0415 - val_mae: 0.1662 - 31ms/epoch - 2ms/step\n",
      "Epoch 113/5000\n",
      "15/15 - 0s - loss: 0.0355 - rmse: 0.1663 - mse: 0.0276 - mae: 0.1346 - val_loss: 0.0503 - val_rmse: 0.2058 - val_mse: 0.0423 - val_mae: 0.1676 - 38ms/epoch - 3ms/step\n",
      "Epoch 114/5000\n",
      "15/15 - 0s - loss: 0.0357 - rmse: 0.1667 - mse: 0.0278 - mae: 0.1348 - val_loss: 0.0534 - val_rmse: 0.2131 - val_mse: 0.0454 - val_mae: 0.1744 - 36ms/epoch - 2ms/step\n",
      "Epoch 115/5000\n",
      "15/15 - 0s - loss: 0.0367 - rmse: 0.1697 - mse: 0.0288 - mae: 0.1381 - val_loss: 0.0526 - val_rmse: 0.2112 - val_mse: 0.0446 - val_mae: 0.1722 - 31ms/epoch - 2ms/step\n",
      "Epoch 116/5000\n",
      "15/15 - 0s - loss: 0.0368 - rmse: 0.1699 - mse: 0.0289 - mae: 0.1387 - val_loss: 0.0488 - val_rmse: 0.2023 - val_mse: 0.0409 - val_mae: 0.1667 - 33ms/epoch - 2ms/step\n",
      "Epoch 117/5000\n",
      "15/15 - 0s - loss: 0.0360 - rmse: 0.1677 - mse: 0.0281 - mae: 0.1367 - val_loss: 0.0494 - val_rmse: 0.2038 - val_mse: 0.0416 - val_mae: 0.1656 - 37ms/epoch - 2ms/step\n",
      "Epoch 118/5000\n",
      "15/15 - 0s - loss: 0.0354 - rmse: 0.1660 - mse: 0.0275 - mae: 0.1346 - val_loss: 0.0495 - val_rmse: 0.2041 - val_mse: 0.0416 - val_mae: 0.1653 - 37ms/epoch - 2ms/step\n",
      "Epoch 119/5000\n",
      "15/15 - 0s - loss: 0.0357 - rmse: 0.1668 - mse: 0.0278 - mae: 0.1350 - val_loss: 0.0495 - val_rmse: 0.2041 - val_mse: 0.0416 - val_mae: 0.1668 - 32ms/epoch - 2ms/step\n",
      "Epoch 120/5000\n",
      "\n",
      "Epoch 120: val_loss improved from 0.04923 to 0.04902, saving model to data/output/activity_single-labeled_Fold-2.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0356 - rmse: 0.1668 - mse: 0.0278 - mae: 0.1355 - val_loss: 0.0490 - val_rmse: 0.2030 - val_mse: 0.0412 - val_mae: 0.1671 - 36ms/epoch - 2ms/step\n",
      "Epoch 121/5000\n",
      "Restoring model weights from the end of the best epoch: 101.\n",
      "15/15 - 0s - loss: 0.0358 - rmse: 0.1673 - mse: 0.0280 - mae: 0.1360 - val_loss: 0.0504 - val_rmse: 0.2064 - val_mse: 0.0426 - val_mae: 0.1681 - 31ms/epoch - 2ms/step\n",
      "Epoch 121: early stopping\n",
      "7/7 [==============================] - 0s 849us/step\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hertelj/git-hertelj/deepFPlearn/dfpl/single_label_model.py:350: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  np.mean(abs_error / np.array(y_test), axis=0),\n",
      "/home/hertelj/build/local/miniforge3/envs/dfpl/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "15/15 - 0s - loss: 4.4929 - rmse: 0.6208 - mse: 0.3854 - mae: 0.4704 - val_loss: 4.0764 - val_rmse: 0.3304 - val_mse: 0.1092 - val_mae: 0.2638 - 236ms/epoch - 16ms/step\n",
      "Epoch 2/5000\n",
      "15/15 - 0s - loss: 3.8986 - rmse: 0.2884 - mse: 0.0832 - mae: 0.2341 - val_loss: 3.6703 - val_rmse: 0.2190 - val_mse: 0.0480 - val_mae: 0.1723 - 47ms/epoch - 3ms/step\n",
      "Epoch 3/5000\n",
      "15/15 - 0s - loss: 3.5149 - rmse: 0.2246 - mse: 0.0505 - mae: 0.1868 - val_loss: 3.3169 - val_rmse: 0.2045 - val_mse: 0.0418 - val_mae: 0.1576 - 31ms/epoch - 2ms/step\n",
      "Epoch 4/5000\n",
      "15/15 - 0s - loss: 3.1731 - rmse: 0.2111 - mse: 0.0446 - mae: 0.1726 - val_loss: 2.9918 - val_rmse: 0.1924 - val_mse: 0.0370 - val_mae: 0.1500 - 42ms/epoch - 3ms/step\n",
      "Epoch 5/5000\n",
      "15/15 - 0s - loss: 2.8647 - rmse: 0.2071 - mse: 0.0429 - mae: 0.1720 - val_loss: 2.7013 - val_rmse: 0.1921 - val_mse: 0.0369 - val_mae: 0.1496 - 37ms/epoch - 2ms/step\n",
      "Epoch 6/5000\n",
      "15/15 - 0s - loss: 2.5859 - rmse: 0.2038 - mse: 0.0415 - mae: 0.1673 - val_loss: 2.4362 - val_rmse: 0.1837 - val_mse: 0.0337 - val_mae: 0.1460 - 38ms/epoch - 3ms/step\n",
      "Epoch 7/5000\n",
      "15/15 - 0s - loss: 2.3349 - rmse: 0.2018 - mse: 0.0407 - mae: 0.1666 - val_loss: 2.1984 - val_rmse: 0.1795 - val_mse: 0.0322 - val_mae: 0.1427 - 37ms/epoch - 2ms/step\n",
      "Epoch 8/5000\n",
      "15/15 - 0s - loss: 2.1091 - rmse: 0.2012 - mse: 0.0405 - mae: 0.1657 - val_loss: 1.9845 - val_rmse: 0.1766 - val_mse: 0.0312 - val_mae: 0.1420 - 47ms/epoch - 3ms/step\n",
      "Epoch 9/5000\n",
      "15/15 - 0s - loss: 1.9027 - rmse: 0.1932 - mse: 0.0373 - mae: 0.1579 - val_loss: 1.7927 - val_rmse: 0.1770 - val_mse: 0.0313 - val_mae: 0.1435 - 47ms/epoch - 3ms/step\n",
      "Epoch 10/5000\n",
      "\n",
      "Epoch 10: val_loss improved from inf to 1.61987, saving model to data/output/activity_single-labeled_Fold-3.model.weights.hdf5\n",
      "15/15 - 0s - loss: 1.7194 - rmse: 0.1931 - mse: 0.0373 - mae: 0.1587 - val_loss: 1.6199 - val_rmse: 0.1773 - val_mse: 0.0314 - val_mae: 0.1419 - 51ms/epoch - 3ms/step\n",
      "Epoch 11/5000\n",
      "15/15 - 0s - loss: 1.5548 - rmse: 0.1945 - mse: 0.0378 - mae: 0.1600 - val_loss: 1.4637 - val_rmse: 0.1763 - val_mse: 0.0311 - val_mae: 0.1431 - 40ms/epoch - 3ms/step\n",
      "Epoch 12/5000\n",
      "15/15 - 0s - loss: 1.4054 - rmse: 0.1928 - mse: 0.0372 - mae: 0.1583 - val_loss: 1.3233 - val_rmse: 0.1765 - val_mse: 0.0312 - val_mae: 0.1422 - 40ms/epoch - 3ms/step\n",
      "Epoch 13/5000\n",
      "15/15 - 0s - loss: 1.2705 - rmse: 0.1909 - mse: 0.0364 - mae: 0.1584 - val_loss: 1.1968 - val_rmse: 0.1770 - val_mse: 0.0313 - val_mae: 0.1424 - 40ms/epoch - 3ms/step\n",
      "Epoch 14/5000\n",
      "15/15 - 0s - loss: 1.1498 - rmse: 0.1919 - mse: 0.0368 - mae: 0.1589 - val_loss: 1.0820 - val_rmse: 0.1756 - val_mse: 0.0308 - val_mae: 0.1417 - 40ms/epoch - 3ms/step\n",
      "Epoch 15/5000\n",
      "15/15 - 0s - loss: 1.0404 - rmse: 0.1907 - mse: 0.0364 - mae: 0.1568 - val_loss: 0.9789 - val_rmse: 0.1751 - val_mse: 0.0307 - val_mae: 0.1415 - 42ms/epoch - 3ms/step\n",
      "Epoch 16/5000\n",
      "15/15 - 0s - loss: 0.9418 - rmse: 0.1897 - mse: 0.0360 - mae: 0.1560 - val_loss: 0.8866 - val_rmse: 0.1762 - val_mse: 0.0310 - val_mae: 0.1411 - 37ms/epoch - 2ms/step\n",
      "Epoch 17/5000\n",
      "15/15 - 0s - loss: 0.8535 - rmse: 0.1905 - mse: 0.0363 - mae: 0.1566 - val_loss: 0.8035 - val_rmse: 0.1778 - val_mse: 0.0316 - val_mae: 0.1421 - 38ms/epoch - 3ms/step\n",
      "Epoch 18/5000\n",
      "15/15 - 0s - loss: 0.7731 - rmse: 0.1895 - mse: 0.0359 - mae: 0.1563 - val_loss: 0.7278 - val_rmse: 0.1774 - val_mse: 0.0315 - val_mae: 0.1445 - 44ms/epoch - 3ms/step\n",
      "Epoch 19/5000\n",
      "15/15 - 0s - loss: 0.7009 - rmse: 0.1889 - mse: 0.0357 - mae: 0.1571 - val_loss: 0.6598 - val_rmse: 0.1770 - val_mse: 0.0313 - val_mae: 0.1427 - 40ms/epoch - 3ms/step\n",
      "Epoch 20/5000\n",
      "\n",
      "Epoch 20: val_loss improved from 1.61987 to 0.59913, saving model to data/output/activity_single-labeled_Fold-3.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.6364 - rmse: 0.1900 - mse: 0.0361 - mae: 0.1561 - val_loss: 0.5991 - val_rmse: 0.1793 - val_mse: 0.0321 - val_mae: 0.1481 - 45ms/epoch - 3ms/step\n",
      "Epoch 21/5000\n",
      "15/15 - 0s - loss: 0.5787 - rmse: 0.1924 - mse: 0.0370 - mae: 0.1592 - val_loss: 0.5427 - val_rmse: 0.1757 - val_mse: 0.0309 - val_mae: 0.1420 - 42ms/epoch - 3ms/step\n",
      "Epoch 22/5000\n",
      "15/15 - 0s - loss: 0.5252 - rmse: 0.1903 - mse: 0.0362 - mae: 0.1585 - val_loss: 0.4927 - val_rmse: 0.1753 - val_mse: 0.0307 - val_mae: 0.1433 - 47ms/epoch - 3ms/step\n",
      "Epoch 23/5000\n",
      "15/15 - 0s - loss: 0.4778 - rmse: 0.1907 - mse: 0.0364 - mae: 0.1569 - val_loss: 0.4478 - val_rmse: 0.1754 - val_mse: 0.0308 - val_mae: 0.1437 - 38ms/epoch - 3ms/step\n",
      "Epoch 24/5000\n",
      "15/15 - 0s - loss: 0.4340 - rmse: 0.1883 - mse: 0.0355 - mae: 0.1569 - val_loss: 0.4077 - val_rmse: 0.1762 - val_mse: 0.0311 - val_mae: 0.1412 - 38ms/epoch - 3ms/step\n",
      "Epoch 25/5000\n",
      "15/15 - 0s - loss: 0.3958 - rmse: 0.1896 - mse: 0.0360 - mae: 0.1557 - val_loss: 0.3709 - val_rmse: 0.1757 - val_mse: 0.0309 - val_mae: 0.1435 - 39ms/epoch - 3ms/step\n",
      "Epoch 26/5000\n",
      "15/15 - 0s - loss: 0.3606 - rmse: 0.1888 - mse: 0.0356 - mae: 0.1585 - val_loss: 0.3382 - val_rmse: 0.1761 - val_mse: 0.0310 - val_mae: 0.1411 - 41ms/epoch - 3ms/step\n",
      "Epoch 27/5000\n",
      "15/15 - 0s - loss: 0.3298 - rmse: 0.1903 - mse: 0.0362 - mae: 0.1583 - val_loss: 0.3094 - val_rmse: 0.1785 - val_mse: 0.0319 - val_mae: 0.1482 - 41ms/epoch - 3ms/step\n",
      "Epoch 28/5000\n",
      "15/15 - 0s - loss: 0.3008 - rmse: 0.1882 - mse: 0.0354 - mae: 0.1567 - val_loss: 0.2817 - val_rmse: 0.1755 - val_mse: 0.0308 - val_mae: 0.1430 - 42ms/epoch - 3ms/step\n",
      "Epoch 29/5000\n",
      "15/15 - 0s - loss: 0.2748 - rmse: 0.1865 - mse: 0.0348 - mae: 0.1542 - val_loss: 0.2577 - val_rmse: 0.1753 - val_mse: 0.0307 - val_mae: 0.1422 - 40ms/epoch - 3ms/step\n",
      "Epoch 30/5000\n",
      "\n",
      "Epoch 30: val_loss improved from 0.59913 to 0.23623, saving model to data/output/activity_single-labeled_Fold-3.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.2514 - rmse: 0.1854 - mse: 0.0344 - mae: 0.1523 - val_loss: 0.2362 - val_rmse: 0.1761 - val_mse: 0.0310 - val_mae: 0.1419 - 46ms/epoch - 3ms/step\n",
      "Epoch 31/5000\n",
      "15/15 - 0s - loss: 0.2315 - rmse: 0.1881 - mse: 0.0354 - mae: 0.1562 - val_loss: 0.2163 - val_rmse: 0.1754 - val_mse: 0.0308 - val_mae: 0.1432 - 37ms/epoch - 2ms/step\n",
      "Epoch 32/5000\n",
      "15/15 - 0s - loss: 0.2118 - rmse: 0.1851 - mse: 0.0343 - mae: 0.1549 - val_loss: 0.1987 - val_rmse: 0.1750 - val_mse: 0.0306 - val_mae: 0.1430 - 37ms/epoch - 2ms/step\n",
      "Epoch 33/5000\n",
      "15/15 - 0s - loss: 0.1949 - rmse: 0.1845 - mse: 0.0341 - mae: 0.1520 - val_loss: 0.1827 - val_rmse: 0.1745 - val_mse: 0.0304 - val_mae: 0.1426 - 40ms/epoch - 3ms/step\n",
      "Epoch 34/5000\n",
      "15/15 - 0s - loss: 0.1804 - rmse: 0.1862 - mse: 0.0347 - mae: 0.1532 - val_loss: 0.1683 - val_rmse: 0.1746 - val_mse: 0.0305 - val_mae: 0.1421 - 51ms/epoch - 3ms/step\n",
      "Epoch 35/5000\n",
      "15/15 - 0s - loss: 0.1665 - rmse: 0.1861 - mse: 0.0346 - mae: 0.1547 - val_loss: 0.1551 - val_rmse: 0.1740 - val_mse: 0.0303 - val_mae: 0.1412 - 50ms/epoch - 3ms/step\n",
      "Epoch 36/5000\n",
      "15/15 - 0s - loss: 0.1547 - rmse: 0.1875 - mse: 0.0352 - mae: 0.1557 - val_loss: 0.1440 - val_rmse: 0.1751 - val_mse: 0.0307 - val_mae: 0.1421 - 35ms/epoch - 2ms/step\n",
      "Epoch 37/5000\n",
      "15/15 - 0s - loss: 0.1427 - rmse: 0.1847 - mse: 0.0341 - mae: 0.1540 - val_loss: 0.1335 - val_rmse: 0.1752 - val_mse: 0.0307 - val_mae: 0.1420 - 34ms/epoch - 2ms/step\n",
      "Epoch 38/5000\n",
      "15/15 - 0s - loss: 0.1330 - rmse: 0.1855 - mse: 0.0344 - mae: 0.1532 - val_loss: 0.1238 - val_rmse: 0.1741 - val_mse: 0.0303 - val_mae: 0.1425 - 38ms/epoch - 3ms/step\n",
      "Epoch 39/5000\n",
      "15/15 - 0s - loss: 0.1240 - rmse: 0.1855 - mse: 0.0344 - mae: 0.1533 - val_loss: 0.1156 - val_rmse: 0.1753 - val_mse: 0.0307 - val_mae: 0.1451 - 35ms/epoch - 2ms/step\n",
      "Epoch 40/5000\n",
      "\n",
      "Epoch 40: val_loss improved from 0.23623 to 0.10768, saving model to data/output/activity_single-labeled_Fold-3.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.1163 - rmse: 0.1868 - mse: 0.0349 - mae: 0.1550 - val_loss: 0.1077 - val_rmse: 0.1743 - val_mse: 0.0304 - val_mae: 0.1415 - 41ms/epoch - 3ms/step\n",
      "Epoch 41/5000\n",
      "15/15 - 0s - loss: 0.1080 - rmse: 0.1839 - mse: 0.0338 - mae: 0.1525 - val_loss: 0.1011 - val_rmse: 0.1752 - val_mse: 0.0307 - val_mae: 0.1411 - 36ms/epoch - 2ms/step\n",
      "Epoch 42/5000\n",
      "15/15 - 0s - loss: 0.1016 - rmse: 0.1844 - mse: 0.0340 - mae: 0.1515 - val_loss: 0.0949 - val_rmse: 0.1755 - val_mse: 0.0308 - val_mae: 0.1460 - 34ms/epoch - 2ms/step\n",
      "Epoch 43/5000\n",
      "15/15 - 0s - loss: 0.0954 - rmse: 0.1839 - mse: 0.0338 - mae: 0.1518 - val_loss: 0.0891 - val_rmse: 0.1747 - val_mse: 0.0305 - val_mae: 0.1409 - 39ms/epoch - 3ms/step\n",
      "Epoch 44/5000\n",
      "15/15 - 0s - loss: 0.0905 - rmse: 0.1852 - mse: 0.0343 - mae: 0.1536 - val_loss: 0.0852 - val_rmse: 0.1779 - val_mse: 0.0317 - val_mae: 0.1415 - 36ms/epoch - 2ms/step\n",
      "Epoch 45/5000\n",
      "15/15 - 0s - loss: 0.0855 - rmse: 0.1848 - mse: 0.0341 - mae: 0.1532 - val_loss: 0.0795 - val_rmse: 0.1752 - val_mse: 0.0307 - val_mae: 0.1450 - 43ms/epoch - 3ms/step\n",
      "Epoch 46/5000\n",
      "15/15 - 0s - loss: 0.0808 - rmse: 0.1839 - mse: 0.0338 - mae: 0.1514 - val_loss: 0.0749 - val_rmse: 0.1736 - val_mse: 0.0301 - val_mae: 0.1413 - 48ms/epoch - 3ms/step\n",
      "Epoch 47/5000\n",
      "15/15 - 0s - loss: 0.0769 - rmse: 0.1838 - mse: 0.0338 - mae: 0.1521 - val_loss: 0.0726 - val_rmse: 0.1775 - val_mse: 0.0315 - val_mae: 0.1410 - 39ms/epoch - 3ms/step\n",
      "Epoch 48/5000\n",
      "15/15 - 0s - loss: 0.0734 - rmse: 0.1840 - mse: 0.0339 - mae: 0.1521 - val_loss: 0.0684 - val_rmse: 0.1748 - val_mse: 0.0306 - val_mae: 0.1450 - 38ms/epoch - 3ms/step\n",
      "Epoch 49/5000\n",
      "15/15 - 0s - loss: 0.0701 - rmse: 0.1835 - mse: 0.0337 - mae: 0.1510 - val_loss: 0.0645 - val_rmse: 0.1721 - val_mse: 0.0296 - val_mae: 0.1413 - 43ms/epoch - 3ms/step\n",
      "Epoch 50/5000\n",
      "\n",
      "Epoch 50: val_loss improved from 0.10768 to 0.06243, saving model to data/output/activity_single-labeled_Fold-3.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0671 - rmse: 0.1834 - mse: 0.0336 - mae: 0.1519 - val_loss: 0.0624 - val_rmse: 0.1744 - val_mse: 0.0304 - val_mae: 0.1444 - 47ms/epoch - 3ms/step\n",
      "Epoch 51/5000\n",
      "15/15 - 0s - loss: 0.0641 - rmse: 0.1820 - mse: 0.0331 - mae: 0.1497 - val_loss: 0.0596 - val_rmse: 0.1731 - val_mse: 0.0300 - val_mae: 0.1392 - 40ms/epoch - 3ms/step\n",
      "Epoch 52/5000\n",
      "15/15 - 0s - loss: 0.0617 - rmse: 0.1817 - mse: 0.0330 - mae: 0.1504 - val_loss: 0.0576 - val_rmse: 0.1737 - val_mse: 0.0302 - val_mae: 0.1409 - 38ms/epoch - 3ms/step\n",
      "Epoch 53/5000\n",
      "15/15 - 0s - loss: 0.0599 - rmse: 0.1828 - mse: 0.0334 - mae: 0.1512 - val_loss: 0.0558 - val_rmse: 0.1744 - val_mse: 0.0304 - val_mae: 0.1437 - 40ms/epoch - 3ms/step\n",
      "Epoch 54/5000\n",
      "15/15 - 0s - loss: 0.0581 - rmse: 0.1827 - mse: 0.0334 - mae: 0.1509 - val_loss: 0.0542 - val_rmse: 0.1747 - val_mse: 0.0305 - val_mae: 0.1400 - 40ms/epoch - 3ms/step\n",
      "Epoch 55/5000\n",
      "15/15 - 0s - loss: 0.0565 - rmse: 0.1831 - mse: 0.0335 - mae: 0.1512 - val_loss: 0.0529 - val_rmse: 0.1755 - val_mse: 0.0308 - val_mae: 0.1412 - 39ms/epoch - 3ms/step\n",
      "Epoch 56/5000\n",
      "15/15 - 0s - loss: 0.0542 - rmse: 0.1813 - mse: 0.0329 - mae: 0.1497 - val_loss: 0.0504 - val_rmse: 0.1729 - val_mse: 0.0299 - val_mae: 0.1403 - 37ms/epoch - 2ms/step\n",
      "Epoch 57/5000\n",
      "15/15 - 0s - loss: 0.0532 - rmse: 0.1823 - mse: 0.0332 - mae: 0.1495 - val_loss: 0.0493 - val_rmse: 0.1734 - val_mse: 0.0301 - val_mae: 0.1438 - 39ms/epoch - 3ms/step\n",
      "Epoch 58/5000\n",
      "15/15 - 0s - loss: 0.0515 - rmse: 0.1811 - mse: 0.0328 - mae: 0.1494 - val_loss: 0.0479 - val_rmse: 0.1728 - val_mse: 0.0299 - val_mae: 0.1415 - 53ms/epoch - 4ms/step\n",
      "Epoch 59/5000\n",
      "15/15 - 0s - loss: 0.0506 - rmse: 0.1816 - mse: 0.0330 - mae: 0.1499 - val_loss: 0.0480 - val_rmse: 0.1758 - val_mse: 0.0309 - val_mae: 0.1401 - 53ms/epoch - 4ms/step\n",
      "Epoch 60/5000\n",
      "\n",
      "Epoch 60: val_loss improved from 0.06243 to 0.04632, saving model to data/output/activity_single-labeled_Fold-3.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0497 - rmse: 0.1818 - mse: 0.0330 - mae: 0.1493 - val_loss: 0.0463 - val_rmse: 0.1740 - val_mse: 0.0303 - val_mae: 0.1396 - 41ms/epoch - 3ms/step\n",
      "Epoch 61/5000\n",
      "15/15 - 0s - loss: 0.0482 - rmse: 0.1803 - mse: 0.0325 - mae: 0.1488 - val_loss: 0.0453 - val_rmse: 0.1735 - val_mse: 0.0301 - val_mae: 0.1426 - 41ms/epoch - 3ms/step\n",
      "Epoch 62/5000\n",
      "15/15 - 0s - loss: 0.0475 - rmse: 0.1804 - mse: 0.0325 - mae: 0.1488 - val_loss: 0.0440 - val_rmse: 0.1715 - val_mse: 0.0294 - val_mae: 0.1389 - 51ms/epoch - 3ms/step\n",
      "Epoch 63/5000\n",
      "15/15 - 0s - loss: 0.0469 - rmse: 0.1810 - mse: 0.0327 - mae: 0.1483 - val_loss: 0.0438 - val_rmse: 0.1733 - val_mse: 0.0300 - val_mae: 0.1419 - 39ms/epoch - 3ms/step\n",
      "Epoch 64/5000\n",
      "15/15 - 0s - loss: 0.0464 - rmse: 0.1814 - mse: 0.0329 - mae: 0.1493 - val_loss: 0.0426 - val_rmse: 0.1716 - val_mse: 0.0294 - val_mae: 0.1407 - 40ms/epoch - 3ms/step\n",
      "Epoch 65/5000\n",
      "15/15 - 0s - loss: 0.0466 - rmse: 0.1838 - mse: 0.0338 - mae: 0.1514 - val_loss: 0.0428 - val_rmse: 0.1739 - val_mse: 0.0302 - val_mae: 0.1397 - 49ms/epoch - 3ms/step\n",
      "Epoch 66/5000\n",
      "15/15 - 0s - loss: 0.0451 - rmse: 0.1809 - mse: 0.0327 - mae: 0.1490 - val_loss: 0.0422 - val_rmse: 0.1735 - val_mse: 0.0301 - val_mae: 0.1423 - 53ms/epoch - 4ms/step\n",
      "Epoch 67/5000\n",
      "15/15 - 0s - loss: 0.0442 - rmse: 0.1799 - mse: 0.0324 - mae: 0.1477 - val_loss: 0.0419 - val_rmse: 0.1741 - val_mse: 0.0303 - val_mae: 0.1442 - 33ms/epoch - 2ms/step\n",
      "Epoch 68/5000\n",
      "15/15 - 0s - loss: 0.0440 - rmse: 0.1807 - mse: 0.0327 - mae: 0.1498 - val_loss: 0.0408 - val_rmse: 0.1724 - val_mse: 0.0297 - val_mae: 0.1411 - 45ms/epoch - 3ms/step\n",
      "Epoch 69/5000\n",
      "15/15 - 0s - loss: 0.0435 - rmse: 0.1801 - mse: 0.0324 - mae: 0.1484 - val_loss: 0.0411 - val_rmse: 0.1739 - val_mse: 0.0303 - val_mae: 0.1420 - 58ms/epoch - 4ms/step\n",
      "Epoch 70/5000\n",
      "\n",
      "Epoch 70: val_loss improved from 0.04632 to 0.04130, saving model to data/output/activity_single-labeled_Fold-3.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0436 - rmse: 0.1816 - mse: 0.0330 - mae: 0.1489 - val_loss: 0.0413 - val_rmse: 0.1756 - val_mse: 0.0308 - val_mae: 0.1411 - 44ms/epoch - 3ms/step\n",
      "Epoch 71/5000\n",
      "15/15 - 0s - loss: 0.0429 - rmse: 0.1804 - mse: 0.0326 - mae: 0.1481 - val_loss: 0.0397 - val_rmse: 0.1718 - val_mse: 0.0295 - val_mae: 0.1402 - 39ms/epoch - 3ms/step\n",
      "Epoch 72/5000\n",
      "15/15 - 0s - loss: 0.0422 - rmse: 0.1793 - mse: 0.0321 - mae: 0.1472 - val_loss: 0.0400 - val_rmse: 0.1734 - val_mse: 0.0301 - val_mae: 0.1432 - 37ms/epoch - 2ms/step\n",
      "Epoch 73/5000\n",
      "15/15 - 0s - loss: 0.0422 - rmse: 0.1799 - mse: 0.0324 - mae: 0.1486 - val_loss: 0.0398 - val_rmse: 0.1734 - val_mse: 0.0301 - val_mae: 0.1445 - 45ms/epoch - 3ms/step\n",
      "Epoch 74/5000\n",
      "15/15 - 0s - loss: 0.0426 - rmse: 0.1813 - mse: 0.0329 - mae: 0.1484 - val_loss: 0.0393 - val_rmse: 0.1722 - val_mse: 0.0297 - val_mae: 0.1419 - 41ms/epoch - 3ms/step\n",
      "Epoch 75/5000\n",
      "15/15 - 0s - loss: 0.0429 - rmse: 0.1831 - mse: 0.0335 - mae: 0.1498 - val_loss: 0.0394 - val_rmse: 0.1739 - val_mse: 0.0302 - val_mae: 0.1455 - 38ms/epoch - 3ms/step\n",
      "Epoch 76/5000\n",
      "15/15 - 0s - loss: 0.0418 - rmse: 0.1807 - mse: 0.0327 - mae: 0.1477 - val_loss: 0.0394 - val_rmse: 0.1741 - val_mse: 0.0303 - val_mae: 0.1450 - 38ms/epoch - 3ms/step\n",
      "Epoch 77/5000\n",
      "15/15 - 0s - loss: 0.0418 - rmse: 0.1810 - mse: 0.0327 - mae: 0.1481 - val_loss: 0.0389 - val_rmse: 0.1731 - val_mse: 0.0300 - val_mae: 0.1418 - 43ms/epoch - 3ms/step\n",
      "Epoch 78/5000\n",
      "15/15 - 0s - loss: 0.0408 - rmse: 0.1788 - mse: 0.0320 - mae: 0.1469 - val_loss: 0.0392 - val_rmse: 0.1744 - val_mse: 0.0304 - val_mae: 0.1452 - 54ms/epoch - 4ms/step\n",
      "Epoch 79/5000\n",
      "15/15 - 0s - loss: 0.0411 - rmse: 0.1798 - mse: 0.0323 - mae: 0.1475 - val_loss: 0.0382 - val_rmse: 0.1717 - val_mse: 0.0295 - val_mae: 0.1405 - 38ms/epoch - 3ms/step\n",
      "Epoch 80/5000\n",
      "\n",
      "Epoch 80: val_loss improved from 0.04130 to 0.03853, saving model to data/output/activity_single-labeled_Fold-3.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0400 - rmse: 0.1771 - mse: 0.0314 - mae: 0.1457 - val_loss: 0.0385 - val_rmse: 0.1731 - val_mse: 0.0300 - val_mae: 0.1408 - 47ms/epoch - 3ms/step\n",
      "Epoch 81/5000\n",
      "15/15 - 0s - loss: 0.0407 - rmse: 0.1794 - mse: 0.0322 - mae: 0.1472 - val_loss: 0.0388 - val_rmse: 0.1741 - val_mse: 0.0303 - val_mae: 0.1418 - 39ms/epoch - 3ms/step\n",
      "Epoch 82/5000\n",
      "15/15 - 0s - loss: 0.0407 - rmse: 0.1797 - mse: 0.0323 - mae: 0.1475 - val_loss: 0.0380 - val_rmse: 0.1724 - val_mse: 0.0297 - val_mae: 0.1421 - 44ms/epoch - 3ms/step\n",
      "Epoch 83/5000\n",
      "15/15 - 0s - loss: 0.0411 - rmse: 0.1811 - mse: 0.0328 - mae: 0.1484 - val_loss: 0.0400 - val_rmse: 0.1782 - val_mse: 0.0318 - val_mae: 0.1481 - 65ms/epoch - 4ms/step\n",
      "Epoch 84/5000\n",
      "15/15 - 0s - loss: 0.0401 - rmse: 0.1787 - mse: 0.0319 - mae: 0.1465 - val_loss: 0.0390 - val_rmse: 0.1755 - val_mse: 0.0308 - val_mae: 0.1402 - 44ms/epoch - 3ms/step\n",
      "Epoch 85/5000\n",
      "15/15 - 0s - loss: 0.0404 - rmse: 0.1795 - mse: 0.0322 - mae: 0.1473 - val_loss: 0.0383 - val_rmse: 0.1735 - val_mse: 0.0301 - val_mae: 0.1439 - 42ms/epoch - 3ms/step\n",
      "Epoch 86/5000\n",
      "15/15 - 0s - loss: 0.0397 - rmse: 0.1776 - mse: 0.0316 - mae: 0.1453 - val_loss: 0.0383 - val_rmse: 0.1740 - val_mse: 0.0303 - val_mae: 0.1453 - 40ms/epoch - 3ms/step\n",
      "Epoch 87/5000\n",
      "15/15 - 0s - loss: 0.0403 - rmse: 0.1794 - mse: 0.0322 - mae: 0.1470 - val_loss: 0.0379 - val_rmse: 0.1729 - val_mse: 0.0299 - val_mae: 0.1428 - 40ms/epoch - 3ms/step\n",
      "Epoch 88/5000\n",
      "15/15 - 0s - loss: 0.0395 - rmse: 0.1777 - mse: 0.0316 - mae: 0.1454 - val_loss: 0.0381 - val_rmse: 0.1736 - val_mse: 0.0301 - val_mae: 0.1428 - 41ms/epoch - 3ms/step\n",
      "Epoch 89/5000\n",
      "15/15 - 0s - loss: 0.0407 - rmse: 0.1810 - mse: 0.0328 - mae: 0.1490 - val_loss: 0.0419 - val_rmse: 0.1843 - val_mse: 0.0340 - val_mae: 0.1545 - 37ms/epoch - 2ms/step\n",
      "Epoch 90/5000\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.03853\n",
      "15/15 - 0s - loss: 0.0411 - rmse: 0.1820 - mse: 0.0331 - mae: 0.1470 - val_loss: 0.0392 - val_rmse: 0.1766 - val_mse: 0.0312 - val_mae: 0.1475 - 39ms/epoch - 3ms/step\n",
      "Epoch 91/5000\n",
      "15/15 - 0s - loss: 0.0402 - rmse: 0.1795 - mse: 0.0322 - mae: 0.1472 - val_loss: 0.0380 - val_rmse: 0.1735 - val_mse: 0.0301 - val_mae: 0.1436 - 42ms/epoch - 3ms/step\n",
      "Epoch 92/5000\n",
      "15/15 - 0s - loss: 0.0397 - rmse: 0.1786 - mse: 0.0319 - mae: 0.1462 - val_loss: 0.0375 - val_rmse: 0.1723 - val_mse: 0.0297 - val_mae: 0.1417 - 44ms/epoch - 3ms/step\n",
      "Epoch 93/5000\n",
      "15/15 - 0s - loss: 0.0402 - rmse: 0.1801 - mse: 0.0324 - mae: 0.1483 - val_loss: 0.0374 - val_rmse: 0.1722 - val_mse: 0.0296 - val_mae: 0.1399 - 45ms/epoch - 3ms/step\n",
      "Epoch 94/5000\n",
      "15/15 - 0s - loss: 0.0393 - rmse: 0.1774 - mse: 0.0315 - mae: 0.1458 - val_loss: 0.0374 - val_rmse: 0.1721 - val_mse: 0.0296 - val_mae: 0.1406 - 31ms/epoch - 2ms/step\n",
      "Epoch 95/5000\n",
      "15/15 - 0s - loss: 0.0396 - rmse: 0.1783 - mse: 0.0318 - mae: 0.1455 - val_loss: 0.0381 - val_rmse: 0.1741 - val_mse: 0.0303 - val_mae: 0.1412 - 41ms/epoch - 3ms/step\n",
      "Epoch 96/5000\n",
      "15/15 - 0s - loss: 0.0396 - rmse: 0.1783 - mse: 0.0318 - mae: 0.1456 - val_loss: 0.0375 - val_rmse: 0.1723 - val_mse: 0.0297 - val_mae: 0.1385 - 63ms/epoch - 4ms/step\n",
      "Epoch 97/5000\n",
      "15/15 - 0s - loss: 0.0399 - rmse: 0.1797 - mse: 0.0323 - mae: 0.1485 - val_loss: 0.0377 - val_rmse: 0.1737 - val_mse: 0.0302 - val_mae: 0.1433 - 51ms/epoch - 3ms/step\n",
      "Epoch 98/5000\n",
      "15/15 - 0s - loss: 0.0398 - rmse: 0.1795 - mse: 0.0322 - mae: 0.1479 - val_loss: 0.0373 - val_rmse: 0.1721 - val_mse: 0.0296 - val_mae: 0.1414 - 74ms/epoch - 5ms/step\n",
      "Epoch 99/5000\n",
      "15/15 - 0s - loss: 0.0397 - rmse: 0.1788 - mse: 0.0320 - mae: 0.1461 - val_loss: 0.0377 - val_rmse: 0.1732 - val_mse: 0.0300 - val_mae: 0.1420 - 68ms/epoch - 5ms/step\n",
      "Epoch 100/5000\n",
      "\n",
      "Epoch 100: val_loss improved from 0.03853 to 0.03734, saving model to data/output/activity_single-labeled_Fold-3.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0391 - rmse: 0.1773 - mse: 0.0314 - mae: 0.1446 - val_loss: 0.0373 - val_rmse: 0.1724 - val_mse: 0.0297 - val_mae: 0.1395 - 49ms/epoch - 3ms/step\n",
      "Epoch 101/5000\n",
      "15/15 - 0s - loss: 0.0387 - rmse: 0.1764 - mse: 0.0311 - mae: 0.1458 - val_loss: 0.0382 - val_rmse: 0.1750 - val_mse: 0.0306 - val_mae: 0.1409 - 45ms/epoch - 3ms/step\n",
      "Epoch 102/5000\n",
      "15/15 - 0s - loss: 0.0391 - rmse: 0.1775 - mse: 0.0315 - mae: 0.1458 - val_loss: 0.0377 - val_rmse: 0.1734 - val_mse: 0.0301 - val_mae: 0.1412 - 47ms/epoch - 3ms/step\n",
      "Epoch 103/5000\n",
      "15/15 - 0s - loss: 0.0389 - rmse: 0.1769 - mse: 0.0313 - mae: 0.1440 - val_loss: 0.0377 - val_rmse: 0.1734 - val_mse: 0.0301 - val_mae: 0.1399 - 53ms/epoch - 4ms/step\n",
      "Epoch 104/5000\n",
      "15/15 - 0s - loss: 0.0389 - rmse: 0.1768 - mse: 0.0312 - mae: 0.1447 - val_loss: 0.0378 - val_rmse: 0.1737 - val_mse: 0.0302 - val_mae: 0.1389 - 57ms/epoch - 4ms/step\n",
      "Epoch 105/5000\n",
      "15/15 - 0s - loss: 0.0388 - rmse: 0.1765 - mse: 0.0312 - mae: 0.1430 - val_loss: 0.0376 - val_rmse: 0.1732 - val_mse: 0.0300 - val_mae: 0.1432 - 44ms/epoch - 3ms/step\n",
      "Epoch 106/5000\n",
      "15/15 - 0s - loss: 0.0387 - rmse: 0.1767 - mse: 0.0312 - mae: 0.1444 - val_loss: 0.0404 - val_rmse: 0.1815 - val_mse: 0.0329 - val_mae: 0.1521 - 35ms/epoch - 2ms/step\n",
      "Epoch 107/5000\n",
      "15/15 - 0s - loss: 0.0402 - rmse: 0.1807 - mse: 0.0326 - mae: 0.1480 - val_loss: 0.0372 - val_rmse: 0.1721 - val_mse: 0.0296 - val_mae: 0.1428 - 50ms/epoch - 3ms/step\n",
      "Epoch 108/5000\n",
      "15/15 - 0s - loss: 0.0396 - rmse: 0.1792 - mse: 0.0321 - mae: 0.1472 - val_loss: 0.0385 - val_rmse: 0.1759 - val_mse: 0.0309 - val_mae: 0.1452 - 51ms/epoch - 3ms/step\n",
      "Epoch 109/5000\n",
      "15/15 - 0s - loss: 0.0389 - rmse: 0.1771 - mse: 0.0314 - mae: 0.1445 - val_loss: 0.0404 - val_rmse: 0.1812 - val_mse: 0.0328 - val_mae: 0.1415 - 38ms/epoch - 3ms/step\n",
      "Epoch 110/5000\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.03734\n",
      "15/15 - 0s - loss: 0.0388 - rmse: 0.1770 - mse: 0.0313 - mae: 0.1452 - val_loss: 0.0378 - val_rmse: 0.1742 - val_mse: 0.0303 - val_mae: 0.1455 - 37ms/epoch - 2ms/step\n",
      "Epoch 111/5000\n",
      "15/15 - 0s - loss: 0.0386 - rmse: 0.1762 - mse: 0.0311 - mae: 0.1444 - val_loss: 0.0396 - val_rmse: 0.1790 - val_mse: 0.0320 - val_mae: 0.1500 - 48ms/epoch - 3ms/step\n",
      "Epoch 112/5000\n",
      "15/15 - 0s - loss: 0.0397 - rmse: 0.1791 - mse: 0.0321 - mae: 0.1464 - val_loss: 0.0378 - val_rmse: 0.1738 - val_mse: 0.0302 - val_mae: 0.1421 - 52ms/epoch - 3ms/step\n",
      "Epoch 113/5000\n",
      "15/15 - 0s - loss: 0.0388 - rmse: 0.1767 - mse: 0.0312 - mae: 0.1441 - val_loss: 0.0371 - val_rmse: 0.1722 - val_mse: 0.0296 - val_mae: 0.1416 - 54ms/epoch - 4ms/step\n",
      "Epoch 114/5000\n",
      "15/15 - 0s - loss: 0.0390 - rmse: 0.1777 - mse: 0.0316 - mae: 0.1461 - val_loss: 0.0386 - val_rmse: 0.1764 - val_mse: 0.0311 - val_mae: 0.1467 - 42ms/epoch - 3ms/step\n",
      "Epoch 115/5000\n",
      "15/15 - 0s - loss: 0.0388 - rmse: 0.1765 - mse: 0.0312 - mae: 0.1429 - val_loss: 0.0399 - val_rmse: 0.1796 - val_mse: 0.0323 - val_mae: 0.1496 - 40ms/epoch - 3ms/step\n",
      "Epoch 116/5000\n",
      "15/15 - 0s - loss: 0.0396 - rmse: 0.1790 - mse: 0.0320 - mae: 0.1449 - val_loss: 0.0399 - val_rmse: 0.1798 - val_mse: 0.0323 - val_mae: 0.1506 - 47ms/epoch - 3ms/step\n",
      "Epoch 117/5000\n",
      "15/15 - 0s - loss: 0.0384 - rmse: 0.1757 - mse: 0.0309 - mae: 0.1425 - val_loss: 0.0375 - val_rmse: 0.1732 - val_mse: 0.0300 - val_mae: 0.1414 - 39ms/epoch - 3ms/step\n",
      "Epoch 118/5000\n",
      "15/15 - 0s - loss: 0.0393 - rmse: 0.1782 - mse: 0.0317 - mae: 0.1443 - val_loss: 0.0379 - val_rmse: 0.1744 - val_mse: 0.0304 - val_mae: 0.1426 - 45ms/epoch - 3ms/step\n",
      "Epoch 119/5000\n",
      "15/15 - 0s - loss: 0.0382 - rmse: 0.1752 - mse: 0.0307 - mae: 0.1429 - val_loss: 0.0377 - val_rmse: 0.1737 - val_mse: 0.0302 - val_mae: 0.1396 - 39ms/epoch - 3ms/step\n",
      "Epoch 120/5000\n",
      "\n",
      "Epoch 120: val_loss improved from 0.03734 to 0.03703, saving model to data/output/activity_single-labeled_Fold-3.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0392 - rmse: 0.1777 - mse: 0.0316 - mae: 0.1450 - val_loss: 0.0370 - val_rmse: 0.1718 - val_mse: 0.0295 - val_mae: 0.1402 - 47ms/epoch - 3ms/step\n",
      "Epoch 121/5000\n",
      "15/15 - 0s - loss: 0.0385 - rmse: 0.1763 - mse: 0.0311 - mae: 0.1446 - val_loss: 0.0376 - val_rmse: 0.1736 - val_mse: 0.0301 - val_mae: 0.1413 - 32ms/epoch - 2ms/step\n",
      "Epoch 122/5000\n",
      "15/15 - 0s - loss: 0.0388 - rmse: 0.1770 - mse: 0.0313 - mae: 0.1445 - val_loss: 0.0374 - val_rmse: 0.1728 - val_mse: 0.0299 - val_mae: 0.1424 - 38ms/epoch - 3ms/step\n",
      "Epoch 123/5000\n",
      "15/15 - 0s - loss: 0.0381 - rmse: 0.1748 - mse: 0.0306 - mae: 0.1429 - val_loss: 0.0365 - val_rmse: 0.1701 - val_mse: 0.0289 - val_mae: 0.1386 - 50ms/epoch - 3ms/step\n",
      "Epoch 124/5000\n",
      "15/15 - 0s - loss: 0.0388 - rmse: 0.1765 - mse: 0.0312 - mae: 0.1430 - val_loss: 0.0379 - val_rmse: 0.1744 - val_mse: 0.0304 - val_mae: 0.1443 - 49ms/epoch - 3ms/step\n",
      "Epoch 125/5000\n",
      "15/15 - 0s - loss: 0.0383 - rmse: 0.1756 - mse: 0.0308 - mae: 0.1446 - val_loss: 0.0379 - val_rmse: 0.1745 - val_mse: 0.0304 - val_mae: 0.1449 - 31ms/epoch - 2ms/step\n",
      "Epoch 126/5000\n",
      "15/15 - 0s - loss: 0.0382 - rmse: 0.1748 - mse: 0.0305 - mae: 0.1428 - val_loss: 0.0373 - val_rmse: 0.1722 - val_mse: 0.0296 - val_mae: 0.1413 - 37ms/epoch - 2ms/step\n",
      "Epoch 127/5000\n",
      "15/15 - 0s - loss: 0.0390 - rmse: 0.1772 - mse: 0.0314 - mae: 0.1449 - val_loss: 0.0384 - val_rmse: 0.1755 - val_mse: 0.0308 - val_mae: 0.1455 - 38ms/epoch - 3ms/step\n",
      "Epoch 128/5000\n",
      "15/15 - 0s - loss: 0.0382 - rmse: 0.1749 - mse: 0.0306 - mae: 0.1424 - val_loss: 0.0379 - val_rmse: 0.1742 - val_mse: 0.0303 - val_mae: 0.1421 - 38ms/epoch - 3ms/step\n",
      "Epoch 129/5000\n",
      "15/15 - 0s - loss: 0.0387 - rmse: 0.1766 - mse: 0.0312 - mae: 0.1437 - val_loss: 0.0373 - val_rmse: 0.1727 - val_mse: 0.0298 - val_mae: 0.1428 - 35ms/epoch - 2ms/step\n",
      "Epoch 130/5000\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.03703\n",
      "15/15 - 0s - loss: 0.0384 - rmse: 0.1757 - mse: 0.0309 - mae: 0.1440 - val_loss: 0.0372 - val_rmse: 0.1723 - val_mse: 0.0297 - val_mae: 0.1404 - 35ms/epoch - 2ms/step\n",
      "Epoch 131/5000\n",
      "15/15 - 0s - loss: 0.0379 - rmse: 0.1741 - mse: 0.0303 - mae: 0.1427 - val_loss: 0.0384 - val_rmse: 0.1756 - val_mse: 0.0308 - val_mae: 0.1403 - 37ms/epoch - 2ms/step\n",
      "Epoch 132/5000\n",
      "15/15 - 0s - loss: 0.0380 - rmse: 0.1742 - mse: 0.0304 - mae: 0.1428 - val_loss: 0.0378 - val_rmse: 0.1737 - val_mse: 0.0302 - val_mae: 0.1420 - 35ms/epoch - 2ms/step\n",
      "Epoch 133/5000\n",
      "15/15 - 0s - loss: 0.0389 - rmse: 0.1767 - mse: 0.0312 - mae: 0.1449 - val_loss: 0.0394 - val_rmse: 0.1782 - val_mse: 0.0318 - val_mae: 0.1410 - 36ms/epoch - 2ms/step\n",
      "Epoch 134/5000\n",
      "15/15 - 0s - loss: 0.0392 - rmse: 0.1776 - mse: 0.0315 - mae: 0.1440 - val_loss: 0.0370 - val_rmse: 0.1715 - val_mse: 0.0294 - val_mae: 0.1398 - 31ms/epoch - 2ms/step\n",
      "Epoch 135/5000\n",
      "15/15 - 0s - loss: 0.0386 - rmse: 0.1764 - mse: 0.0311 - mae: 0.1448 - val_loss: 0.0382 - val_rmse: 0.1749 - val_mse: 0.0306 - val_mae: 0.1401 - 52ms/epoch - 3ms/step\n",
      "Epoch 136/5000\n",
      "15/15 - 0s - loss: 0.0385 - rmse: 0.1758 - mse: 0.0309 - mae: 0.1445 - val_loss: 0.0383 - val_rmse: 0.1749 - val_mse: 0.0306 - val_mae: 0.1396 - 45ms/epoch - 3ms/step\n",
      "Epoch 137/5000\n",
      "15/15 - 0s - loss: 0.0386 - rmse: 0.1759 - mse: 0.0309 - mae: 0.1440 - val_loss: 0.0387 - val_rmse: 0.1762 - val_mse: 0.0311 - val_mae: 0.1395 - 30ms/epoch - 2ms/step\n",
      "Epoch 138/5000\n",
      "15/15 - 0s - loss: 0.0390 - rmse: 0.1772 - mse: 0.0314 - mae: 0.1454 - val_loss: 0.0387 - val_rmse: 0.1764 - val_mse: 0.0311 - val_mae: 0.1430 - 44ms/epoch - 3ms/step\n",
      "Epoch 139/5000\n",
      "15/15 - 0s - loss: 0.0385 - rmse: 0.1760 - mse: 0.0310 - mae: 0.1442 - val_loss: 0.0373 - val_rmse: 0.1724 - val_mse: 0.0297 - val_mae: 0.1387 - 51ms/epoch - 3ms/step\n",
      "Epoch 140/5000\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.03703\n",
      "15/15 - 0s - loss: 0.0377 - rmse: 0.1736 - mse: 0.0302 - mae: 0.1421 - val_loss: 0.0380 - val_rmse: 0.1745 - val_mse: 0.0305 - val_mae: 0.1395 - 41ms/epoch - 3ms/step\n",
      "Epoch 141/5000\n",
      "15/15 - 0s - loss: 0.0382 - rmse: 0.1751 - mse: 0.0306 - mae: 0.1439 - val_loss: 0.0388 - val_rmse: 0.1765 - val_mse: 0.0312 - val_mae: 0.1392 - 38ms/epoch - 3ms/step\n",
      "Epoch 142/5000\n",
      "15/15 - 0s - loss: 0.0387 - rmse: 0.1761 - mse: 0.0310 - mae: 0.1430 - val_loss: 0.0375 - val_rmse: 0.1727 - val_mse: 0.0298 - val_mae: 0.1420 - 40ms/epoch - 3ms/step\n",
      "Epoch 143/5000\n",
      "Restoring model weights from the end of the best epoch: 123.\n",
      "15/15 - 0s - loss: 0.0393 - rmse: 0.1779 - mse: 0.0316 - mae: 0.1453 - val_loss: 0.0391 - val_rmse: 0.1773 - val_mse: 0.0314 - val_mae: 0.1476 - 41ms/epoch - 3ms/step\n",
      "Epoch 143: early stopping\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hertelj/build/local/miniforge3/envs/dfpl/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "15/15 - 0s - loss: 4.5906 - rmse: 0.6662 - mse: 0.4439 - mae: 0.5110 - val_loss: 4.1124 - val_rmse: 0.3209 - val_mse: 0.1030 - val_mae: 0.2536 - 237ms/epoch - 16ms/step\n",
      "Epoch 2/5000\n",
      "15/15 - 0s - loss: 3.9514 - rmse: 0.3066 - mse: 0.0940 - mae: 0.2476 - val_loss: 3.7078 - val_rmse: 0.2109 - val_mse: 0.0445 - val_mae: 0.1829 - 32ms/epoch - 2ms/step\n",
      "Epoch 3/5000\n",
      "15/15 - 0s - loss: 3.5585 - rmse: 0.2335 - mse: 0.0545 - mae: 0.1901 - val_loss: 3.3560 - val_rmse: 0.2084 - val_mse: 0.0434 - val_mae: 0.1726 - 32ms/epoch - 2ms/step\n",
      "Epoch 4/5000\n",
      "15/15 - 0s - loss: 3.2104 - rmse: 0.2145 - mse: 0.0460 - mae: 0.1766 - val_loss: 3.0235 - val_rmse: 0.1870 - val_mse: 0.0350 - val_mae: 0.1530 - 38ms/epoch - 3ms/step\n",
      "Epoch 5/5000\n",
      "15/15 - 0s - loss: 2.8958 - rmse: 0.2042 - mse: 0.0417 - mae: 0.1695 - val_loss: 2.7269 - val_rmse: 0.1787 - val_mse: 0.0319 - val_mae: 0.1443 - 36ms/epoch - 2ms/step\n",
      "Epoch 6/5000\n",
      "15/15 - 0s - loss: 2.6146 - rmse: 0.2028 - mse: 0.0411 - mae: 0.1682 - val_loss: 2.4620 - val_rmse: 0.1790 - val_mse: 0.0321 - val_mae: 0.1483 - 39ms/epoch - 3ms/step\n",
      "Epoch 7/5000\n",
      "15/15 - 0s - loss: 2.3591 - rmse: 0.1966 - mse: 0.0386 - mae: 0.1622 - val_loss: 2.2223 - val_rmse: 0.1769 - val_mse: 0.0313 - val_mae: 0.1454 - 55ms/epoch - 4ms/step\n",
      "Epoch 8/5000\n",
      "15/15 - 0s - loss: 2.1285 - rmse: 0.1902 - mse: 0.0362 - mae: 0.1567 - val_loss: 2.0054 - val_rmse: 0.1723 - val_mse: 0.0297 - val_mae: 0.1391 - 73ms/epoch - 5ms/step\n",
      "Epoch 9/5000\n",
      "15/15 - 0s - loss: 1.9236 - rmse: 0.1915 - mse: 0.0367 - mae: 0.1564 - val_loss: 1.8126 - val_rmse: 0.1756 - val_mse: 0.0308 - val_mae: 0.1445 - 36ms/epoch - 2ms/step\n",
      "Epoch 10/5000\n",
      "\n",
      "Epoch 10: val_loss improved from inf to 1.63727, saving model to data/output/activity_single-labeled_Fold-4.model.weights.hdf5\n",
      "15/15 - 0s - loss: 1.7398 - rmse: 0.1953 - mse: 0.0382 - mae: 0.1628 - val_loss: 1.6373 - val_rmse: 0.1742 - val_mse: 0.0303 - val_mae: 0.1430 - 60ms/epoch - 4ms/step\n",
      "Epoch 11/5000\n",
      "15/15 - 0s - loss: 1.5703 - rmse: 0.1887 - mse: 0.0356 - mae: 0.1567 - val_loss: 1.4796 - val_rmse: 0.1740 - val_mse: 0.0303 - val_mae: 0.1415 - 38ms/epoch - 3ms/step\n",
      "Epoch 12/5000\n",
      "15/15 - 0s - loss: 1.4196 - rmse: 0.1879 - mse: 0.0353 - mae: 0.1552 - val_loss: 1.3374 - val_rmse: 0.1735 - val_mse: 0.0301 - val_mae: 0.1415 - 51ms/epoch - 3ms/step\n",
      "Epoch 13/5000\n",
      "15/15 - 0s - loss: 1.2851 - rmse: 0.1911 - mse: 0.0365 - mae: 0.1574 - val_loss: 1.2100 - val_rmse: 0.1759 - val_mse: 0.0309 - val_mae: 0.1446 - 38ms/epoch - 3ms/step\n",
      "Epoch 14/5000\n",
      "15/15 - 0s - loss: 1.1618 - rmse: 0.1887 - mse: 0.0356 - mae: 0.1555 - val_loss: 1.0943 - val_rmse: 0.1749 - val_mse: 0.0306 - val_mae: 0.1429 - 46ms/epoch - 3ms/step\n",
      "Epoch 15/5000\n",
      "15/15 - 0s - loss: 1.0524 - rmse: 0.1907 - mse: 0.0364 - mae: 0.1595 - val_loss: 0.9912 - val_rmse: 0.1779 - val_mse: 0.0317 - val_mae: 0.1434 - 35ms/epoch - 2ms/step\n",
      "Epoch 16/5000\n",
      "15/15 - 0s - loss: 0.9535 - rmse: 0.1925 - mse: 0.0370 - mae: 0.1599 - val_loss: 0.8990 - val_rmse: 0.1828 - val_mse: 0.0334 - val_mae: 0.1531 - 34ms/epoch - 2ms/step\n",
      "Epoch 17/5000\n",
      "15/15 - 0s - loss: 0.8640 - rmse: 0.1928 - mse: 0.0372 - mae: 0.1602 - val_loss: 0.8113 - val_rmse: 0.1741 - val_mse: 0.0303 - val_mae: 0.1421 - 35ms/epoch - 2ms/step\n",
      "Epoch 18/5000\n",
      "15/15 - 0s - loss: 0.7817 - rmse: 0.1885 - mse: 0.0355 - mae: 0.1569 - val_loss: 0.7352 - val_rmse: 0.1743 - val_mse: 0.0304 - val_mae: 0.1426 - 54ms/epoch - 4ms/step\n",
      "Epoch 19/5000\n",
      "15/15 - 0s - loss: 0.7092 - rmse: 0.1894 - mse: 0.0359 - mae: 0.1570 - val_loss: 0.6673 - val_rmse: 0.1769 - val_mse: 0.0313 - val_mae: 0.1457 - 35ms/epoch - 2ms/step\n",
      "Epoch 20/5000\n",
      "\n",
      "Epoch 20: val_loss improved from 1.63727 to 0.60489, saving model to data/output/activity_single-labeled_Fold-4.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.6431 - rmse: 0.1886 - mse: 0.0356 - mae: 0.1564 - val_loss: 0.6049 - val_rmse: 0.1760 - val_mse: 0.0310 - val_mae: 0.1450 - 39ms/epoch - 3ms/step\n",
      "Epoch 21/5000\n",
      "15/15 - 0s - loss: 0.5835 - rmse: 0.1875 - mse: 0.0352 - mae: 0.1565 - val_loss: 0.5486 - val_rmse: 0.1747 - val_mse: 0.0305 - val_mae: 0.1413 - 58ms/epoch - 4ms/step\n",
      "Epoch 22/5000\n",
      "15/15 - 0s - loss: 0.5308 - rmse: 0.1893 - mse: 0.0358 - mae: 0.1569 - val_loss: 0.4986 - val_rmse: 0.1760 - val_mse: 0.0310 - val_mae: 0.1444 - 52ms/epoch - 3ms/step\n",
      "Epoch 23/5000\n",
      "15/15 - 0s - loss: 0.4825 - rmse: 0.1890 - mse: 0.0357 - mae: 0.1580 - val_loss: 0.4532 - val_rmse: 0.1764 - val_mse: 0.0311 - val_mae: 0.1445 - 56ms/epoch - 4ms/step\n",
      "Epoch 24/5000\n",
      "15/15 - 0s - loss: 0.4388 - rmse: 0.1883 - mse: 0.0354 - mae: 0.1565 - val_loss: 0.4123 - val_rmse: 0.1763 - val_mse: 0.0311 - val_mae: 0.1440 - 57ms/epoch - 4ms/step\n",
      "Epoch 25/5000\n",
      "15/15 - 0s - loss: 0.4003 - rmse: 0.1898 - mse: 0.0360 - mae: 0.1579 - val_loss: 0.3752 - val_rmse: 0.1759 - val_mse: 0.0310 - val_mae: 0.1447 - 38ms/epoch - 3ms/step\n",
      "Epoch 26/5000\n",
      "15/15 - 0s - loss: 0.3643 - rmse: 0.1878 - mse: 0.0353 - mae: 0.1557 - val_loss: 0.3424 - val_rmse: 0.1770 - val_mse: 0.0313 - val_mae: 0.1458 - 41ms/epoch - 3ms/step\n",
      "Epoch 27/5000\n",
      "15/15 - 0s - loss: 0.3328 - rmse: 0.1886 - mse: 0.0356 - mae: 0.1583 - val_loss: 0.3123 - val_rmse: 0.1770 - val_mse: 0.0313 - val_mae: 0.1437 - 37ms/epoch - 2ms/step\n",
      "Epoch 28/5000\n",
      "15/15 - 0s - loss: 0.3035 - rmse: 0.1868 - mse: 0.0349 - mae: 0.1562 - val_loss: 0.2848 - val_rmse: 0.1756 - val_mse: 0.0308 - val_mae: 0.1445 - 38ms/epoch - 3ms/step\n",
      "Epoch 29/5000\n",
      "15/15 - 0s - loss: 0.2780 - rmse: 0.1874 - mse: 0.0351 - mae: 0.1548 - val_loss: 0.2606 - val_rmse: 0.1759 - val_mse: 0.0309 - val_mae: 0.1445 - 40ms/epoch - 3ms/step\n",
      "Epoch 30/5000\n",
      "\n",
      "Epoch 30: val_loss improved from 0.60489 to 0.23888, saving model to data/output/activity_single-labeled_Fold-4.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.2552 - rmse: 0.1887 - mse: 0.0356 - mae: 0.1580 - val_loss: 0.2389 - val_rmse: 0.1767 - val_mse: 0.0312 - val_mae: 0.1435 - 62ms/epoch - 4ms/step\n",
      "Epoch 31/5000\n",
      "15/15 - 0s - loss: 0.2335 - rmse: 0.1871 - mse: 0.0350 - mae: 0.1560 - val_loss: 0.2192 - val_rmse: 0.1774 - val_mse: 0.0315 - val_mae: 0.1470 - 42ms/epoch - 3ms/step\n",
      "Epoch 32/5000\n",
      "15/15 - 0s - loss: 0.2147 - rmse: 0.1872 - mse: 0.0350 - mae: 0.1564 - val_loss: 0.2012 - val_rmse: 0.1767 - val_mse: 0.0312 - val_mae: 0.1458 - 37ms/epoch - 2ms/step\n",
      "Epoch 33/5000\n",
      "15/15 - 0s - loss: 0.1974 - rmse: 0.1863 - mse: 0.0347 - mae: 0.1560 - val_loss: 0.1844 - val_rmse: 0.1743 - val_mse: 0.0304 - val_mae: 0.1424 - 52ms/epoch - 3ms/step\n",
      "Epoch 34/5000\n",
      "15/15 - 0s - loss: 0.1819 - rmse: 0.1859 - mse: 0.0346 - mae: 0.1544 - val_loss: 0.1712 - val_rmse: 0.1779 - val_mse: 0.0317 - val_mae: 0.1467 - 55ms/epoch - 4ms/step\n",
      "Epoch 35/5000\n",
      "15/15 - 0s - loss: 0.1675 - rmse: 0.1843 - mse: 0.0340 - mae: 0.1531 - val_loss: 0.1572 - val_rmse: 0.1753 - val_mse: 0.0307 - val_mae: 0.1432 - 38ms/epoch - 3ms/step\n",
      "Epoch 36/5000\n",
      "15/15 - 0s - loss: 0.1550 - rmse: 0.1840 - mse: 0.0338 - mae: 0.1532 - val_loss: 0.1453 - val_rmse: 0.1748 - val_mse: 0.0306 - val_mae: 0.1438 - 56ms/epoch - 4ms/step\n",
      "Epoch 37/5000\n",
      "15/15 - 0s - loss: 0.1441 - rmse: 0.1852 - mse: 0.0343 - mae: 0.1549 - val_loss: 0.1345 - val_rmse: 0.1743 - val_mse: 0.0304 - val_mae: 0.1419 - 38ms/epoch - 3ms/step\n",
      "Epoch 38/5000\n",
      "15/15 - 0s - loss: 0.1338 - rmse: 0.1846 - mse: 0.0341 - mae: 0.1522 - val_loss: 0.1254 - val_rmse: 0.1755 - val_mse: 0.0308 - val_mae: 0.1441 - 39ms/epoch - 3ms/step\n",
      "Epoch 39/5000\n",
      "15/15 - 0s - loss: 0.1250 - rmse: 0.1855 - mse: 0.0344 - mae: 0.1540 - val_loss: 0.1168 - val_rmse: 0.1760 - val_mse: 0.0310 - val_mae: 0.1437 - 38ms/epoch - 3ms/step\n",
      "Epoch 40/5000\n",
      "\n",
      "Epoch 40: val_loss improved from 0.23888 to 0.10869, saving model to data/output/activity_single-labeled_Fold-4.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.1166 - rmse: 0.1851 - mse: 0.0343 - mae: 0.1543 - val_loss: 0.1087 - val_rmse: 0.1748 - val_mse: 0.0306 - val_mae: 0.1436 - 43ms/epoch - 3ms/step\n",
      "Epoch 41/5000\n",
      "15/15 - 0s - loss: 0.1089 - rmse: 0.1844 - mse: 0.0340 - mae: 0.1536 - val_loss: 0.1013 - val_rmse: 0.1738 - val_mse: 0.0302 - val_mae: 0.1419 - 35ms/epoch - 2ms/step\n",
      "Epoch 42/5000\n",
      "15/15 - 0s - loss: 0.1022 - rmse: 0.1840 - mse: 0.0338 - mae: 0.1534 - val_loss: 0.0949 - val_rmse: 0.1732 - val_mse: 0.0300 - val_mae: 0.1407 - 31ms/epoch - 2ms/step\n",
      "Epoch 43/5000\n",
      "15/15 - 0s - loss: 0.0980 - rmse: 0.1892 - mse: 0.0358 - mae: 0.1561 - val_loss: 0.0936 - val_rmse: 0.1857 - val_mse: 0.0345 - val_mae: 0.1543 - 40ms/epoch - 3ms/step\n",
      "Epoch 44/5000\n",
      "15/15 - 0s - loss: 0.0914 - rmse: 0.1861 - mse: 0.0346 - mae: 0.1537 - val_loss: 0.0849 - val_rmse: 0.1758 - val_mse: 0.0309 - val_mae: 0.1435 - 34ms/epoch - 2ms/step\n",
      "Epoch 45/5000\n",
      "15/15 - 0s - loss: 0.0863 - rmse: 0.1855 - mse: 0.0344 - mae: 0.1531 - val_loss: 0.0797 - val_rmse: 0.1738 - val_mse: 0.0302 - val_mae: 0.1413 - 38ms/epoch - 3ms/step\n",
      "Epoch 46/5000\n",
      "15/15 - 0s - loss: 0.0814 - rmse: 0.1840 - mse: 0.0339 - mae: 0.1527 - val_loss: 0.0761 - val_rmse: 0.1758 - val_mse: 0.0309 - val_mae: 0.1440 - 37ms/epoch - 2ms/step\n",
      "Epoch 47/5000\n",
      "15/15 - 0s - loss: 0.0771 - rmse: 0.1832 - mse: 0.0336 - mae: 0.1532 - val_loss: 0.0726 - val_rmse: 0.1762 - val_mse: 0.0310 - val_mae: 0.1426 - 40ms/epoch - 3ms/step\n",
      "Epoch 48/5000\n",
      "15/15 - 0s - loss: 0.0739 - rmse: 0.1842 - mse: 0.0339 - mae: 0.1521 - val_loss: 0.0697 - val_rmse: 0.1777 - val_mse: 0.0316 - val_mae: 0.1457 - 42ms/epoch - 3ms/step\n",
      "Epoch 49/5000\n",
      "15/15 - 0s - loss: 0.0706 - rmse: 0.1839 - mse: 0.0338 - mae: 0.1533 - val_loss: 0.0652 - val_rmse: 0.1733 - val_mse: 0.0300 - val_mae: 0.1414 - 35ms/epoch - 2ms/step\n",
      "Epoch 50/5000\n",
      "\n",
      "Epoch 50: val_loss improved from 0.10869 to 0.06307, saving model to data/output/activity_single-labeled_Fold-4.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0675 - rmse: 0.1835 - mse: 0.0337 - mae: 0.1516 - val_loss: 0.0631 - val_rmse: 0.1755 - val_mse: 0.0308 - val_mae: 0.1443 - 40ms/epoch - 3ms/step\n",
      "Epoch 51/5000\n",
      "15/15 - 0s - loss: 0.0647 - rmse: 0.1832 - mse: 0.0336 - mae: 0.1528 - val_loss: 0.0600 - val_rmse: 0.1737 - val_mse: 0.0302 - val_mae: 0.1413 - 34ms/epoch - 2ms/step\n",
      "Epoch 52/5000\n",
      "15/15 - 0s - loss: 0.0620 - rmse: 0.1822 - mse: 0.0332 - mae: 0.1510 - val_loss: 0.0582 - val_rmse: 0.1747 - val_mse: 0.0305 - val_mae: 0.1423 - 31ms/epoch - 2ms/step\n",
      "Epoch 53/5000\n",
      "15/15 - 0s - loss: 0.0601 - rmse: 0.1826 - mse: 0.0334 - mae: 0.1514 - val_loss: 0.0565 - val_rmse: 0.1757 - val_mse: 0.0309 - val_mae: 0.1429 - 36ms/epoch - 2ms/step\n",
      "Epoch 54/5000\n",
      "15/15 - 0s - loss: 0.0589 - rmse: 0.1849 - mse: 0.0342 - mae: 0.1542 - val_loss: 0.0542 - val_rmse: 0.1746 - val_mse: 0.0305 - val_mae: 0.1413 - 48ms/epoch - 3ms/step\n",
      "Epoch 55/5000\n",
      "15/15 - 0s - loss: 0.0564 - rmse: 0.1827 - mse: 0.0334 - mae: 0.1521 - val_loss: 0.0520 - val_rmse: 0.1728 - val_mse: 0.0299 - val_mae: 0.1405 - 36ms/epoch - 2ms/step\n",
      "Epoch 56/5000\n",
      "15/15 - 0s - loss: 0.0548 - rmse: 0.1822 - mse: 0.0332 - mae: 0.1508 - val_loss: 0.0510 - val_rmse: 0.1737 - val_mse: 0.0302 - val_mae: 0.1418 - 44ms/epoch - 3ms/step\n",
      "Epoch 57/5000\n",
      "15/15 - 0s - loss: 0.0533 - rmse: 0.1819 - mse: 0.0331 - mae: 0.1510 - val_loss: 0.0494 - val_rmse: 0.1733 - val_mse: 0.0300 - val_mae: 0.1412 - 28ms/epoch - 2ms/step\n",
      "Epoch 58/5000\n",
      "15/15 - 0s - loss: 0.0521 - rmse: 0.1823 - mse: 0.0332 - mae: 0.1526 - val_loss: 0.0485 - val_rmse: 0.1740 - val_mse: 0.0303 - val_mae: 0.1414 - 29ms/epoch - 2ms/step\n",
      "Epoch 59/5000\n",
      "15/15 - 0s - loss: 0.0507 - rmse: 0.1818 - mse: 0.0330 - mae: 0.1502 - val_loss: 0.0466 - val_rmse: 0.1717 - val_mse: 0.0295 - val_mae: 0.1396 - 34ms/epoch - 2ms/step\n",
      "Epoch 60/5000\n",
      "\n",
      "Epoch 60: val_loss improved from 0.06307 to 0.04674, saving model to data/output/activity_single-labeled_Fold-4.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0496 - rmse: 0.1812 - mse: 0.0328 - mae: 0.1500 - val_loss: 0.0467 - val_rmse: 0.1748 - val_mse: 0.0306 - val_mae: 0.1408 - 50ms/epoch - 3ms/step\n",
      "Epoch 61/5000\n",
      "15/15 - 0s - loss: 0.0493 - rmse: 0.1833 - mse: 0.0336 - mae: 0.1520 - val_loss: 0.0455 - val_rmse: 0.1741 - val_mse: 0.0303 - val_mae: 0.1424 - 31ms/epoch - 2ms/step\n",
      "Epoch 62/5000\n",
      "15/15 - 0s - loss: 0.0477 - rmse: 0.1812 - mse: 0.0328 - mae: 0.1494 - val_loss: 0.0449 - val_rmse: 0.1742 - val_mse: 0.0304 - val_mae: 0.1421 - 28ms/epoch - 2ms/step\n",
      "Epoch 63/5000\n",
      "15/15 - 0s - loss: 0.0469 - rmse: 0.1810 - mse: 0.0328 - mae: 0.1490 - val_loss: 0.0437 - val_rmse: 0.1732 - val_mse: 0.0300 - val_mae: 0.1416 - 33ms/epoch - 2ms/step\n",
      "Epoch 64/5000\n",
      "15/15 - 0s - loss: 0.0472 - rmse: 0.1834 - mse: 0.0336 - mae: 0.1520 - val_loss: 0.0426 - val_rmse: 0.1715 - val_mse: 0.0294 - val_mae: 0.1387 - 47ms/epoch - 3ms/step\n",
      "Epoch 65/5000\n",
      "15/15 - 0s - loss: 0.0452 - rmse: 0.1795 - mse: 0.0322 - mae: 0.1490 - val_loss: 0.0424 - val_rmse: 0.1726 - val_mse: 0.0298 - val_mae: 0.1396 - 37ms/epoch - 2ms/step\n",
      "Epoch 66/5000\n",
      "15/15 - 0s - loss: 0.0448 - rmse: 0.1799 - mse: 0.0324 - mae: 0.1480 - val_loss: 0.0421 - val_rmse: 0.1731 - val_mse: 0.0300 - val_mae: 0.1401 - 34ms/epoch - 2ms/step\n",
      "Epoch 67/5000\n",
      "15/15 - 0s - loss: 0.0445 - rmse: 0.1806 - mse: 0.0326 - mae: 0.1486 - val_loss: 0.0417 - val_rmse: 0.1736 - val_mse: 0.0301 - val_mae: 0.1412 - 54ms/epoch - 4ms/step\n",
      "Epoch 68/5000\n",
      "15/15 - 0s - loss: 0.0438 - rmse: 0.1801 - mse: 0.0324 - mae: 0.1495 - val_loss: 0.0410 - val_rmse: 0.1727 - val_mse: 0.0298 - val_mae: 0.1408 - 40ms/epoch - 3ms/step\n",
      "Epoch 69/5000\n",
      "15/15 - 0s - loss: 0.0436 - rmse: 0.1803 - mse: 0.0325 - mae: 0.1496 - val_loss: 0.0413 - val_rmse: 0.1746 - val_mse: 0.0305 - val_mae: 0.1422 - 27ms/epoch - 2ms/step\n",
      "Epoch 70/5000\n",
      "\n",
      "Epoch 70: val_loss improved from 0.04674 to 0.04050, saving model to data/output/activity_single-labeled_Fold-4.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0435 - rmse: 0.1809 - mse: 0.0327 - mae: 0.1487 - val_loss: 0.0405 - val_rmse: 0.1731 - val_mse: 0.0300 - val_mae: 0.1406 - 41ms/epoch - 3ms/step\n",
      "Epoch 71/5000\n",
      "15/15 - 0s - loss: 0.0431 - rmse: 0.1811 - mse: 0.0328 - mae: 0.1504 - val_loss: 0.0409 - val_rmse: 0.1753 - val_mse: 0.0307 - val_mae: 0.1436 - 37ms/epoch - 2ms/step\n",
      "Epoch 72/5000\n",
      "15/15 - 0s - loss: 0.0425 - rmse: 0.1801 - mse: 0.0324 - mae: 0.1486 - val_loss: 0.0391 - val_rmse: 0.1708 - val_mse: 0.0292 - val_mae: 0.1378 - 34ms/epoch - 2ms/step\n",
      "Epoch 73/5000\n",
      "15/15 - 0s - loss: 0.0418 - rmse: 0.1792 - mse: 0.0321 - mae: 0.1477 - val_loss: 0.0389 - val_rmse: 0.1714 - val_mse: 0.0294 - val_mae: 0.1394 - 35ms/epoch - 2ms/step\n",
      "Epoch 74/5000\n",
      "15/15 - 0s - loss: 0.0418 - rmse: 0.1795 - mse: 0.0322 - mae: 0.1483 - val_loss: 0.0392 - val_rmse: 0.1723 - val_mse: 0.0297 - val_mae: 0.1392 - 30ms/epoch - 2ms/step\n",
      "Epoch 75/5000\n",
      "15/15 - 0s - loss: 0.0415 - rmse: 0.1790 - mse: 0.0320 - mae: 0.1472 - val_loss: 0.0395 - val_rmse: 0.1736 - val_mse: 0.0301 - val_mae: 0.1409 - 28ms/epoch - 2ms/step\n",
      "Epoch 76/5000\n",
      "15/15 - 0s - loss: 0.0411 - rmse: 0.1787 - mse: 0.0319 - mae: 0.1482 - val_loss: 0.0390 - val_rmse: 0.1732 - val_mse: 0.0300 - val_mae: 0.1409 - 31ms/epoch - 2ms/step\n",
      "Epoch 77/5000\n",
      "15/15 - 0s - loss: 0.0415 - rmse: 0.1801 - mse: 0.0324 - mae: 0.1490 - val_loss: 0.0392 - val_rmse: 0.1739 - val_mse: 0.0302 - val_mae: 0.1409 - 46ms/epoch - 3ms/step\n",
      "Epoch 78/5000\n",
      "15/15 - 0s - loss: 0.0427 - rmse: 0.1838 - mse: 0.0338 - mae: 0.1505 - val_loss: 0.0392 - val_rmse: 0.1745 - val_mse: 0.0304 - val_mae: 0.1415 - 37ms/epoch - 2ms/step\n",
      "Epoch 79/5000\n",
      "15/15 - 0s - loss: 0.0414 - rmse: 0.1809 - mse: 0.0327 - mae: 0.1491 - val_loss: 0.0397 - val_rmse: 0.1765 - val_mse: 0.0311 - val_mae: 0.1445 - 35ms/epoch - 2ms/step\n",
      "Epoch 80/5000\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.04050\n",
      "15/15 - 0s - loss: 0.0411 - rmse: 0.1808 - mse: 0.0327 - mae: 0.1496 - val_loss: 0.0409 - val_rmse: 0.1802 - val_mse: 0.0325 - val_mae: 0.1482 - 39ms/epoch - 3ms/step\n",
      "Epoch 81/5000\n",
      "15/15 - 0s - loss: 0.0418 - rmse: 0.1825 - mse: 0.0333 - mae: 0.1501 - val_loss: 0.0393 - val_rmse: 0.1755 - val_mse: 0.0308 - val_mae: 0.1430 - 45ms/epoch - 3ms/step\n",
      "Epoch 82/5000\n",
      "15/15 - 0s - loss: 0.0406 - rmse: 0.1796 - mse: 0.0322 - mae: 0.1477 - val_loss: 0.0406 - val_rmse: 0.1798 - val_mse: 0.0323 - val_mae: 0.1477 - 38ms/epoch - 3ms/step\n",
      "Epoch 83/5000\n",
      "15/15 - 0s - loss: 0.0412 - rmse: 0.1815 - mse: 0.0330 - mae: 0.1487 - val_loss: 0.0388 - val_rmse: 0.1748 - val_mse: 0.0306 - val_mae: 0.1426 - 38ms/epoch - 3ms/step\n",
      "Epoch 84/5000\n",
      "15/15 - 0s - loss: 0.0411 - rmse: 0.1813 - mse: 0.0329 - mae: 0.1487 - val_loss: 0.0378 - val_rmse: 0.1720 - val_mse: 0.0296 - val_mae: 0.1399 - 36ms/epoch - 2ms/step\n",
      "Epoch 85/5000\n",
      "15/15 - 0s - loss: 0.0411 - rmse: 0.1815 - mse: 0.0330 - mae: 0.1497 - val_loss: 0.0379 - val_rmse: 0.1729 - val_mse: 0.0299 - val_mae: 0.1400 - 41ms/epoch - 3ms/step\n",
      "Epoch 86/5000\n",
      "15/15 - 0s - loss: 0.0404 - rmse: 0.1800 - mse: 0.0324 - mae: 0.1482 - val_loss: 0.0374 - val_rmse: 0.1713 - val_mse: 0.0294 - val_mae: 0.1388 - 39ms/epoch - 3ms/step\n",
      "Epoch 87/5000\n",
      "15/15 - 0s - loss: 0.0408 - rmse: 0.1811 - mse: 0.0328 - mae: 0.1493 - val_loss: 0.0372 - val_rmse: 0.1709 - val_mse: 0.0292 - val_mae: 0.1377 - 43ms/epoch - 3ms/step\n",
      "Epoch 88/5000\n",
      "15/15 - 0s - loss: 0.0395 - rmse: 0.1776 - mse: 0.0316 - mae: 0.1463 - val_loss: 0.0404 - val_rmse: 0.1803 - val_mse: 0.0325 - val_mae: 0.1481 - 36ms/epoch - 2ms/step\n",
      "Epoch 89/5000\n",
      "15/15 - 0s - loss: 0.0414 - rmse: 0.1832 - mse: 0.0336 - mae: 0.1489 - val_loss: 0.0394 - val_rmse: 0.1775 - val_mse: 0.0315 - val_mae: 0.1454 - 56ms/epoch - 4ms/step\n",
      "Epoch 90/5000\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.04050\n",
      "15/15 - 0s - loss: 0.0411 - rmse: 0.1827 - mse: 0.0334 - mae: 0.1506 - val_loss: 0.0406 - val_rmse: 0.1809 - val_mse: 0.0327 - val_mae: 0.1497 - 38ms/epoch - 3ms/step\n",
      "Epoch 91/5000\n",
      "15/15 - 0s - loss: 0.0412 - rmse: 0.1824 - mse: 0.0333 - mae: 0.1491 - val_loss: 0.0376 - val_rmse: 0.1721 - val_mse: 0.0296 - val_mae: 0.1393 - 37ms/epoch - 2ms/step\n",
      "Epoch 92/5000\n",
      "15/15 - 0s - loss: 0.0394 - rmse: 0.1778 - mse: 0.0316 - mae: 0.1471 - val_loss: 0.0374 - val_rmse: 0.1724 - val_mse: 0.0297 - val_mae: 0.1392 - 34ms/epoch - 2ms/step\n",
      "Epoch 93/5000\n",
      "15/15 - 0s - loss: 0.0394 - rmse: 0.1779 - mse: 0.0316 - mae: 0.1467 - val_loss: 0.0369 - val_rmse: 0.1706 - val_mse: 0.0291 - val_mae: 0.1385 - 50ms/epoch - 3ms/step\n",
      "Epoch 94/5000\n",
      "15/15 - 0s - loss: 0.0395 - rmse: 0.1779 - mse: 0.0317 - mae: 0.1461 - val_loss: 0.0372 - val_rmse: 0.1715 - val_mse: 0.0294 - val_mae: 0.1391 - 57ms/epoch - 4ms/step\n",
      "Epoch 95/5000\n",
      "15/15 - 0s - loss: 0.0395 - rmse: 0.1785 - mse: 0.0319 - mae: 0.1471 - val_loss: 0.0387 - val_rmse: 0.1763 - val_mse: 0.0311 - val_mae: 0.1411 - 37ms/epoch - 2ms/step\n",
      "Epoch 96/5000\n",
      "15/15 - 0s - loss: 0.0399 - rmse: 0.1794 - mse: 0.0322 - mae: 0.1477 - val_loss: 0.0379 - val_rmse: 0.1737 - val_mse: 0.0302 - val_mae: 0.1397 - 33ms/epoch - 2ms/step\n",
      "Epoch 97/5000\n",
      "15/15 - 0s - loss: 0.0400 - rmse: 0.1794 - mse: 0.0322 - mae: 0.1474 - val_loss: 0.0382 - val_rmse: 0.1747 - val_mse: 0.0305 - val_mae: 0.1400 - 42ms/epoch - 3ms/step\n",
      "Epoch 98/5000\n",
      "15/15 - 0s - loss: 0.0404 - rmse: 0.1811 - mse: 0.0328 - mae: 0.1483 - val_loss: 0.0381 - val_rmse: 0.1746 - val_mse: 0.0305 - val_mae: 0.1408 - 30ms/epoch - 2ms/step\n",
      "Epoch 99/5000\n",
      "15/15 - 0s - loss: 0.0392 - rmse: 0.1777 - mse: 0.0316 - mae: 0.1460 - val_loss: 0.0401 - val_rmse: 0.1800 - val_mse: 0.0324 - val_mae: 0.1462 - 35ms/epoch - 2ms/step\n",
      "Epoch 100/5000\n",
      "\n",
      "Epoch 100: val_loss improved from 0.04050 to 0.03846, saving model to data/output/activity_single-labeled_Fold-4.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0397 - rmse: 0.1789 - mse: 0.0320 - mae: 0.1463 - val_loss: 0.0385 - val_rmse: 0.1753 - val_mse: 0.0307 - val_mae: 0.1412 - 42ms/epoch - 3ms/step\n",
      "Epoch 101/5000\n",
      "15/15 - 0s - loss: 0.0397 - rmse: 0.1788 - mse: 0.0320 - mae: 0.1475 - val_loss: 0.0372 - val_rmse: 0.1718 - val_mse: 0.0295 - val_mae: 0.1387 - 30ms/epoch - 2ms/step\n",
      "Epoch 102/5000\n",
      "15/15 - 0s - loss: 0.0388 - rmse: 0.1765 - mse: 0.0311 - mae: 0.1449 - val_loss: 0.0376 - val_rmse: 0.1732 - val_mse: 0.0300 - val_mae: 0.1408 - 26ms/epoch - 2ms/step\n",
      "Epoch 103/5000\n",
      "15/15 - 0s - loss: 0.0392 - rmse: 0.1777 - mse: 0.0316 - mae: 0.1469 - val_loss: 0.0376 - val_rmse: 0.1731 - val_mse: 0.0300 - val_mae: 0.1398 - 40ms/epoch - 3ms/step\n",
      "Epoch 104/5000\n",
      "15/15 - 0s - loss: 0.0393 - rmse: 0.1780 - mse: 0.0317 - mae: 0.1454 - val_loss: 0.0380 - val_rmse: 0.1744 - val_mse: 0.0304 - val_mae: 0.1406 - 54ms/epoch - 4ms/step\n",
      "Epoch 105/5000\n",
      "15/15 - 0s - loss: 0.0386 - rmse: 0.1765 - mse: 0.0312 - mae: 0.1458 - val_loss: 0.0375 - val_rmse: 0.1734 - val_mse: 0.0301 - val_mae: 0.1403 - 52ms/epoch - 3ms/step\n",
      "Epoch 106/5000\n",
      "15/15 - 0s - loss: 0.0389 - rmse: 0.1768 - mse: 0.0313 - mae: 0.1450 - val_loss: 0.0373 - val_rmse: 0.1722 - val_mse: 0.0297 - val_mae: 0.1390 - 64ms/epoch - 4ms/step\n",
      "Epoch 107/5000\n",
      "15/15 - 0s - loss: 0.0384 - rmse: 0.1754 - mse: 0.0308 - mae: 0.1440 - val_loss: 0.0376 - val_rmse: 0.1731 - val_mse: 0.0300 - val_mae: 0.1401 - 35ms/epoch - 2ms/step\n",
      "Epoch 108/5000\n",
      "15/15 - 0s - loss: 0.0386 - rmse: 0.1760 - mse: 0.0310 - mae: 0.1446 - val_loss: 0.0376 - val_rmse: 0.1732 - val_mse: 0.0300 - val_mae: 0.1402 - 34ms/epoch - 2ms/step\n",
      "Epoch 109/5000\n",
      "15/15 - 0s - loss: 0.0384 - rmse: 0.1754 - mse: 0.0308 - mae: 0.1447 - val_loss: 0.0375 - val_rmse: 0.1730 - val_mse: 0.0299 - val_mae: 0.1407 - 53ms/epoch - 4ms/step\n",
      "Epoch 110/5000\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.03846\n",
      "15/15 - 0s - loss: 0.0390 - rmse: 0.1771 - mse: 0.0314 - mae: 0.1451 - val_loss: 0.0387 - val_rmse: 0.1760 - val_mse: 0.0310 - val_mae: 0.1421 - 34ms/epoch - 2ms/step\n",
      "Epoch 111/5000\n",
      "15/15 - 0s - loss: 0.0386 - rmse: 0.1757 - mse: 0.0309 - mae: 0.1438 - val_loss: 0.0378 - val_rmse: 0.1735 - val_mse: 0.0301 - val_mae: 0.1398 - 37ms/epoch - 2ms/step\n",
      "Epoch 112/5000\n",
      "15/15 - 0s - loss: 0.0390 - rmse: 0.1772 - mse: 0.0314 - mae: 0.1465 - val_loss: 0.0372 - val_rmse: 0.1719 - val_mse: 0.0295 - val_mae: 0.1395 - 30ms/epoch - 2ms/step\n",
      "Epoch 113/5000\n",
      "Restoring model weights from the end of the best epoch: 93.\n",
      "15/15 - 0s - loss: 0.0394 - rmse: 0.1783 - mse: 0.0318 - mae: 0.1458 - val_loss: 0.0372 - val_rmse: 0.1719 - val_mse: 0.0295 - val_mae: 0.1391 - 30ms/epoch - 2ms/step\n",
      "Epoch 113: early stopping\n",
      "7/7 [==============================] - 0s 769us/step\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hertelj/build/local/miniforge3/envs/dfpl/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "15/15 - 0s - loss: 4.4218 - rmse: 0.5928 - mse: 0.3515 - mae: 0.4411 - val_loss: 3.9983 - val_rmse: 0.2575 - val_mse: 0.0663 - val_mae: 0.2015 - 245ms/epoch - 16ms/step\n",
      "Epoch 2/5000\n",
      "15/15 - 0s - loss: 3.8553 - rmse: 0.2713 - mse: 0.0736 - mae: 0.2195 - val_loss: 3.6396 - val_rmse: 0.2217 - val_mse: 0.0491 - val_mae: 0.1833 - 26ms/epoch - 2ms/step\n",
      "Epoch 3/5000\n",
      "15/15 - 0s - loss: 3.4819 - rmse: 0.2185 - mse: 0.0477 - mae: 0.1771 - val_loss: 3.2948 - val_rmse: 0.2197 - val_mse: 0.0483 - val_mae: 0.1907 - 40ms/epoch - 3ms/step\n",
      "Epoch 4/5000\n",
      "15/15 - 0s - loss: 3.1410 - rmse: 0.1991 - mse: 0.0397 - mae: 0.1622 - val_loss: 2.9729 - val_rmse: 0.2095 - val_mse: 0.0439 - val_mae: 0.1763 - 43ms/epoch - 3ms/step\n",
      "Epoch 5/5000\n",
      "15/15 - 0s - loss: 2.8358 - rmse: 0.1964 - mse: 0.0386 - mae: 0.1587 - val_loss: 2.6838 - val_rmse: 0.2063 - val_mse: 0.0425 - val_mae: 0.1748 - 37ms/epoch - 2ms/step\n",
      "Epoch 6/5000\n",
      "15/15 - 0s - loss: 2.5599 - rmse: 0.1939 - mse: 0.0376 - mae: 0.1580 - val_loss: 2.4232 - val_rmse: 0.2041 - val_mse: 0.0416 - val_mae: 0.1718 - 37ms/epoch - 2ms/step\n",
      "Epoch 7/5000\n",
      "15/15 - 0s - loss: 2.3116 - rmse: 0.1930 - mse: 0.0373 - mae: 0.1570 - val_loss: 2.1893 - val_rmse: 0.2045 - val_mse: 0.0418 - val_mae: 0.1720 - 35ms/epoch - 2ms/step\n",
      "Epoch 8/5000\n",
      "15/15 - 0s - loss: 2.0886 - rmse: 0.1945 - mse: 0.0378 - mae: 0.1575 - val_loss: 1.9768 - val_rmse: 0.2010 - val_mse: 0.0404 - val_mae: 0.1700 - 33ms/epoch - 2ms/step\n",
      "Epoch 9/5000\n",
      "15/15 - 0s - loss: 1.8858 - rmse: 0.1913 - mse: 0.0366 - mae: 0.1570 - val_loss: 1.7880 - val_rmse: 0.2048 - val_mse: 0.0419 - val_mae: 0.1697 - 34ms/epoch - 2ms/step\n",
      "Epoch 10/5000\n",
      "\n",
      "Epoch 10: val_loss improved from inf to 1.61566, saving model to data/output/activity_single-labeled_Fold-5.model.weights.hdf5\n",
      "15/15 - 0s - loss: 1.7022 - rmse: 0.1862 - mse: 0.0347 - mae: 0.1529 - val_loss: 1.6157 - val_rmse: 0.2026 - val_mse: 0.0410 - val_mae: 0.1695 - 48ms/epoch - 3ms/step\n",
      "Epoch 11/5000\n",
      "15/15 - 0s - loss: 1.5376 - rmse: 0.1840 - mse: 0.0339 - mae: 0.1466 - val_loss: 1.4600 - val_rmse: 0.2002 - val_mse: 0.0401 - val_mae: 0.1700 - 34ms/epoch - 2ms/step\n",
      "Epoch 12/5000\n",
      "15/15 - 0s - loss: 1.3898 - rmse: 0.1834 - mse: 0.0336 - mae: 0.1478 - val_loss: 1.3206 - val_rmse: 0.1999 - val_mse: 0.0399 - val_mae: 0.1679 - 32ms/epoch - 2ms/step\n",
      "Epoch 13/5000\n",
      "15/15 - 0s - loss: 1.2565 - rmse: 0.1827 - mse: 0.0334 - mae: 0.1488 - val_loss: 1.1942 - val_rmse: 0.1978 - val_mse: 0.0391 - val_mae: 0.1680 - 35ms/epoch - 2ms/step\n",
      "Epoch 14/5000\n",
      "15/15 - 0s - loss: 1.1374 - rmse: 0.1849 - mse: 0.0342 - mae: 0.1497 - val_loss: 1.0810 - val_rmse: 0.1980 - val_mse: 0.0392 - val_mae: 0.1675 - 37ms/epoch - 2ms/step\n",
      "Epoch 15/5000\n",
      "15/15 - 0s - loss: 1.0288 - rmse: 0.1838 - mse: 0.0338 - mae: 0.1495 - val_loss: 0.9787 - val_rmse: 0.1975 - val_mse: 0.0390 - val_mae: 0.1667 - 35ms/epoch - 2ms/step\n",
      "Epoch 16/5000\n",
      "15/15 - 0s - loss: 0.9309 - rmse: 0.1827 - mse: 0.0334 - mae: 0.1490 - val_loss: 0.8870 - val_rmse: 0.1983 - val_mse: 0.0393 - val_mae: 0.1696 - 34ms/epoch - 2ms/step\n",
      "Epoch 17/5000\n",
      "15/15 - 0s - loss: 0.8431 - rmse: 0.1829 - mse: 0.0335 - mae: 0.1508 - val_loss: 0.8041 - val_rmse: 0.1983 - val_mse: 0.0393 - val_mae: 0.1685 - 34ms/epoch - 2ms/step\n",
      "Epoch 18/5000\n",
      "15/15 - 0s - loss: 0.7649 - rmse: 0.1855 - mse: 0.0344 - mae: 0.1492 - val_loss: 0.7295 - val_rmse: 0.1987 - val_mse: 0.0395 - val_mae: 0.1689 - 34ms/epoch - 2ms/step\n",
      "Epoch 19/5000\n",
      "15/15 - 0s - loss: 0.6920 - rmse: 0.1812 - mse: 0.0328 - mae: 0.1468 - val_loss: 0.6622 - val_rmse: 0.1988 - val_mse: 0.0395 - val_mae: 0.1694 - 37ms/epoch - 2ms/step\n",
      "Epoch 20/5000\n",
      "\n",
      "Epoch 20: val_loss improved from 1.61566 to 0.60173, saving model to data/output/activity_single-labeled_Fold-5.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.6281 - rmse: 0.1822 - mse: 0.0332 - mae: 0.1485 - val_loss: 0.6017 - val_rmse: 0.1996 - val_mse: 0.0398 - val_mae: 0.1696 - 42ms/epoch - 3ms/step\n",
      "Epoch 21/5000\n",
      "15/15 - 0s - loss: 0.5701 - rmse: 0.1825 - mse: 0.0333 - mae: 0.1496 - val_loss: 0.5469 - val_rmse: 0.1994 - val_mse: 0.0398 - val_mae: 0.1703 - 34ms/epoch - 2ms/step\n",
      "Epoch 22/5000\n",
      "15/15 - 0s - loss: 0.5184 - rmse: 0.1839 - mse: 0.0338 - mae: 0.1498 - val_loss: 0.4972 - val_rmse: 0.1985 - val_mse: 0.0394 - val_mae: 0.1688 - 33ms/epoch - 2ms/step\n",
      "Epoch 23/5000\n",
      "15/15 - 0s - loss: 0.4709 - rmse: 0.1829 - mse: 0.0335 - mae: 0.1495 - val_loss: 0.4530 - val_rmse: 0.1991 - val_mse: 0.0397 - val_mae: 0.1679 - 42ms/epoch - 3ms/step\n",
      "Epoch 24/5000\n",
      "15/15 - 0s - loss: 0.4277 - rmse: 0.1807 - mse: 0.0327 - mae: 0.1482 - val_loss: 0.4126 - val_rmse: 0.1982 - val_mse: 0.0393 - val_mae: 0.1686 - 45ms/epoch - 3ms/step\n",
      "Epoch 25/5000\n",
      "15/15 - 0s - loss: 0.3898 - rmse: 0.1814 - mse: 0.0329 - mae: 0.1472 - val_loss: 0.3768 - val_rmse: 0.1988 - val_mse: 0.0395 - val_mae: 0.1690 - 35ms/epoch - 2ms/step\n",
      "Epoch 26/5000\n",
      "15/15 - 0s - loss: 0.3555 - rmse: 0.1821 - mse: 0.0332 - mae: 0.1499 - val_loss: 0.3441 - val_rmse: 0.1985 - val_mse: 0.0394 - val_mae: 0.1683 - 32ms/epoch - 2ms/step\n",
      "Epoch 27/5000\n",
      "15/15 - 0s - loss: 0.3244 - rmse: 0.1823 - mse: 0.0332 - mae: 0.1497 - val_loss: 0.3151 - val_rmse: 0.1995 - val_mse: 0.0398 - val_mae: 0.1680 - 53ms/epoch - 4ms/step\n",
      "Epoch 28/5000\n",
      "15/15 - 0s - loss: 0.2967 - rmse: 0.1832 - mse: 0.0336 - mae: 0.1482 - val_loss: 0.2889 - val_rmse: 0.2005 - val_mse: 0.0402 - val_mae: 0.1729 - 36ms/epoch - 2ms/step\n",
      "Epoch 29/5000\n",
      "15/15 - 0s - loss: 0.2703 - rmse: 0.1801 - mse: 0.0324 - mae: 0.1482 - val_loss: 0.2648 - val_rmse: 0.1994 - val_mse: 0.0398 - val_mae: 0.1673 - 38ms/epoch - 3ms/step\n",
      "Epoch 30/5000\n",
      "\n",
      "Epoch 30: val_loss improved from 0.60173 to 0.24253, saving model to data/output/activity_single-labeled_Fold-5.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.2481 - rmse: 0.1816 - mse: 0.0330 - mae: 0.1485 - val_loss: 0.2425 - val_rmse: 0.1977 - val_mse: 0.0391 - val_mae: 0.1701 - 42ms/epoch - 3ms/step\n",
      "Epoch 31/5000\n",
      "15/15 - 0s - loss: 0.2279 - rmse: 0.1824 - mse: 0.0333 - mae: 0.1506 - val_loss: 0.2233 - val_rmse: 0.1979 - val_mse: 0.0392 - val_mae: 0.1682 - 33ms/epoch - 2ms/step\n",
      "Epoch 32/5000\n",
      "15/15 - 0s - loss: 0.2085 - rmse: 0.1802 - mse: 0.0325 - mae: 0.1484 - val_loss: 0.2057 - val_rmse: 0.1975 - val_mse: 0.0390 - val_mae: 0.1684 - 35ms/epoch - 2ms/step\n",
      "Epoch 33/5000\n",
      "15/15 - 0s - loss: 0.1917 - rmse: 0.1792 - mse: 0.0321 - mae: 0.1460 - val_loss: 0.1898 - val_rmse: 0.1966 - val_mse: 0.0387 - val_mae: 0.1673 - 54ms/epoch - 4ms/step\n",
      "Epoch 34/5000\n",
      "15/15 - 0s - loss: 0.1771 - rmse: 0.1804 - mse: 0.0326 - mae: 0.1479 - val_loss: 0.1756 - val_rmse: 0.1969 - val_mse: 0.0388 - val_mae: 0.1689 - 45ms/epoch - 3ms/step\n",
      "Epoch 35/5000\n",
      "15/15 - 0s - loss: 0.1631 - rmse: 0.1792 - mse: 0.0321 - mae: 0.1475 - val_loss: 0.1627 - val_rmse: 0.1966 - val_mse: 0.0386 - val_mae: 0.1678 - 33ms/epoch - 2ms/step\n",
      "Epoch 36/5000\n",
      "15/15 - 0s - loss: 0.1514 - rmse: 0.1808 - mse: 0.0327 - mae: 0.1496 - val_loss: 0.1516 - val_rmse: 0.1977 - val_mse: 0.0391 - val_mae: 0.1685 - 55ms/epoch - 4ms/step\n",
      "Epoch 37/5000\n",
      "15/15 - 0s - loss: 0.1401 - rmse: 0.1798 - mse: 0.0323 - mae: 0.1477 - val_loss: 0.1410 - val_rmse: 0.1970 - val_mse: 0.0388 - val_mae: 0.1668 - 35ms/epoch - 2ms/step\n",
      "Epoch 38/5000\n",
      "15/15 - 0s - loss: 0.1307 - rmse: 0.1809 - mse: 0.0327 - mae: 0.1471 - val_loss: 0.1324 - val_rmse: 0.1989 - val_mse: 0.0396 - val_mae: 0.1706 - 38ms/epoch - 3ms/step\n",
      "Epoch 39/5000\n",
      "15/15 - 0s - loss: 0.1209 - rmse: 0.1788 - mse: 0.0320 - mae: 0.1473 - val_loss: 0.1242 - val_rmse: 0.1995 - val_mse: 0.0398 - val_mae: 0.1664 - 31ms/epoch - 2ms/step\n",
      "Epoch 40/5000\n",
      "\n",
      "Epoch 40: val_loss improved from 0.24253 to 0.11650, saving model to data/output/activity_single-labeled_Fold-5.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.1131 - rmse: 0.1797 - mse: 0.0323 - mae: 0.1469 - val_loss: 0.1165 - val_rmse: 0.1994 - val_mse: 0.0398 - val_mae: 0.1711 - 39ms/epoch - 3ms/step\n",
      "Epoch 41/5000\n",
      "15/15 - 0s - loss: 0.1060 - rmse: 0.1799 - mse: 0.0324 - mae: 0.1462 - val_loss: 0.1088 - val_rmse: 0.1972 - val_mse: 0.0389 - val_mae: 0.1673 - 27ms/epoch - 2ms/step\n",
      "Epoch 42/5000\n",
      "15/15 - 0s - loss: 0.0992 - rmse: 0.1790 - mse: 0.0320 - mae: 0.1462 - val_loss: 0.1027 - val_rmse: 0.1973 - val_mse: 0.0389 - val_mae: 0.1676 - 29ms/epoch - 2ms/step\n",
      "Epoch 43/5000\n",
      "15/15 - 0s - loss: 0.0933 - rmse: 0.1794 - mse: 0.0322 - mae: 0.1478 - val_loss: 0.0968 - val_rmse: 0.1968 - val_mse: 0.0387 - val_mae: 0.1677 - 29ms/epoch - 2ms/step\n",
      "Epoch 44/5000\n",
      "15/15 - 0s - loss: 0.0878 - rmse: 0.1789 - mse: 0.0320 - mae: 0.1475 - val_loss: 0.0916 - val_rmse: 0.1961 - val_mse: 0.0384 - val_mae: 0.1670 - 27ms/epoch - 2ms/step\n",
      "Epoch 45/5000\n",
      "15/15 - 0s - loss: 0.0827 - rmse: 0.1777 - mse: 0.0316 - mae: 0.1445 - val_loss: 0.0870 - val_rmse: 0.1959 - val_mse: 0.0384 - val_mae: 0.1666 - 31ms/epoch - 2ms/step\n",
      "Epoch 46/5000\n",
      "15/15 - 0s - loss: 0.0785 - rmse: 0.1782 - mse: 0.0317 - mae: 0.1457 - val_loss: 0.0834 - val_rmse: 0.1971 - val_mse: 0.0388 - val_mae: 0.1657 - 36ms/epoch - 2ms/step\n",
      "Epoch 47/5000\n",
      "15/15 - 0s - loss: 0.0745 - rmse: 0.1778 - mse: 0.0316 - mae: 0.1460 - val_loss: 0.0789 - val_rmse: 0.1949 - val_mse: 0.0380 - val_mae: 0.1653 - 54ms/epoch - 4ms/step\n",
      "Epoch 48/5000\n",
      "15/15 - 0s - loss: 0.0713 - rmse: 0.1790 - mse: 0.0320 - mae: 0.1462 - val_loss: 0.0758 - val_rmse: 0.1958 - val_mse: 0.0383 - val_mae: 0.1659 - 55ms/epoch - 4ms/step\n",
      "Epoch 49/5000\n",
      "15/15 - 0s - loss: 0.0680 - rmse: 0.1787 - mse: 0.0319 - mae: 0.1456 - val_loss: 0.0727 - val_rmse: 0.1954 - val_mse: 0.0382 - val_mae: 0.1673 - 58ms/epoch - 4ms/step\n",
      "Epoch 50/5000\n",
      "\n",
      "Epoch 50: val_loss improved from 0.11650 to 0.06986, saving model to data/output/activity_single-labeled_Fold-5.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0652 - rmse: 0.1785 - mse: 0.0319 - mae: 0.1457 - val_loss: 0.0699 - val_rmse: 0.1949 - val_mse: 0.0380 - val_mae: 0.1658 - 45ms/epoch - 3ms/step\n",
      "Epoch 51/5000\n",
      "15/15 - 0s - loss: 0.0623 - rmse: 0.1778 - mse: 0.0316 - mae: 0.1449 - val_loss: 0.0678 - val_rmse: 0.1960 - val_mse: 0.0384 - val_mae: 0.1661 - 34ms/epoch - 2ms/step\n",
      "Epoch 52/5000\n",
      "15/15 - 0s - loss: 0.0600 - rmse: 0.1781 - mse: 0.0317 - mae: 0.1466 - val_loss: 0.0654 - val_rmse: 0.1957 - val_mse: 0.0383 - val_mae: 0.1658 - 41ms/epoch - 3ms/step\n",
      "Epoch 53/5000\n",
      "15/15 - 0s - loss: 0.0577 - rmse: 0.1773 - mse: 0.0314 - mae: 0.1450 - val_loss: 0.0638 - val_rmse: 0.1963 - val_mse: 0.0385 - val_mae: 0.1662 - 37ms/epoch - 2ms/step\n",
      "Epoch 54/5000\n",
      "15/15 - 0s - loss: 0.0561 - rmse: 0.1782 - mse: 0.0318 - mae: 0.1459 - val_loss: 0.0625 - val_rmse: 0.1979 - val_mse: 0.0392 - val_mae: 0.1701 - 70ms/epoch - 5ms/step\n",
      "Epoch 55/5000\n",
      "15/15 - 0s - loss: 0.0548 - rmse: 0.1791 - mse: 0.0321 - mae: 0.1460 - val_loss: 0.0606 - val_rmse: 0.1968 - val_mse: 0.0387 - val_mae: 0.1652 - 43ms/epoch - 3ms/step\n",
      "Epoch 56/5000\n",
      "15/15 - 0s - loss: 0.0540 - rmse: 0.1810 - mse: 0.0328 - mae: 0.1482 - val_loss: 0.0610 - val_rmse: 0.2016 - val_mse: 0.0406 - val_mae: 0.1666 - 39ms/epoch - 3ms/step\n",
      "Epoch 57/5000\n",
      "15/15 - 0s - loss: 0.0512 - rmse: 0.1776 - mse: 0.0315 - mae: 0.1450 - val_loss: 0.0580 - val_rmse: 0.1976 - val_mse: 0.0390 - val_mae: 0.1682 - 39ms/epoch - 3ms/step\n",
      "Epoch 58/5000\n",
      "15/15 - 0s - loss: 0.0501 - rmse: 0.1777 - mse: 0.0316 - mae: 0.1451 - val_loss: 0.0565 - val_rmse: 0.1966 - val_mse: 0.0387 - val_mae: 0.1666 - 55ms/epoch - 4ms/step\n",
      "Epoch 59/5000\n",
      "15/15 - 0s - loss: 0.0483 - rmse: 0.1758 - mse: 0.0309 - mae: 0.1441 - val_loss: 0.0559 - val_rmse: 0.1975 - val_mse: 0.0390 - val_mae: 0.1659 - 42ms/epoch - 3ms/step\n",
      "Epoch 60/5000\n",
      "\n",
      "Epoch 60: val_loss improved from 0.06986 to 0.05443, saving model to data/output/activity_single-labeled_Fold-5.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0476 - rmse: 0.1763 - mse: 0.0311 - mae: 0.1435 - val_loss: 0.0544 - val_rmse: 0.1961 - val_mse: 0.0384 - val_mae: 0.1657 - 48ms/epoch - 3ms/step\n",
      "Epoch 61/5000\n",
      "15/15 - 0s - loss: 0.0466 - rmse: 0.1762 - mse: 0.0310 - mae: 0.1440 - val_loss: 0.0532 - val_rmse: 0.1953 - val_mse: 0.0381 - val_mae: 0.1653 - 52ms/epoch - 3ms/step\n",
      "Epoch 62/5000\n",
      "15/15 - 0s - loss: 0.0457 - rmse: 0.1760 - mse: 0.0310 - mae: 0.1439 - val_loss: 0.0528 - val_rmse: 0.1962 - val_mse: 0.0385 - val_mae: 0.1662 - 40ms/epoch - 3ms/step\n",
      "Epoch 63/5000\n",
      "15/15 - 0s - loss: 0.0446 - rmse: 0.1749 - mse: 0.0306 - mae: 0.1414 - val_loss: 0.0520 - val_rmse: 0.1958 - val_mse: 0.0383 - val_mae: 0.1650 - 38ms/epoch - 3ms/step\n",
      "Epoch 64/5000\n",
      "15/15 - 0s - loss: 0.0447 - rmse: 0.1775 - mse: 0.0315 - mae: 0.1454 - val_loss: 0.0514 - val_rmse: 0.1963 - val_mse: 0.0385 - val_mae: 0.1661 - 42ms/epoch - 3ms/step\n",
      "Epoch 65/5000\n",
      "15/15 - 0s - loss: 0.0438 - rmse: 0.1764 - mse: 0.0311 - mae: 0.1442 - val_loss: 0.0502 - val_rmse: 0.1944 - val_mse: 0.0378 - val_mae: 0.1647 - 71ms/epoch - 5ms/step\n",
      "Epoch 66/5000\n",
      "15/15 - 0s - loss: 0.0428 - rmse: 0.1750 - mse: 0.0306 - mae: 0.1421 - val_loss: 0.0498 - val_rmse: 0.1946 - val_mse: 0.0379 - val_mae: 0.1644 - 40ms/epoch - 3ms/step\n",
      "Epoch 67/5000\n",
      "15/15 - 0s - loss: 0.0427 - rmse: 0.1762 - mse: 0.0311 - mae: 0.1434 - val_loss: 0.0495 - val_rmse: 0.1953 - val_mse: 0.0381 - val_mae: 0.1644 - 63ms/epoch - 4ms/step\n",
      "Epoch 68/5000\n",
      "15/15 - 0s - loss: 0.0425 - rmse: 0.1768 - mse: 0.0313 - mae: 0.1435 - val_loss: 0.0489 - val_rmse: 0.1947 - val_mse: 0.0379 - val_mae: 0.1648 - 40ms/epoch - 3ms/step\n",
      "Epoch 69/5000\n",
      "15/15 - 0s - loss: 0.0416 - rmse: 0.1755 - mse: 0.0308 - mae: 0.1444 - val_loss: 0.0494 - val_rmse: 0.1969 - val_mse: 0.0388 - val_mae: 0.1653 - 38ms/epoch - 3ms/step\n",
      "Epoch 70/5000\n",
      "\n",
      "Epoch 70: val_loss improved from 0.05443 to 0.04864, saving model to data/output/activity_single-labeled_Fold-5.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0415 - rmse: 0.1763 - mse: 0.0311 - mae: 0.1438 - val_loss: 0.0486 - val_rmse: 0.1960 - val_mse: 0.0384 - val_mae: 0.1649 - 41ms/epoch - 3ms/step\n",
      "Epoch 71/5000\n",
      "15/15 - 0s - loss: 0.0412 - rmse: 0.1765 - mse: 0.0311 - mae: 0.1438 - val_loss: 0.0487 - val_rmse: 0.1968 - val_mse: 0.0387 - val_mae: 0.1661 - 46ms/epoch - 3ms/step\n",
      "Epoch 72/5000\n",
      "15/15 - 0s - loss: 0.0406 - rmse: 0.1753 - mse: 0.0307 - mae: 0.1424 - val_loss: 0.0480 - val_rmse: 0.1955 - val_mse: 0.0382 - val_mae: 0.1647 - 56ms/epoch - 4ms/step\n",
      "Epoch 73/5000\n",
      "15/15 - 0s - loss: 0.0401 - rmse: 0.1746 - mse: 0.0305 - mae: 0.1422 - val_loss: 0.0472 - val_rmse: 0.1941 - val_mse: 0.0377 - val_mae: 0.1628 - 42ms/epoch - 3ms/step\n",
      "Epoch 74/5000\n",
      "15/15 - 0s - loss: 0.0406 - rmse: 0.1767 - mse: 0.0312 - mae: 0.1436 - val_loss: 0.0475 - val_rmse: 0.1956 - val_mse: 0.0383 - val_mae: 0.1640 - 39ms/epoch - 3ms/step\n",
      "Epoch 75/5000\n",
      "15/15 - 0s - loss: 0.0398 - rmse: 0.1754 - mse: 0.0308 - mae: 0.1431 - val_loss: 0.0474 - val_rmse: 0.1960 - val_mse: 0.0384 - val_mae: 0.1653 - 46ms/epoch - 3ms/step\n",
      "Epoch 76/5000\n",
      "15/15 - 0s - loss: 0.0395 - rmse: 0.1751 - mse: 0.0307 - mae: 0.1436 - val_loss: 0.0469 - val_rmse: 0.1953 - val_mse: 0.0381 - val_mae: 0.1643 - 39ms/epoch - 3ms/step\n",
      "Epoch 77/5000\n",
      "15/15 - 0s - loss: 0.0395 - rmse: 0.1757 - mse: 0.0309 - mae: 0.1426 - val_loss: 0.0466 - val_rmse: 0.1949 - val_mse: 0.0380 - val_mae: 0.1658 - 40ms/epoch - 3ms/step\n",
      "Epoch 78/5000\n",
      "15/15 - 0s - loss: 0.0395 - rmse: 0.1756 - mse: 0.0308 - mae: 0.1429 - val_loss: 0.0464 - val_rmse: 0.1944 - val_mse: 0.0378 - val_mae: 0.1632 - 55ms/epoch - 4ms/step\n",
      "Epoch 79/5000\n",
      "15/15 - 0s - loss: 0.0394 - rmse: 0.1759 - mse: 0.0309 - mae: 0.1429 - val_loss: 0.0462 - val_rmse: 0.1948 - val_mse: 0.0379 - val_mae: 0.1649 - 59ms/epoch - 4ms/step\n",
      "Epoch 80/5000\n",
      "\n",
      "Epoch 80: val_loss improved from 0.04864 to 0.04713, saving model to data/output/activity_single-labeled_Fold-5.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0390 - rmse: 0.1750 - mse: 0.0306 - mae: 0.1423 - val_loss: 0.0471 - val_rmse: 0.1970 - val_mse: 0.0388 - val_mae: 0.1656 - 71ms/epoch - 5ms/step\n",
      "Epoch 81/5000\n",
      "15/15 - 0s - loss: 0.0390 - rmse: 0.1753 - mse: 0.0307 - mae: 0.1430 - val_loss: 0.0466 - val_rmse: 0.1959 - val_mse: 0.0384 - val_mae: 0.1642 - 47ms/epoch - 3ms/step\n",
      "Epoch 82/5000\n",
      "15/15 - 0s - loss: 0.0396 - rmse: 0.1773 - mse: 0.0314 - mae: 0.1443 - val_loss: 0.0460 - val_rmse: 0.1949 - val_mse: 0.0380 - val_mae: 0.1643 - 63ms/epoch - 4ms/step\n",
      "Epoch 83/5000\n",
      "15/15 - 0s - loss: 0.0395 - rmse: 0.1777 - mse: 0.0316 - mae: 0.1449 - val_loss: 0.0466 - val_rmse: 0.1967 - val_mse: 0.0387 - val_mae: 0.1637 - 55ms/epoch - 4ms/step\n",
      "Epoch 84/5000\n",
      "15/15 - 0s - loss: 0.0387 - rmse: 0.1753 - mse: 0.0307 - mae: 0.1425 - val_loss: 0.0464 - val_rmse: 0.1961 - val_mse: 0.0385 - val_mae: 0.1645 - 42ms/epoch - 3ms/step\n",
      "Epoch 85/5000\n",
      "15/15 - 0s - loss: 0.0381 - rmse: 0.1740 - mse: 0.0303 - mae: 0.1410 - val_loss: 0.0466 - val_rmse: 0.1970 - val_mse: 0.0388 - val_mae: 0.1653 - 39ms/epoch - 3ms/step\n",
      "Epoch 86/5000\n",
      "15/15 - 0s - loss: 0.0383 - rmse: 0.1745 - mse: 0.0305 - mae: 0.1422 - val_loss: 0.0466 - val_rmse: 0.1970 - val_mse: 0.0388 - val_mae: 0.1655 - 41ms/epoch - 3ms/step\n",
      "Epoch 87/5000\n",
      "15/15 - 0s - loss: 0.0380 - rmse: 0.1739 - mse: 0.0303 - mae: 0.1414 - val_loss: 0.0459 - val_rmse: 0.1956 - val_mse: 0.0383 - val_mae: 0.1651 - 40ms/epoch - 3ms/step\n",
      "Epoch 88/5000\n",
      "15/15 - 0s - loss: 0.0379 - rmse: 0.1737 - mse: 0.0302 - mae: 0.1414 - val_loss: 0.0455 - val_rmse: 0.1945 - val_mse: 0.0378 - val_mae: 0.1637 - 42ms/epoch - 3ms/step\n",
      "Epoch 89/5000\n",
      "15/15 - 0s - loss: 0.0384 - rmse: 0.1753 - mse: 0.0307 - mae: 0.1425 - val_loss: 0.0461 - val_rmse: 0.1962 - val_mse: 0.0385 - val_mae: 0.1647 - 40ms/epoch - 3ms/step\n",
      "Epoch 90/5000\n",
      "\n",
      "Epoch 90: val_loss improved from 0.04713 to 0.04665, saving model to data/output/activity_single-labeled_Fold-5.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0382 - rmse: 0.1749 - mse: 0.0306 - mae: 0.1421 - val_loss: 0.0466 - val_rmse: 0.1979 - val_mse: 0.0392 - val_mae: 0.1689 - 45ms/epoch - 3ms/step\n",
      "Epoch 91/5000\n",
      "15/15 - 0s - loss: 0.0378 - rmse: 0.1740 - mse: 0.0303 - mae: 0.1419 - val_loss: 0.0460 - val_rmse: 0.1960 - val_mse: 0.0384 - val_mae: 0.1656 - 29ms/epoch - 2ms/step\n",
      "Epoch 92/5000\n",
      "15/15 - 0s - loss: 0.0375 - rmse: 0.1730 - mse: 0.0299 - mae: 0.1407 - val_loss: 0.0457 - val_rmse: 0.1954 - val_mse: 0.0382 - val_mae: 0.1628 - 32ms/epoch - 2ms/step\n",
      "Epoch 93/5000\n",
      "15/15 - 0s - loss: 0.0379 - rmse: 0.1743 - mse: 0.0304 - mae: 0.1420 - val_loss: 0.0460 - val_rmse: 0.1963 - val_mse: 0.0385 - val_mae: 0.1656 - 32ms/epoch - 2ms/step\n",
      "Epoch 94/5000\n",
      "15/15 - 0s - loss: 0.0374 - rmse: 0.1729 - mse: 0.0299 - mae: 0.1415 - val_loss: 0.0466 - val_rmse: 0.1977 - val_mse: 0.0391 - val_mae: 0.1643 - 31ms/epoch - 2ms/step\n",
      "Epoch 95/5000\n",
      "15/15 - 0s - loss: 0.0380 - rmse: 0.1747 - mse: 0.0305 - mae: 0.1430 - val_loss: 0.0463 - val_rmse: 0.1972 - val_mse: 0.0389 - val_mae: 0.1648 - 31ms/epoch - 2ms/step\n",
      "Epoch 96/5000\n",
      "15/15 - 0s - loss: 0.0378 - rmse: 0.1742 - mse: 0.0303 - mae: 0.1412 - val_loss: 0.0451 - val_rmse: 0.1941 - val_mse: 0.0377 - val_mae: 0.1632 - 54ms/epoch - 4ms/step\n",
      "Epoch 97/5000\n",
      "15/15 - 0s - loss: 0.0375 - rmse: 0.1735 - mse: 0.0301 - mae: 0.1413 - val_loss: 0.0456 - val_rmse: 0.1955 - val_mse: 0.0382 - val_mae: 0.1650 - 53ms/epoch - 4ms/step\n",
      "Epoch 98/5000\n",
      "15/15 - 0s - loss: 0.0379 - rmse: 0.1748 - mse: 0.0305 - mae: 0.1417 - val_loss: 0.0479 - val_rmse: 0.2015 - val_mse: 0.0406 - val_mae: 0.1706 - 58ms/epoch - 4ms/step\n",
      "Epoch 99/5000\n",
      "15/15 - 0s - loss: 0.0387 - rmse: 0.1771 - mse: 0.0314 - mae: 0.1436 - val_loss: 0.0463 - val_rmse: 0.1975 - val_mse: 0.0390 - val_mae: 0.1680 - 50ms/epoch - 3ms/step\n",
      "Epoch 100/5000\n",
      "\n",
      "Epoch 100: val_loss improved from 0.04665 to 0.04566, saving model to data/output/activity_single-labeled_Fold-5.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0375 - rmse: 0.1739 - mse: 0.0302 - mae: 0.1426 - val_loss: 0.0457 - val_rmse: 0.1958 - val_mse: 0.0383 - val_mae: 0.1646 - 80ms/epoch - 5ms/step\n",
      "Epoch 101/5000\n",
      "15/15 - 0s - loss: 0.0376 - rmse: 0.1738 - mse: 0.0302 - mae: 0.1420 - val_loss: 0.0458 - val_rmse: 0.1961 - val_mse: 0.0384 - val_mae: 0.1643 - 38ms/epoch - 3ms/step\n",
      "Epoch 102/5000\n",
      "15/15 - 0s - loss: 0.0371 - rmse: 0.1725 - mse: 0.0298 - mae: 0.1404 - val_loss: 0.0461 - val_rmse: 0.1971 - val_mse: 0.0388 - val_mae: 0.1643 - 36ms/epoch - 2ms/step\n",
      "Epoch 103/5000\n",
      "15/15 - 0s - loss: 0.0375 - rmse: 0.1736 - mse: 0.0301 - mae: 0.1414 - val_loss: 0.0454 - val_rmse: 0.1952 - val_mse: 0.0381 - val_mae: 0.1631 - 43ms/epoch - 3ms/step\n",
      "Epoch 104/5000\n",
      "15/15 - 0s - loss: 0.0377 - rmse: 0.1741 - mse: 0.0303 - mae: 0.1417 - val_loss: 0.0476 - val_rmse: 0.2007 - val_mse: 0.0403 - val_mae: 0.1659 - 60ms/epoch - 4ms/step\n",
      "Epoch 105/5000\n",
      "15/15 - 0s - loss: 0.0375 - rmse: 0.1736 - mse: 0.0302 - mae: 0.1398 - val_loss: 0.0483 - val_rmse: 0.2024 - val_mse: 0.0410 - val_mae: 0.1664 - 71ms/epoch - 5ms/step\n",
      "Epoch 106/5000\n",
      "15/15 - 0s - loss: 0.0374 - rmse: 0.1739 - mse: 0.0302 - mae: 0.1413 - val_loss: 0.0451 - val_rmse: 0.1949 - val_mse: 0.0380 - val_mae: 0.1643 - 41ms/epoch - 3ms/step\n",
      "Epoch 107/5000\n",
      "15/15 - 0s - loss: 0.0369 - rmse: 0.1725 - mse: 0.0298 - mae: 0.1412 - val_loss: 0.0450 - val_rmse: 0.1943 - val_mse: 0.0377 - val_mae: 0.1629 - 37ms/epoch - 2ms/step\n",
      "Epoch 108/5000\n",
      "15/15 - 0s - loss: 0.0374 - rmse: 0.1733 - mse: 0.0300 - mae: 0.1397 - val_loss: 0.0463 - val_rmse: 0.1975 - val_mse: 0.0390 - val_mae: 0.1656 - 53ms/epoch - 4ms/step\n",
      "Epoch 109/5000\n",
      "15/15 - 0s - loss: 0.0369 - rmse: 0.1721 - mse: 0.0296 - mae: 0.1401 - val_loss: 0.0450 - val_rmse: 0.1943 - val_mse: 0.0378 - val_mae: 0.1625 - 34ms/epoch - 2ms/step\n",
      "Epoch 110/5000\n",
      "\n",
      "Epoch 110: val_loss did not improve from 0.04566\n",
      "15/15 - 0s - loss: 0.0380 - rmse: 0.1754 - mse: 0.0307 - mae: 0.1421 - val_loss: 0.0458 - val_rmse: 0.1965 - val_mse: 0.0386 - val_mae: 0.1634 - 36ms/epoch - 2ms/step\n",
      "Epoch 111/5000\n",
      "15/15 - 0s - loss: 0.0369 - rmse: 0.1724 - mse: 0.0297 - mae: 0.1407 - val_loss: 0.0479 - val_rmse: 0.2020 - val_mse: 0.0408 - val_mae: 0.1664 - 37ms/epoch - 2ms/step\n",
      "Epoch 112/5000\n",
      "15/15 - 0s - loss: 0.0370 - rmse: 0.1728 - mse: 0.0299 - mae: 0.1409 - val_loss: 0.0460 - val_rmse: 0.1971 - val_mse: 0.0389 - val_mae: 0.1642 - 36ms/epoch - 2ms/step\n",
      "Epoch 113/5000\n",
      "15/15 - 0s - loss: 0.0376 - rmse: 0.1743 - mse: 0.0304 - mae: 0.1401 - val_loss: 0.0459 - val_rmse: 0.1969 - val_mse: 0.0388 - val_mae: 0.1633 - 35ms/epoch - 2ms/step\n",
      "Epoch 114/5000\n",
      "15/15 - 0s - loss: 0.0387 - rmse: 0.1774 - mse: 0.0315 - mae: 0.1442 - val_loss: 0.0459 - val_rmse: 0.1967 - val_mse: 0.0387 - val_mae: 0.1641 - 49ms/epoch - 3ms/step\n",
      "Epoch 115/5000\n",
      "15/15 - 0s - loss: 0.0376 - rmse: 0.1744 - mse: 0.0304 - mae: 0.1417 - val_loss: 0.0455 - val_rmse: 0.1960 - val_mse: 0.0384 - val_mae: 0.1642 - 34ms/epoch - 2ms/step\n",
      "Epoch 116/5000\n",
      "15/15 - 0s - loss: 0.0373 - rmse: 0.1736 - mse: 0.0301 - mae: 0.1410 - val_loss: 0.0466 - val_rmse: 0.1986 - val_mse: 0.0394 - val_mae: 0.1676 - 34ms/epoch - 2ms/step\n",
      "Epoch 117/5000\n",
      "15/15 - 0s - loss: 0.0374 - rmse: 0.1736 - mse: 0.0301 - mae: 0.1407 - val_loss: 0.0447 - val_rmse: 0.1935 - val_mse: 0.0374 - val_mae: 0.1624 - 37ms/epoch - 2ms/step\n",
      "Epoch 118/5000\n",
      "15/15 - 0s - loss: 0.0375 - rmse: 0.1743 - mse: 0.0304 - mae: 0.1419 - val_loss: 0.0472 - val_rmse: 0.2002 - val_mse: 0.0401 - val_mae: 0.1651 - 39ms/epoch - 3ms/step\n",
      "Epoch 119/5000\n",
      "15/15 - 0s - loss: 0.0392 - rmse: 0.1790 - mse: 0.0321 - mae: 0.1434 - val_loss: 0.0487 - val_rmse: 0.2037 - val_mse: 0.0415 - val_mae: 0.1677 - 45ms/epoch - 3ms/step\n",
      "Epoch 120/5000\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.04566\n",
      "15/15 - 0s - loss: 0.0370 - rmse: 0.1727 - mse: 0.0298 - mae: 0.1400 - val_loss: 0.0458 - val_rmse: 0.1965 - val_mse: 0.0386 - val_mae: 0.1641 - 39ms/epoch - 3ms/step\n",
      "Epoch 121/5000\n",
      "15/15 - 0s - loss: 0.0370 - rmse: 0.1725 - mse: 0.0298 - mae: 0.1405 - val_loss: 0.0449 - val_rmse: 0.1941 - val_mse: 0.0377 - val_mae: 0.1627 - 38ms/epoch - 3ms/step\n",
      "Epoch 122/5000\n",
      "15/15 - 0s - loss: 0.0369 - rmse: 0.1723 - mse: 0.0297 - mae: 0.1398 - val_loss: 0.0457 - val_rmse: 0.1962 - val_mse: 0.0385 - val_mae: 0.1635 - 36ms/epoch - 2ms/step\n",
      "Epoch 123/5000\n",
      "15/15 - 0s - loss: 0.0372 - rmse: 0.1733 - mse: 0.0300 - mae: 0.1416 - val_loss: 0.0458 - val_rmse: 0.1966 - val_mse: 0.0387 - val_mae: 0.1632 - 30ms/epoch - 2ms/step\n",
      "Epoch 124/5000\n",
      "15/15 - 0s - loss: 0.0367 - rmse: 0.1721 - mse: 0.0296 - mae: 0.1396 - val_loss: 0.0445 - val_rmse: 0.1934 - val_mse: 0.0374 - val_mae: 0.1616 - 30ms/epoch - 2ms/step\n",
      "Epoch 125/5000\n",
      "15/15 - 0s - loss: 0.0372 - rmse: 0.1733 - mse: 0.0300 - mae: 0.1387 - val_loss: 0.0457 - val_rmse: 0.1964 - val_mse: 0.0386 - val_mae: 0.1650 - 31ms/epoch - 2ms/step\n",
      "Epoch 126/5000\n",
      "15/15 - 0s - loss: 0.0368 - rmse: 0.1725 - mse: 0.0298 - mae: 0.1397 - val_loss: 0.0456 - val_rmse: 0.1964 - val_mse: 0.0386 - val_mae: 0.1660 - 31ms/epoch - 2ms/step\n",
      "Epoch 127/5000\n",
      "15/15 - 0s - loss: 0.0368 - rmse: 0.1722 - mse: 0.0296 - mae: 0.1394 - val_loss: 0.0454 - val_rmse: 0.1957 - val_mse: 0.0383 - val_mae: 0.1637 - 34ms/epoch - 2ms/step\n",
      "Epoch 128/5000\n",
      "15/15 - 0s - loss: 0.0367 - rmse: 0.1718 - mse: 0.0295 - mae: 0.1400 - val_loss: 0.0451 - val_rmse: 0.1949 - val_mse: 0.0380 - val_mae: 0.1628 - 30ms/epoch - 2ms/step\n",
      "Epoch 129/5000\n",
      "15/15 - 0s - loss: 0.0367 - rmse: 0.1720 - mse: 0.0296 - mae: 0.1392 - val_loss: 0.0464 - val_rmse: 0.1983 - val_mse: 0.0393 - val_mae: 0.1652 - 31ms/epoch - 2ms/step\n",
      "Epoch 130/5000\n",
      "\n",
      "Epoch 130: val_loss did not improve from 0.04566\n",
      "15/15 - 0s - loss: 0.0371 - rmse: 0.1731 - mse: 0.0299 - mae: 0.1409 - val_loss: 0.0458 - val_rmse: 0.1966 - val_mse: 0.0387 - val_mae: 0.1637 - 46ms/epoch - 3ms/step\n",
      "Epoch 131/5000\n",
      "15/15 - 0s - loss: 0.0371 - rmse: 0.1732 - mse: 0.0300 - mae: 0.1405 - val_loss: 0.0457 - val_rmse: 0.1965 - val_mse: 0.0386 - val_mae: 0.1645 - 57ms/epoch - 4ms/step\n",
      "Epoch 132/5000\n",
      "15/15 - 0s - loss: 0.0370 - rmse: 0.1728 - mse: 0.0298 - mae: 0.1397 - val_loss: 0.0477 - val_rmse: 0.2014 - val_mse: 0.0406 - val_mae: 0.1702 - 49ms/epoch - 3ms/step\n",
      "Epoch 133/5000\n",
      "15/15 - 0s - loss: 0.0383 - rmse: 0.1766 - mse: 0.0312 - mae: 0.1427 - val_loss: 0.0450 - val_rmse: 0.1947 - val_mse: 0.0379 - val_mae: 0.1624 - 51ms/epoch - 3ms/step\n",
      "Epoch 134/5000\n",
      "15/15 - 0s - loss: 0.0369 - rmse: 0.1728 - mse: 0.0299 - mae: 0.1385 - val_loss: 0.0452 - val_rmse: 0.1952 - val_mse: 0.0381 - val_mae: 0.1637 - 42ms/epoch - 3ms/step\n",
      "Epoch 135/5000\n",
      "15/15 - 0s - loss: 0.0365 - rmse: 0.1716 - mse: 0.0295 - mae: 0.1393 - val_loss: 0.0462 - val_rmse: 0.1980 - val_mse: 0.0392 - val_mae: 0.1642 - 38ms/epoch - 3ms/step\n",
      "Epoch 136/5000\n",
      "15/15 - 0s - loss: 0.0379 - rmse: 0.1757 - mse: 0.0309 - mae: 0.1415 - val_loss: 0.0451 - val_rmse: 0.1951 - val_mse: 0.0381 - val_mae: 0.1637 - 53ms/epoch - 4ms/step\n",
      "Epoch 137/5000\n",
      "15/15 - 0s - loss: 0.0367 - rmse: 0.1723 - mse: 0.0297 - mae: 0.1396 - val_loss: 0.0463 - val_rmse: 0.1981 - val_mse: 0.0393 - val_mae: 0.1643 - 40ms/epoch - 3ms/step\n",
      "Epoch 138/5000\n",
      "15/15 - 0s - loss: 0.0376 - rmse: 0.1749 - mse: 0.0306 - mae: 0.1414 - val_loss: 0.0469 - val_rmse: 0.2000 - val_mse: 0.0400 - val_mae: 0.1648 - 40ms/epoch - 3ms/step\n",
      "Epoch 139/5000\n",
      "15/15 - 0s - loss: 0.0375 - rmse: 0.1746 - mse: 0.0305 - mae: 0.1406 - val_loss: 0.0449 - val_rmse: 0.1947 - val_mse: 0.0379 - val_mae: 0.1647 - 31ms/epoch - 2ms/step\n",
      "Epoch 140/5000\n",
      "\n",
      "Epoch 140: val_loss improved from 0.04566 to 0.04519, saving model to data/output/activity_single-labeled_Fold-5.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0366 - rmse: 0.1724 - mse: 0.0297 - mae: 0.1398 - val_loss: 0.0452 - val_rmse: 0.1957 - val_mse: 0.0383 - val_mae: 0.1639 - 35ms/epoch - 2ms/step\n",
      "Epoch 141/5000\n",
      "15/15 - 0s - loss: 0.0376 - rmse: 0.1750 - mse: 0.0306 - mae: 0.1425 - val_loss: 0.0452 - val_rmse: 0.1955 - val_mse: 0.0382 - val_mae: 0.1635 - 35ms/epoch - 2ms/step\n",
      "Epoch 142/5000\n",
      "15/15 - 0s - loss: 0.0373 - rmse: 0.1740 - mse: 0.0303 - mae: 0.1422 - val_loss: 0.0458 - val_rmse: 0.1968 - val_mse: 0.0387 - val_mae: 0.1629 - 33ms/epoch - 2ms/step\n",
      "Epoch 143/5000\n",
      "15/15 - 0s - loss: 0.0375 - rmse: 0.1746 - mse: 0.0305 - mae: 0.1407 - val_loss: 0.0447 - val_rmse: 0.1943 - val_mse: 0.0377 - val_mae: 0.1640 - 33ms/epoch - 2ms/step\n",
      "Epoch 144/5000\n",
      "Restoring model weights from the end of the best epoch: 124.\n",
      "15/15 - 0s - loss: 0.0364 - rmse: 0.1714 - mse: 0.0294 - mae: 0.1388 - val_loss: 0.0455 - val_rmse: 0.1962 - val_mse: 0.0385 - val_mae: 0.1640 - 62ms/epoch - 4ms/step\n",
      "Epoch 144: early stopping\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "INFO:tensorflow:Assets written to: data/output/activity_saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/output/activity_saved_model/assets\n"
     ]
    }
   ],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
