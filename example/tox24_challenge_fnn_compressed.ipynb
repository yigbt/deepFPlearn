{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Tox 24 challenge - see how deepFPlearn performs\n",
    "\n",
    "We are doing the following steps\n",
    "- load challenge data: training and test datasets\n",
    "- remove duplicated SMILES with different target values\n",
    "- scale the target value to the range [0, 1]\n",
    "- use the whole set of SMILES (test and train substances), generate 2048 bit binary molecular fingerprints, train a specific autoencoder for compressing 2048 bit binary molecular fingerprints into 256 bit vectors with less zeros\n",
    "- use the trained specific autoencoder to encode the 2048 bit fingerprints of the training substances\n",
    "- train a regression model with this data \n",
    "- use the trained autoencoder to encode the test substances, use the regression model to predict the scaled target values\n",
    "- reverse the scaling of the target values\n",
    "- submit the predictions"
   ],
   "id": "f39d8e00d450f205"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setup",
   "id": "e266323388f81cf6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:42:26.746282Z",
     "start_time": "2024-08-08T13:42:20.628182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import fnmatch\n",
    "from IPython.display import Image, display\n",
    "from keras.models import load_model\n",
    "\n",
    "from dfpl import options, fingerprint as fp, utils, autoencoder as ac, single_label_model as sl, predictions\n"
   ],
   "id": "65926e083aa21c3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 15:42:21.661254: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/home/hertelj/build/local/miniforge3/envs/dfpl/lib/python3.10/site-packages/tensorflow/python/keras/engine/training_arrays_v1.py:37: UserWarning: A NumPy version >=1.23.5 and <2.3.0 is required for this version of SciPy (detected version 1.22.4)\n",
      "  from scipy.sparse import issparse  # pylint: disable=g-import-not-at-top\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:42:26.750482Z",
     "start_time": "2024-08-08T13:42:26.747628Z"
    }
   },
   "cell_type": "code",
   "source": "base_out_dir = 'data/output/fnn_compressed/'",
   "id": "7dc5ea47dbb5b4f2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:42:26.760471Z",
     "start_time": "2024-08-08T13:42:26.751219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pd.concat([pd.read_csv('data/tox24_challenge_train.csv'),\n",
    "           pd.read_csv('data/tox24_challenge_test.csv')],\n",
    "          ignore_index=True).to_csv('data/tox24_challenge_smiles_all.csv', index=False)"
   ],
   "id": "af1f4343d0f4f4a9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:42:26.763199Z",
     "start_time": "2024-08-08T13:42:26.761766Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9156fd06c1c0d5c6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Train the autoencoder\n",
    "\n",
    "For this load train and test datasets first to get the full set of molecular structures. Store all structures again in a .csv file."
   ],
   "id": "f468abce82a41b0e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Adjust all options for training the autoencoder",
   "id": "e1f61e746f7bd1c6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:42:26.766251Z",
     "start_time": "2024-08-08T13:42:26.763882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "opts = options.Options(\n",
    "    inputFile='data/tox24_challenge_smiles_all.csv',\n",
    "    outputDir=f'{base_out_dir}',\n",
    "    ecModelDir=f'{base_out_dir}/AE_encoder/',\n",
    "    ecWeightsFile='',\n",
    "    type='smiles',\n",
    "    fpType='topological',\n",
    "    fpSize=2048,\n",
    "    encFPSize=256,\n",
    "    verbose=2,\n",
    "    trainAC=True,\n",
    "    aeActivationFunction='tanh',\n",
    "    aeEpochs=3000,\n",
    "    aeBatchSize=52,\n",
    "    aeLearningRate=0.004123771070856377,\n",
    "    aeLearningRateDecay=0.05465859583974732,\n",
    "    trainFNN=False,\n",
    "    wabTracking=True,\n",
    ")\n"
   ],
   "id": "830f69a695117692",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Allow tracking the training in Weights & Biases.\n",
    "\n",
    "This requires a Weights & Biases account and at least the free plan. Feel free to comment this code cell."
   ],
   "id": "b8f05091d7d36b4d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:42:30.740864Z",
     "start_time": "2024-08-08T13:42:26.766950Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if opts.wabTracking:\n",
    "    wandb.init(project=f\"tox_24\",\n",
    "               entity=\"dfpl_regression\",\n",
    "               config=vars(opts))"
   ],
   "id": "321e393564597d7f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mmai00fti\u001B[0m (\u001B[33mdfpl_regression\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.17.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/hertelj/git-hertelj/deepFPlearn/example/wandb/run-20240808_154227-kpo6hvn8</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dfpl_regression/tox_24/runs/kpo6hvn8' target=\"_blank\">royal-lion-12</a></strong> to <a href='https://wandb.ai/dfpl_regression/tox_24' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/dfpl_regression/tox_24' target=\"_blank\">https://wandb.ai/dfpl_regression/tox_24</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/dfpl_regression/tox_24/runs/kpo6hvn8' target=\"_blank\">https://wandb.ai/dfpl_regression/tox_24/runs/kpo6hvn8</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load the training data and generate fingerprints.",
   "id": "b473706eafb7d90f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:42:31.234614Z",
     "start_time": "2024-08-08T13:42:30.741801Z"
    }
   },
   "cell_type": "code",
   "source": "df = fp.importDataFile(opts.inputFile, import_function=fp.importCSV, fp_size=opts.fpSize)",
   "id": "3b4d4ab290c67aff",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Train the autoencoder",
   "id": "51e594de4eb47fe6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:42:31.238138Z",
     "start_time": "2024-08-08T13:42:31.235710Z"
    }
   },
   "cell_type": "code",
   "source": "opts.trainAC=False",
   "id": "c078584eb52a2ae0",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:42:31.245317Z",
     "start_time": "2024-08-08T13:42:31.238800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "utils.createDirectory(opts.outputDir)\n",
    "\n",
    "# opts.trainAC=False\n",
    "if opts.trainAC:\n",
    "    # train an autoencoder on the full feature matrix\n",
    "    encoder = ac.train_full_ac(df, opts)"
   ],
   "id": "3433c8f1b647d6f6",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Update the options for training the regression model with compressed features.",
   "id": "efe4e9f05a9cb933"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:42:31.249703Z",
     "start_time": "2024-08-08T13:42:31.246955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "opts = options.Options(\n",
    "    inputFile='data/tox24_challenge_train.csv',\n",
    "    outputDir=f'{base_out_dir}',\n",
    "    ecModelDir=f'{base_out_dir}/AE_encoder/',\n",
    "    ecWeightsFile='',\n",
    "    type='smiles',\n",
    "    fpType='topological',\n",
    "    fpSize=2048,\n",
    "    encFPSize=256,\n",
    "    verbose=2,\n",
    "    trainFNN=True,\n",
    "    compressFeatures=True,\n",
    "    kFolds=5,\n",
    "    testSize=0.2,\n",
    "    optimizer=\"SGD\",\n",
    "    lossFunction=\"mse\",\n",
    "    epochs=5000,\n",
    "    batchSize=56,\n",
    "    activationFunction=\"tanh\",\n",
    "    dropout=0.15657883016344468,\n",
    "    learningRate=0.017935022040821466,\n",
    "    l2reg=0.009308121424156192,\n",
    "    fnnType=\"REG\",\n",
    "    enableMultiLabel=False,\n",
    "    wabTarget=\"activity\",\n",
    ")\n"
   ],
   "id": "1e8b262fc474dfca",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:42:31.558573Z",
     "start_time": "2024-08-08T13:42:31.250506Z"
    }
   },
   "cell_type": "code",
   "source": "df = fp.importDataFile(opts.inputFile, import_function=fp.importCSV, fp_size=opts.fpSize)",
   "id": "da3b909acb03f733",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:42:32.040187Z",
     "start_time": "2024-08-08T13:42:31.559292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if opts.compressFeatures:\n",
    "    # load trained model for autoencoder\n",
    "    encoder = keras.models.load_model(opts.ecModelDir)\n",
    "\n",
    "    # compress the fingerprints using the autoencoder\n",
    "    df = ac.compress_fingerprints(df, encoder)"
   ],
   "id": "b132021657300b35",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 15:42:31.575386: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-08 15:42:31.576023: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-08 15:42:31.576102: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-08 15:42:31.576422: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-08 15:42:31.577346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-08 15:42:31.577429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-08 15:42:31.577484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-08 15:42:31.638471: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-08 15:42:31.638591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-08 15:42:31.638673: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-08-08 15:42:31.638743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10226 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 903us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 15:42:31.982967: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Scale the target values to [0,1]",
   "id": "b7b1d0964575ca82"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:42:32.043873Z",
     "start_time": "2024-08-08T13:42:32.040742Z"
    }
   },
   "cell_type": "code",
   "source": "df.columns",
   "id": "b42ef4c461b0e3e1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SMILES', 'activity', 'fp', 'fpcompressed'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:42:32.048568Z",
     "start_time": "2024-08-08T13:42:32.044542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "unscaled_target = df['activity'].to_numpy().reshape(-1, 1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(unscaled_target)\n",
    "scaled_target = scaler.transform(unscaled_target)\n",
    "df = df.drop('activity', axis=1)\n",
    "df = pd.concat([df, pd.DataFrame(scaled_target, columns=['activity'])], axis=1)"
   ],
   "id": "4056aed7e8294160",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now train the regression model",
   "id": "ddc875717f5798bb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:42:32.051871Z",
     "start_time": "2024-08-08T13:42:32.049260Z"
    }
   },
   "cell_type": "code",
   "source": "opts.inputFile",
   "id": "83885dd3791332c8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/tox24_challenge_train.csv'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:43:59.026523Z",
     "start_time": "2024-08-08T13:42:32.052450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if opts.trainFNN:\n",
    "    sl.train_single_label_models(df=df, opts=opts);"
   ],
   "id": "6da9acabdf2079d0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hertelj/build/local/miniforge3/envs/dfpl/lib/python3.10/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Finishing last run (ID:kpo6hvn8) before initializing another..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8aa7423ed34042d2ae27af7a137347ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">royal-lion-12</strong> at: <a href='https://wandb.ai/dfpl_regression/tox_24/runs/kpo6hvn8' target=\"_blank\">https://wandb.ai/dfpl_regression/tox_24/runs/kpo6hvn8</a><br/> View project at: <a href='https://wandb.ai/dfpl_regression/tox_24' target=\"_blank\">https://wandb.ai/dfpl_regression/tox_24</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20240808_154227-kpo6hvn8/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Successfully finished last run (ID:kpo6hvn8). Initializing new run:<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113111989106982, max=1.0â€¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e7a5e78efa65474bb772070e7944eda9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.17.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/hertelj/git-hertelj/deepFPlearn/example/wandb/run-20240808_154232-dqo5mpgo</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dfpl_regression/FNN_0.5_random/runs/dqo5mpgo' target=\"_blank\">activity-1</a></strong> to <a href='https://wandb.ai/dfpl_regression/FNN_0.5_random' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/dfpl_regression/FNN_0.5_random' target=\"_blank\">https://wandb.ai/dfpl_regression/FNN_0.5_random</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/dfpl_regression/FNN_0.5_random/runs/dqo5mpgo' target=\"_blank\">https://wandb.ai/dfpl_regression/FNN_0.5_random/runs/dqo5mpgo</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hertelj/build/local/miniforge3/envs/dfpl/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "15/15 - 0s - loss: 4.6716 - rmse: 0.7582 - mse: 0.5749 - mae: 0.5786 - val_loss: 4.0641 - val_rmse: 0.3140 - val_mse: 0.0986 - val_mae: 0.2658 - 301ms/epoch - 20ms/step\n",
      "Epoch 2/5000\n",
      "15/15 - 0s - loss: 3.8907 - rmse: 0.2704 - mse: 0.0731 - mae: 0.2081 - val_loss: 3.6454 - val_rmse: 0.1349 - val_mse: 0.0182 - val_mae: 0.1107 - 24ms/epoch - 2ms/step\n",
      "Epoch 3/5000\n",
      "15/15 - 0s - loss: 3.4888 - rmse: 0.1362 - mse: 0.0185 - mae: 0.1063 - val_loss: 3.2961 - val_rmse: 0.1234 - val_mse: 0.0152 - val_mae: 0.1132 - 30ms/epoch - 2ms/step\n",
      "Epoch 4/5000\n",
      "15/15 - 0s - loss: 3.1421 - rmse: 0.0885 - mse: 0.0078 - mae: 0.0655 - val_loss: 2.9614 - val_rmse: 0.0398 - val_mse: 0.0016 - val_mae: 0.0288 - 30ms/epoch - 2ms/step\n",
      "Epoch 5/5000\n",
      "15/15 - 0s - loss: 2.8308 - rmse: 0.0641 - mse: 0.0041 - mae: 0.0418 - val_loss: 2.6699 - val_rmse: 0.0327 - val_mse: 0.0011 - val_mae: 0.0244 - 30ms/epoch - 2ms/step\n",
      "Epoch 6/5000\n",
      "15/15 - 0s - loss: 2.5517 - rmse: 0.0554 - mse: 0.0031 - mae: 0.0330 - val_loss: 2.4071 - val_rmse: 0.0295 - val_mse: 8.7065e-04 - val_mae: 0.0217 - 31ms/epoch - 2ms/step\n",
      "Epoch 7/5000\n",
      "15/15 - 0s - loss: 2.3005 - rmse: 0.0511 - mse: 0.0026 - mae: 0.0301 - val_loss: 2.1702 - val_rmse: 0.0280 - val_mse: 7.8265e-04 - val_mae: 0.0218 - 29ms/epoch - 2ms/step\n",
      "Epoch 8/5000\n",
      "15/15 - 0s - loss: 2.0742 - rmse: 0.0493 - mse: 0.0024 - mae: 0.0272 - val_loss: 1.9566 - val_rmse: 0.0241 - val_mse: 5.8012e-04 - val_mae: 0.0183 - 29ms/epoch - 2ms/step\n",
      "Epoch 9/5000\n",
      "15/15 - 0s - loss: 1.8703 - rmse: 0.0484 - mse: 0.0023 - mae: 0.0259 - val_loss: 1.7642 - val_rmse: 0.0243 - val_mse: 5.9058e-04 - val_mae: 0.0189 - 30ms/epoch - 2ms/step\n",
      "Epoch 10/5000\n",
      "\n",
      "Epoch 10: val_loss improved from inf to 1.59065, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-1.model.weights.hdf5\n",
      "15/15 - 0s - loss: 1.6864 - rmse: 0.0460 - mse: 0.0021 - mae: 0.0234 - val_loss: 1.5907 - val_rmse: 0.0219 - val_mse: 4.7987e-04 - val_mae: 0.0164 - 34ms/epoch - 2ms/step\n",
      "Epoch 11/5000\n",
      "15/15 - 0s - loss: 1.5207 - rmse: 0.0460 - mse: 0.0021 - mae: 0.0239 - val_loss: 1.4343 - val_rmse: 0.0215 - val_mse: 4.6080e-04 - val_mae: 0.0165 - 31ms/epoch - 2ms/step\n",
      "Epoch 12/5000\n",
      "15/15 - 0s - loss: 1.3714 - rmse: 0.0456 - mse: 0.0021 - mae: 0.0231 - val_loss: 1.2934 - val_rmse: 0.0241 - val_mse: 5.8023e-04 - val_mae: 0.0196 - 32ms/epoch - 2ms/step\n",
      "Epoch 13/5000\n",
      "15/15 - 0s - loss: 1.2366 - rmse: 0.0440 - mse: 0.0019 - mae: 0.0223 - val_loss: 1.1662 - val_rmse: 0.0210 - val_mse: 4.4142e-04 - val_mae: 0.0159 - 29ms/epoch - 2ms/step\n",
      "Epoch 14/5000\n",
      "15/15 - 0s - loss: 1.1154 - rmse: 0.0451 - mse: 0.0020 - mae: 0.0239 - val_loss: 1.0518 - val_rmse: 0.0242 - val_mse: 5.8774e-04 - val_mae: 0.0198 - 28ms/epoch - 2ms/step\n",
      "Epoch 15/5000\n",
      "15/15 - 0s - loss: 1.0058 - rmse: 0.0432 - mse: 0.0019 - mae: 0.0225 - val_loss: 0.9482 - val_rmse: 0.0194 - val_mse: 3.7462e-04 - val_mae: 0.0145 - 31ms/epoch - 2ms/step\n",
      "Epoch 16/5000\n",
      "15/15 - 0s - loss: 0.9071 - rmse: 0.0435 - mse: 0.0019 - mae: 0.0216 - val_loss: 0.8550 - val_rmse: 0.0189 - val_mse: 3.5550e-04 - val_mae: 0.0143 - 37ms/epoch - 2ms/step\n",
      "Epoch 17/5000\n",
      "15/15 - 0s - loss: 0.8181 - rmse: 0.0428 - mse: 0.0018 - mae: 0.0211 - val_loss: 0.7710 - val_rmse: 0.0175 - val_mse: 3.0713e-04 - val_mae: 0.0130 - 35ms/epoch - 2ms/step\n",
      "Epoch 18/5000\n",
      "15/15 - 0s - loss: 0.7379 - rmse: 0.0436 - mse: 0.0019 - mae: 0.0210 - val_loss: 0.6953 - val_rmse: 0.0183 - val_mse: 3.3364e-04 - val_mae: 0.0143 - 38ms/epoch - 3ms/step\n",
      "Epoch 19/5000\n",
      "15/15 - 0s - loss: 0.6655 - rmse: 0.0428 - mse: 0.0018 - mae: 0.0214 - val_loss: 0.6269 - val_rmse: 0.0158 - val_mse: 2.4912e-04 - val_mae: 0.0116 - 34ms/epoch - 2ms/step\n",
      "Epoch 20/5000\n",
      "\n",
      "Epoch 20: val_loss improved from 1.59065 to 0.56523, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-1.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.6002 - rmse: 0.0418 - mse: 0.0017 - mae: 0.0203 - val_loss: 0.5652 - val_rmse: 0.0148 - val_mse: 2.1925e-04 - val_mae: 0.0110 - 42ms/epoch - 3ms/step\n",
      "Epoch 21/5000\n",
      "15/15 - 0s - loss: 0.5413 - rmse: 0.0411 - mse: 0.0017 - mae: 0.0185 - val_loss: 0.5097 - val_rmse: 0.0146 - val_mse: 2.1265e-04 - val_mae: 0.0109 - 36ms/epoch - 2ms/step\n",
      "Epoch 22/5000\n",
      "15/15 - 0s - loss: 0.4881 - rmse: 0.0400 - mse: 0.0016 - mae: 0.0182 - val_loss: 0.4596 - val_rmse: 0.0143 - val_mse: 2.0447e-04 - val_mae: 0.0109 - 35ms/epoch - 2ms/step\n",
      "Epoch 23/5000\n",
      "15/15 - 0s - loss: 0.4402 - rmse: 0.0391 - mse: 0.0015 - mae: 0.0165 - val_loss: 0.4143 - val_rmse: 0.0116 - val_mse: 1.3404e-04 - val_mae: 0.0088 - 35ms/epoch - 2ms/step\n",
      "Epoch 24/5000\n",
      "15/15 - 0s - loss: 0.3971 - rmse: 0.0390 - mse: 0.0015 - mae: 0.0149 - val_loss: 0.3736 - val_rmse: 0.0138 - val_mse: 1.9078e-04 - val_mae: 0.0114 - 38ms/epoch - 3ms/step\n",
      "Epoch 25/5000\n",
      "15/15 - 0s - loss: 0.3581 - rmse: 0.0381 - mse: 0.0015 - mae: 0.0146 - val_loss: 0.3368 - val_rmse: 0.0102 - val_mse: 1.0425e-04 - val_mae: 0.0079 - 35ms/epoch - 2ms/step\n",
      "Epoch 26/5000\n",
      "15/15 - 0s - loss: 0.3230 - rmse: 0.0380 - mse: 0.0014 - mae: 0.0133 - val_loss: 0.3037 - val_rmse: 0.0098 - val_mse: 9.5889e-05 - val_mae: 0.0077 - 41ms/epoch - 3ms/step\n",
      "Epoch 27/5000\n",
      "15/15 - 0s - loss: 0.2913 - rmse: 0.0372 - mse: 0.0014 - mae: 0.0127 - val_loss: 0.2738 - val_rmse: 0.0081 - val_mse: 6.5752e-05 - val_mae: 0.0062 - 34ms/epoch - 2ms/step\n",
      "Epoch 28/5000\n",
      "15/15 - 0s - loss: 0.2628 - rmse: 0.0371 - mse: 0.0014 - mae: 0.0119 - val_loss: 0.2468 - val_rmse: 0.0068 - val_mse: 4.6710e-05 - val_mae: 0.0053 - 34ms/epoch - 2ms/step\n",
      "Epoch 29/5000\n",
      "15/15 - 0s - loss: 0.2370 - rmse: 0.0368 - mse: 0.0014 - mae: 0.0107 - val_loss: 0.2226 - val_rmse: 0.0086 - val_mse: 7.4455e-05 - val_mae: 0.0073 - 36ms/epoch - 2ms/step\n",
      "Epoch 30/5000\n",
      "\n",
      "Epoch 30: val_loss improved from 0.56523 to 0.20065, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-1.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.2138 - rmse: 0.0363 - mse: 0.0013 - mae: 0.0099 - val_loss: 0.2006 - val_rmse: 0.0061 - val_mse: 3.6742e-05 - val_mae: 0.0047 - 42ms/epoch - 3ms/step\n",
      "Epoch 31/5000\n",
      "15/15 - 0s - loss: 0.1929 - rmse: 0.0365 - mse: 0.0013 - mae: 0.0092 - val_loss: 0.1809 - val_rmse: 0.0050 - val_mse: 2.4876e-05 - val_mae: 0.0038 - 36ms/epoch - 2ms/step\n",
      "Epoch 32/5000\n",
      "15/15 - 0s - loss: 0.1740 - rmse: 0.0361 - mse: 0.0013 - mae: 0.0086 - val_loss: 0.1631 - val_rmse: 0.0044 - val_mse: 1.9115e-05 - val_mae: 0.0034 - 29ms/epoch - 2ms/step\n",
      "Epoch 33/5000\n",
      "15/15 - 0s - loss: 0.1570 - rmse: 0.0356 - mse: 0.0013 - mae: 0.0080 - val_loss: 0.1471 - val_rmse: 0.0074 - val_mse: 5.4154e-05 - val_mae: 0.0066 - 37ms/epoch - 2ms/step\n",
      "Epoch 34/5000\n",
      "15/15 - 0s - loss: 0.1417 - rmse: 0.0356 - mse: 0.0013 - mae: 0.0080 - val_loss: 0.1326 - val_rmse: 0.0051 - val_mse: 2.5967e-05 - val_mae: 0.0042 - 40ms/epoch - 3ms/step\n",
      "Epoch 35/5000\n",
      "15/15 - 0s - loss: 0.1279 - rmse: 0.0354 - mse: 0.0013 - mae: 0.0066 - val_loss: 0.1196 - val_rmse: 0.0048 - val_mse: 2.2646e-05 - val_mae: 0.0041 - 39ms/epoch - 3ms/step\n",
      "Epoch 36/5000\n",
      "15/15 - 0s - loss: 0.1154 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0062 - val_loss: 0.1078 - val_rmse: 0.0027 - val_mse: 7.4421e-06 - val_mae: 0.0021 - 29ms/epoch - 2ms/step\n",
      "Epoch 37/5000\n",
      "15/15 - 0s - loss: 0.1042 - rmse: 0.0356 - mse: 0.0013 - mae: 0.0059 - val_loss: 0.0972 - val_rmse: 0.0047 - val_mse: 2.2073e-05 - val_mae: 0.0043 - 38ms/epoch - 3ms/step\n",
      "Epoch 38/5000\n",
      "15/15 - 0s - loss: 0.0940 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0055 - val_loss: 0.0876 - val_rmse: 0.0020 - val_mse: 3.9958e-06 - val_mae: 0.0016 - 36ms/epoch - 2ms/step\n",
      "Epoch 39/5000\n",
      "15/15 - 0s - loss: 0.0849 - rmse: 0.0356 - mse: 0.0013 - mae: 0.0051 - val_loss: 0.0790 - val_rmse: 0.0025 - val_mse: 6.1059e-06 - val_mae: 0.0020 - 38ms/epoch - 3ms/step\n",
      "Epoch 40/5000\n",
      "\n",
      "Epoch 40: val_loss improved from 0.20065 to 0.07124, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-1.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0767 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0052 - val_loss: 0.0712 - val_rmse: 0.0043 - val_mse: 1.8619e-05 - val_mae: 0.0041 - 43ms/epoch - 3ms/step\n",
      "Epoch 41/5000\n",
      "15/15 - 0s - loss: 0.0693 - rmse: 0.0354 - mse: 0.0013 - mae: 0.0048 - val_loss: 0.0642 - val_rmse: 0.0029 - val_mse: 8.2254e-06 - val_mae: 0.0026 - 38ms/epoch - 3ms/step\n",
      "Epoch 42/5000\n",
      "15/15 - 0s - loss: 0.0626 - rmse: 0.0354 - mse: 0.0013 - mae: 0.0059 - val_loss: 0.0579 - val_rmse: 0.0042 - val_mse: 1.7681e-05 - val_mae: 0.0041 - 35ms/epoch - 2ms/step\n",
      "Epoch 43/5000\n",
      "15/15 - 0s - loss: 0.0565 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0044 - val_loss: 0.0522 - val_rmse: 0.0012 - val_mse: 1.4859e-06 - val_mae: 9.8476e-04 - 29ms/epoch - 2ms/step\n",
      "Epoch 44/5000\n",
      "15/15 - 0s - loss: 0.0511 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0044 - val_loss: 0.0471 - val_rmse: 0.0036 - val_mse: 1.2908e-05 - val_mae: 0.0035 - 40ms/epoch - 3ms/step\n",
      "Epoch 45/5000\n",
      "15/15 - 0s - loss: 0.0462 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0041 - val_loss: 0.0424 - val_rmse: 0.0021 - val_mse: 4.2286e-06 - val_mae: 0.0019 - 43ms/epoch - 3ms/step\n",
      "Epoch 46/5000\n",
      "15/15 - 0s - loss: 0.0418 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0043 - val_loss: 0.0383 - val_rmse: 0.0029 - val_mse: 8.3983e-06 - val_mae: 0.0028 - 41ms/epoch - 3ms/step\n",
      "Epoch 47/5000\n",
      "15/15 - 0s - loss: 0.0378 - rmse: 0.0354 - mse: 0.0013 - mae: 0.0037 - val_loss: 0.0345 - val_rmse: 0.0040 - val_mse: 1.6239e-05 - val_mae: 0.0040 - 40ms/epoch - 3ms/step\n",
      "Epoch 48/5000\n",
      "15/15 - 0s - loss: 0.0342 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0043 - val_loss: 0.0311 - val_rmse: 8.8117e-04 - val_mse: 7.7645e-07 - val_mae: 7.5710e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 49/5000\n",
      "15/15 - 0s - loss: 0.0309 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0031 - val_loss: 0.0281 - val_rmse: 0.0037 - val_mse: 1.3674e-05 - val_mae: 0.0037 - 45ms/epoch - 3ms/step\n",
      "Epoch 50/5000\n",
      "\n",
      "Epoch 50: val_loss improved from 0.07124 to 0.02529, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-1.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0280 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0041 - val_loss: 0.0253 - val_rmse: 5.3476e-04 - val_mse: 2.8597e-07 - val_mae: 4.4091e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 51/5000\n",
      "15/15 - 0s - loss: 0.0254 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0029 - val_loss: 0.0228 - val_rmse: 0.0036 - val_mse: 1.2902e-05 - val_mae: 0.0036 - 35ms/epoch - 2ms/step\n",
      "Epoch 52/5000\n",
      "15/15 - 0s - loss: 0.0230 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0050 - val_loss: 0.0206 - val_rmse: 0.0034 - val_mse: 1.1257e-05 - val_mae: 0.0033 - 34ms/epoch - 2ms/step\n",
      "Epoch 53/5000\n",
      "15/15 - 0s - loss: 0.0209 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0034 - val_loss: 0.0185 - val_rmse: 3.8652e-04 - val_mse: 1.4940e-07 - val_mae: 3.2419e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 54/5000\n",
      "15/15 - 0s - loss: 0.0189 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0032 - val_loss: 0.0167 - val_rmse: 0.0040 - val_mse: 1.6301e-05 - val_mae: 0.0040 - 29ms/epoch - 2ms/step\n",
      "Epoch 55/5000\n",
      "15/15 - 0s - loss: 0.0172 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0035 - val_loss: 0.0151 - val_rmse: 0.0013 - val_mse: 1.8151e-06 - val_mae: 0.0013 - 30ms/epoch - 2ms/step\n",
      "Epoch 56/5000\n",
      "15/15 - 0s - loss: 0.0156 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0045 - val_loss: 0.0136 - val_rmse: 2.5312e-04 - val_mse: 6.4070e-08 - val_mae: 2.1964e-04 - 26ms/epoch - 2ms/step\n",
      "Epoch 57/5000\n",
      "15/15 - 0s - loss: 0.0142 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0026 - val_loss: 0.0122 - val_rmse: 5.3952e-04 - val_mse: 2.9108e-07 - val_mae: 5.2356e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 58/5000\n",
      "15/15 - 0s - loss: 0.0129 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0023 - val_loss: 0.0111 - val_rmse: 0.0027 - val_mse: 7.3663e-06 - val_mae: 0.0027 - 39ms/epoch - 3ms/step\n",
      "Epoch 59/5000\n",
      "15/15 - 0s - loss: 0.0118 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0040 - val_loss: 0.0100 - val_rmse: 5.0369e-04 - val_mse: 2.5371e-07 - val_mae: 4.9416e-04 - 30ms/epoch - 2ms/step\n",
      "Epoch 60/5000\n",
      "\n",
      "Epoch 60: val_loss improved from 0.02529 to 0.00898, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-1.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0108 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0029 - val_loss: 0.0090 - val_rmse: 9.8426e-04 - val_mse: 9.6876e-07 - val_mae: 9.8065e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 61/5000\n",
      "15/15 - 0s - loss: 0.0098 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0025 - val_loss: 0.0081 - val_rmse: 0.0036 - val_mse: 1.3183e-05 - val_mae: 0.0036 - 40ms/epoch - 3ms/step\n",
      "Epoch 62/5000\n",
      "15/15 - 0s - loss: 0.0090 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0041 - val_loss: 0.0073 - val_rmse: 1.9959e-04 - val_mse: 3.9834e-08 - val_mae: 1.9015e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 63/5000\n",
      "15/15 - 0s - loss: 0.0082 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0027 - val_loss: 0.0066 - val_rmse: 0.0013 - val_mse: 1.5866e-06 - val_mae: 0.0013 - 36ms/epoch - 2ms/step\n",
      "Epoch 64/5000\n",
      "15/15 - 0s - loss: 0.0075 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0032 - val_loss: 0.0059 - val_rmse: 7.6152e-04 - val_mse: 5.7992e-07 - val_mae: 7.6015e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 65/5000\n",
      "15/15 - 0s - loss: 0.0069 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0027 - val_loss: 0.0053 - val_rmse: 5.6241e-04 - val_mse: 3.1630e-07 - val_mae: 5.6105e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 66/5000\n",
      "15/15 - 0s - loss: 0.0064 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0025 - val_loss: 0.0048 - val_rmse: 0.0042 - val_mse: 1.7794e-05 - val_mae: 0.0042 - 35ms/epoch - 2ms/step\n",
      "Epoch 67/5000\n",
      "15/15 - 0s - loss: 0.0059 - rmse: 0.0354 - mse: 0.0013 - mae: 0.0037 - val_loss: 0.0043 - val_rmse: 7.2296e-04 - val_mse: 5.2267e-07 - val_mae: 7.2239e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 68/5000\n",
      "15/15 - 0s - loss: 0.0054 - rmse: 0.0355 - mse: 0.0013 - mae: 0.0072 - val_loss: 0.0039 - val_rmse: 0.0037 - val_mse: 1.3572e-05 - val_mae: 0.0037 - 38ms/epoch - 3ms/step\n",
      "Epoch 69/5000\n",
      "15/15 - 0s - loss: 0.0050 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0048 - val_loss: 0.0036 - val_rmse: 0.0066 - val_mse: 4.4104e-05 - val_mae: 0.0066 - 30ms/epoch - 2ms/step\n",
      "Epoch 70/5000\n",
      "\n",
      "Epoch 70: val_loss improved from 0.00898 to 0.00319, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-1.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0046 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0038 - val_loss: 0.0032 - val_rmse: 5.8446e-05 - val_mse: 3.4159e-09 - val_mae: 5.5622e-05 - 54ms/epoch - 4ms/step\n",
      "Epoch 71/5000\n",
      "15/15 - 0s - loss: 0.0043 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0031 - val_loss: 0.0029 - val_rmse: 4.9443e-04 - val_mse: 2.4447e-07 - val_mae: 4.9418e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 72/5000\n",
      "15/15 - 0s - loss: 0.0040 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0028 - val_loss: 0.0026 - val_rmse: 0.0013 - val_mse: 1.5745e-06 - val_mae: 0.0013 - 37ms/epoch - 2ms/step\n",
      "Epoch 73/5000\n",
      "15/15 - 0s - loss: 0.0037 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0026 - val_loss: 0.0023 - val_rmse: 3.2823e-05 - val_mse: 1.0773e-09 - val_mae: 3.0848e-05 - 37ms/epoch - 2ms/step\n",
      "Epoch 74/5000\n",
      "15/15 - 0s - loss: 0.0035 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0027 - val_loss: 0.0021 - val_rmse: 3.1929e-04 - val_mse: 1.0195e-07 - val_mae: 3.1913e-04 - 29ms/epoch - 2ms/step\n",
      "Epoch 75/5000\n",
      "15/15 - 0s - loss: 0.0033 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0028 - val_loss: 0.0019 - val_rmse: 0.0043 - val_mse: 1.8919e-05 - val_mae: 0.0043 - 31ms/epoch - 2ms/step\n",
      "Epoch 76/5000\n",
      "15/15 - 0s - loss: 0.0031 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0036 - val_loss: 0.0017 - val_rmse: 0.0016 - val_mse: 2.4616e-06 - val_mae: 0.0016 - 41ms/epoch - 3ms/step\n",
      "Epoch 77/5000\n",
      "15/15 - 0s - loss: 0.0029 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0037 - val_loss: 0.0016 - val_rmse: 0.0029 - val_mse: 8.6390e-06 - val_mae: 0.0029 - 51ms/epoch - 3ms/step\n",
      "Epoch 78/5000\n",
      "15/15 - 0s - loss: 0.0027 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0029 - val_loss: 0.0014 - val_rmse: 0.0034 - val_mse: 1.1238e-05 - val_mae: 0.0034 - 42ms/epoch - 3ms/step\n",
      "Epoch 79/5000\n",
      "15/15 - 0s - loss: 0.0026 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0031 - val_loss: 0.0013 - val_rmse: 8.5538e-04 - val_mse: 7.3168e-07 - val_mae: 8.5537e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 80/5000\n",
      "\n",
      "Epoch 80: val_loss improved from 0.00319 to 0.00114, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-1.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0024 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0026 - val_loss: 0.0011 - val_rmse: 0.0034 - val_mse: 1.1780e-05 - val_mae: 0.0034 - 44ms/epoch - 3ms/step\n",
      "Epoch 81/5000\n",
      "15/15 - 0s - loss: 0.0023 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0029 - val_loss: 0.0010 - val_rmse: 0.0014 - val_mse: 2.0526e-06 - val_mae: 0.0014 - 40ms/epoch - 3ms/step\n",
      "Epoch 82/5000\n",
      "15/15 - 0s - loss: 0.0022 - rmse: 0.0354 - mse: 0.0013 - mae: 0.0055 - val_loss: 9.3296e-04 - val_rmse: 0.0036 - val_mse: 1.3169e-05 - val_mae: 0.0036 - 37ms/epoch - 2ms/step\n",
      "Epoch 83/5000\n",
      "15/15 - 0s - loss: 0.0021 - rmse: 0.0355 - mse: 0.0013 - mae: 0.0048 - val_loss: 8.3599e-04 - val_rmse: 0.0026 - val_mse: 6.5070e-06 - val_mae: 0.0026 - 38ms/epoch - 3ms/step\n",
      "Epoch 84/5000\n",
      "15/15 - 0s - loss: 0.0020 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0030 - val_loss: 7.6460e-04 - val_rmse: 0.0041 - val_mse: 1.6657e-05 - val_mae: 0.0041 - 37ms/epoch - 2ms/step\n",
      "Epoch 85/5000\n",
      "15/15 - 0s - loss: 0.0020 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0035 - val_loss: 6.7556e-04 - val_rmse: 0.0011 - val_mse: 1.2436e-06 - val_mae: 0.0011 - 38ms/epoch - 3ms/step\n",
      "Epoch 86/5000\n",
      "15/15 - 0s - loss: 0.0019 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0031 - val_loss: 6.1021e-04 - val_rmse: 0.0015 - val_mse: 2.3078e-06 - val_mae: 0.0015 - 37ms/epoch - 2ms/step\n",
      "Epoch 87/5000\n",
      "15/15 - 0s - loss: 0.0018 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0026 - val_loss: 5.6854e-04 - val_rmse: 0.0045 - val_mse: 2.0269e-05 - val_mae: 0.0045 - 38ms/epoch - 3ms/step\n",
      "Epoch 88/5000\n",
      "15/15 - 0s - loss: 0.0018 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0032 - val_loss: 4.9701e-04 - val_rmse: 0.0017 - val_mse: 2.7236e-06 - val_mae: 0.0017 - 30ms/epoch - 2ms/step\n",
      "Epoch 89/5000\n",
      "15/15 - 0s - loss: 0.0017 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0023 - val_loss: 4.5426e-04 - val_rmse: 0.0029 - val_mse: 8.5621e-06 - val_mae: 0.0029 - 31ms/epoch - 2ms/step\n",
      "Epoch 90/5000\n",
      "\n",
      "Epoch 90: val_loss improved from 0.00114 to 0.00041, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-1.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0017 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0040 - val_loss: 4.0619e-04 - val_rmse: 0.0021 - val_mse: 4.4329e-06 - val_mae: 0.0021 - 37ms/epoch - 2ms/step\n",
      "Epoch 91/5000\n",
      "15/15 - 0s - loss: 0.0016 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0039 - val_loss: 3.7788e-04 - val_rmse: 0.0039 - val_mse: 1.5508e-05 - val_mae: 0.0039 - 33ms/epoch - 2ms/step\n",
      "Epoch 92/5000\n",
      "15/15 - 0s - loss: 0.0016 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0025 - val_loss: 3.2747e-04 - val_rmse: 8.8384e-04 - val_mse: 7.8117e-07 - val_mae: 8.8384e-04 - 33ms/epoch - 2ms/step\n",
      "Epoch 93/5000\n",
      "15/15 - 0s - loss: 0.0016 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0032 - val_loss: 2.9765e-04 - val_rmse: 0.0018 - val_mse: 3.1519e-06 - val_mae: 0.0018 - 39ms/epoch - 3ms/step\n",
      "Epoch 94/5000\n",
      "15/15 - 0s - loss: 0.0015 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0024 - val_loss: 2.8093e-04 - val_rmse: 0.0039 - val_mse: 1.5283e-05 - val_mae: 0.0039 - 38ms/epoch - 3ms/step\n",
      "Epoch 95/5000\n",
      "15/15 - 0s - loss: 0.0015 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0035 - val_loss: 2.4049e-04 - val_rmse: 0.0010 - val_mse: 1.0137e-06 - val_mae: 0.0010 - 38ms/epoch - 3ms/step\n",
      "Epoch 96/5000\n",
      "15/15 - 0s - loss: 0.0015 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0041 - val_loss: 2.1620e-04 - val_rmse: 5.2613e-04 - val_mse: 2.7681e-07 - val_mae: 5.2613e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 97/5000\n",
      "15/15 - 0s - loss: 0.0015 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0028 - val_loss: 1.9672e-04 - val_rmse: 0.0014 - val_mse: 2.0208e-06 - val_mae: 0.0014 - 33ms/epoch - 2ms/step\n",
      "Epoch 98/5000\n",
      "15/15 - 0s - loss: 0.0014 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0022 - val_loss: 1.8153e-04 - val_rmse: 0.0024 - val_mse: 5.9642e-06 - val_mae: 0.0024 - 45ms/epoch - 3ms/step\n",
      "Epoch 99/5000\n",
      "15/15 - 0s - loss: 0.0014 - rmse: 0.0354 - mse: 0.0013 - mae: 0.0055 - val_loss: 1.7231e-04 - val_rmse: 0.0038 - val_mse: 1.4092e-05 - val_mae: 0.0038 - 38ms/epoch - 3ms/step\n",
      "Epoch 100/5000\n",
      "\n",
      "Epoch 100: val_loss improved from 0.00041 to 0.00015, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-1.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0014 - rmse: 0.0355 - mse: 0.0013 - mae: 0.0045 - val_loss: 1.4588e-04 - val_rmse: 0.0018 - val_mse: 3.1693e-06 - val_mae: 0.0018 - 46ms/epoch - 3ms/step\n",
      "Epoch 101/5000\n",
      "15/15 - 0s - loss: 0.0014 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0027 - val_loss: 1.4006e-04 - val_rmse: 0.0034 - val_mse: 1.1370e-05 - val_mae: 0.0034 - 34ms/epoch - 2ms/step\n",
      "Epoch 102/5000\n",
      "15/15 - 0s - loss: 0.0014 - rmse: 0.0355 - mse: 0.0013 - mae: 0.0069 - val_loss: 1.2134e-04 - val_rmse: 0.0023 - val_mse: 5.3518e-06 - val_mae: 0.0023 - 37ms/epoch - 2ms/step\n",
      "Epoch 103/5000\n",
      "15/15 - 0s - loss: 0.0014 - rmse: 0.0354 - mse: 0.0013 - mae: 0.0039 - val_loss: 1.0822e-04 - val_rmse: 0.0019 - val_mse: 3.5861e-06 - val_mae: 0.0019 - 44ms/epoch - 3ms/step\n",
      "Epoch 104/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0025 - val_loss: 9.4939e-05 - val_rmse: 7.8730e-04 - val_mse: 6.1985e-07 - val_mae: 7.8730e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 105/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0022 - val_loss: 9.9466e-05 - val_rmse: 0.0038 - val_mse: 1.4400e-05 - val_mae: 0.0038 - 52ms/epoch - 3ms/step\n",
      "Epoch 106/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0038 - val_loss: 7.6663e-05 - val_rmse: 5.2158e-05 - val_mse: 2.7205e-09 - val_mae: 5.2158e-05 - 44ms/epoch - 3ms/step\n",
      "Epoch 107/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0029 - val_loss: 8.0239e-05 - val_rmse: 0.0033 - val_mse: 1.1100e-05 - val_mae: 0.0033 - 33ms/epoch - 2ms/step\n",
      "Epoch 108/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0027 - val_loss: 6.2917e-05 - val_rmse: 7.7393e-04 - val_mse: 5.9897e-07 - val_mae: 7.7393e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 109/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0019 - val_loss: 6.6597e-05 - val_rmse: 0.0032 - val_mse: 1.0389e-05 - val_mae: 0.0032 - 34ms/epoch - 2ms/step\n",
      "Epoch 110/5000\n",
      "\n",
      "Epoch 110: val_loss improved from 0.00015 to 0.00005, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-1.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0043 - val_loss: 5.1405e-05 - val_rmse: 8.7019e-04 - val_mse: 7.5722e-07 - val_mae: 8.7019e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 111/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0023 - val_loss: 4.6025e-05 - val_rmse: 5.9957e-04 - val_mse: 3.5948e-07 - val_mae: 5.9957e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 112/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0021 - val_loss: 5.7716e-05 - val_rmse: 0.0041 - val_mse: 1.6513e-05 - val_mae: 0.0041 - 38ms/epoch - 3ms/step\n",
      "Epoch 113/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0032 - val_loss: 4.0052e-05 - val_rmse: 0.0017 - val_mse: 2.9163e-06 - val_mae: 0.0017 - 38ms/epoch - 3ms/step\n",
      "Epoch 114/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0034 - val_loss: 3.3516e-05 - val_rmse: 1.9518e-04 - val_mse: 3.8094e-08 - val_mae: 1.9518e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 115/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0030 - val_loss: 5.0575e-05 - val_rmse: 0.0045 - val_mse: 2.0362e-05 - val_mae: 0.0045 - 38ms/epoch - 3ms/step\n",
      "Epoch 116/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0040 - val_loss: 3.2649e-05 - val_rmse: 0.0023 - val_mse: 5.4280e-06 - val_mae: 0.0023 - 50ms/epoch - 3ms/step\n",
      "Epoch 117/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0040 - val_loss: 3.4251e-05 - val_rmse: 0.0031 - val_mse: 9.6806e-06 - val_mae: 0.0031 - 30ms/epoch - 2ms/step\n",
      "Epoch 118/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0027 - val_loss: 2.6791e-05 - val_rmse: 0.0022 - val_mse: 4.6391e-06 - val_mae: 0.0022 - 50ms/epoch - 3ms/step\n",
      "Epoch 119/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0023 - val_loss: 2.5254e-05 - val_rmse: 0.0023 - val_mse: 5.2771e-06 - val_mae: 0.0023 - 60ms/epoch - 4ms/step\n",
      "Epoch 120/5000\n",
      "\n",
      "Epoch 120: val_loss improved from 0.00005 to 0.00002, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-1.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0354 - mse: 0.0013 - mae: 0.0064 - val_loss: 1.9504e-05 - val_rmse: 0.0012 - val_mse: 1.4900e-06 - val_mae: 0.0012 - 45ms/epoch - 3ms/step\n",
      "Epoch 121/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0354 - mse: 0.0013 - mae: 0.0039 - val_loss: 2.9448e-05 - val_rmse: 0.0036 - val_mse: 1.3169e-05 - val_mae: 0.0036 - 39ms/epoch - 3ms/step\n",
      "Epoch 122/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0033 - val_loss: 1.8012e-05 - val_rmse: 0.0018 - val_mse: 3.3512e-06 - val_mae: 0.0018 - 61ms/epoch - 4ms/step\n",
      "Epoch 123/5000\n",
      "Restoring model weights from the end of the best epoch: 103.\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0032 - val_loss: 2.8539e-05 - val_rmse: 0.0039 - val_mse: 1.5297e-05 - val_mae: 0.0039 - 42ms/epoch - 3ms/step\n",
      "Epoch 123: early stopping\n",
      "7/7 [==============================] - 0s 2ms/step\n",
      "INFO:tensorflow:Assets written to: data/output/fnn_compressed/activity-1_saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/output/fnn_compressed/activity-1_saved_model/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2fae644a6044e4e833f0f0da4ed1aaa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>loss</td><td>â–ˆâ–†â–„â–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>mae</td><td>â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>mse</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>rmse</td><td>â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val_loss</td><td>â–ˆâ–†â–…â–„â–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val_mae</td><td>â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val_mse</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val_rmse</td><td>â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>121</td></tr><tr><td>best_val_loss</td><td>2e-05</td></tr><tr><td>epoch</td><td>122</td></tr><tr><td>loss</td><td>0.00126</td></tr><tr><td>mae</td><td>0.00323</td></tr><tr><td>mse</td><td>0.00124</td></tr><tr><td>rmse</td><td>0.03523</td></tr><tr><td>val_loss</td><td>3e-05</td></tr><tr><td>val_mae</td><td>0.00391</td></tr><tr><td>val_mse</td><td>2e-05</td></tr><tr><td>val_rmse</td><td>0.00391</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">activity-1</strong> at: <a href='https://wandb.ai/dfpl_regression/FNN_0.5_random/runs/dqo5mpgo' target=\"_blank\">https://wandb.ai/dfpl_regression/FNN_0.5_random/runs/dqo5mpgo</a><br/> View project at: <a href='https://wandb.ai/dfpl_regression/FNN_0.5_random' target=\"_blank\">https://wandb.ai/dfpl_regression/FNN_0.5_random</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20240808_154232-dqo5mpgo/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113578743404812, max=1.0â€¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dd1dde93acc2480699857fccf471e937"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.17.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/hertelj/git-hertelj/deepFPlearn/example/wandb/run-20240808_154254-mnnd6teh</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dfpl_regression/FNN_0.5_random/runs/mnnd6teh' target=\"_blank\">activity-2</a></strong> to <a href='https://wandb.ai/dfpl_regression/FNN_0.5_random' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/dfpl_regression/FNN_0.5_random' target=\"_blank\">https://wandb.ai/dfpl_regression/FNN_0.5_random</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/dfpl_regression/FNN_0.5_random/runs/mnnd6teh' target=\"_blank\">https://wandb.ai/dfpl_regression/FNN_0.5_random/runs/mnnd6teh</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hertelj/build/local/miniforge3/envs/dfpl/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "15/15 - 0s - loss: 4.4966 - rmse: 0.6188 - mse: 0.3830 - mae: 0.4648 - val_loss: 4.0342 - val_rmse: 0.2430 - val_mse: 0.0591 - val_mae: 0.1982 - 422ms/epoch - 28ms/step\n",
      "Epoch 2/5000\n",
      "15/15 - 0s - loss: 3.8641 - rmse: 0.2013 - mse: 0.0405 - mae: 0.1595 - val_loss: 3.6475 - val_rmse: 0.1319 - val_mse: 0.0174 - val_mae: 0.0946 - 36ms/epoch - 2ms/step\n",
      "Epoch 3/5000\n",
      "15/15 - 0s - loss: 3.4797 - rmse: 0.0870 - mse: 0.0076 - mae: 0.0670 - val_loss: 3.2889 - val_rmse: 0.0826 - val_mse: 0.0068 - val_mae: 0.0371 - 40ms/epoch - 3ms/step\n",
      "Epoch 4/5000\n",
      "15/15 - 0s - loss: 3.1370 - rmse: 0.0405 - mse: 0.0016 - mae: 0.0325 - val_loss: 2.9667 - val_rmse: 0.0760 - val_mse: 0.0058 - val_mae: 0.0244 - 41ms/epoch - 3ms/step\n",
      "Epoch 5/5000\n",
      "15/15 - 0s - loss: 2.8283 - rmse: 0.0221 - mse: 4.8683e-04 - mae: 0.0174 - val_loss: 2.6752 - val_rmse: 0.0728 - val_mse: 0.0053 - val_mae: 0.0152 - 42ms/epoch - 3ms/step\n",
      "Epoch 6/5000\n",
      "15/15 - 0s - loss: 2.5499 - rmse: 0.0144 - mse: 2.0700e-04 - mae: 0.0113 - val_loss: 2.4123 - val_rmse: 0.0710 - val_mse: 0.0050 - val_mae: 0.0124 - 55ms/epoch - 4ms/step\n",
      "Epoch 7/5000\n",
      "15/15 - 0s - loss: 2.2990 - rmse: 0.0111 - mse: 1.2417e-04 - mae: 0.0089 - val_loss: 2.1754 - val_rmse: 0.0707 - val_mse: 0.0050 - val_mae: 0.0114 - 60ms/epoch - 4ms/step\n",
      "Epoch 8/5000\n",
      "15/15 - 0s - loss: 2.0728 - rmse: 0.0089 - mse: 7.9812e-05 - mae: 0.0072 - val_loss: 1.9619 - val_rmse: 0.0705 - val_mse: 0.0050 - val_mae: 0.0092 - 53ms/epoch - 4ms/step\n",
      "Epoch 9/5000\n",
      "15/15 - 0s - loss: 1.8688 - rmse: 0.0070 - mse: 4.8462e-05 - mae: 0.0055 - val_loss: 1.7693 - val_rmse: 0.0704 - val_mse: 0.0050 - val_mae: 0.0088 - 48ms/epoch - 3ms/step\n",
      "Epoch 10/5000\n",
      "\n",
      "Epoch 10: val_loss improved from inf to 1.59571, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-2.model.weights.hdf5\n",
      "15/15 - 0s - loss: 1.6850 - rmse: 0.0062 - mse: 3.8013e-05 - mae: 0.0049 - val_loss: 1.5957 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0080 - 42ms/epoch - 3ms/step\n",
      "Epoch 11/5000\n",
      "15/15 - 0s - loss: 1.5192 - rmse: 0.0050 - mse: 2.5304e-05 - mae: 0.0040 - val_loss: 1.4392 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0076 - 37ms/epoch - 2ms/step\n",
      "Epoch 12/5000\n",
      "15/15 - 0s - loss: 1.3697 - rmse: 0.0043 - mse: 1.8570e-05 - mae: 0.0034 - val_loss: 1.2981 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0072 - 42ms/epoch - 3ms/step\n",
      "Epoch 13/5000\n",
      "15/15 - 0s - loss: 1.2350 - rmse: 0.0039 - mse: 1.5452e-05 - mae: 0.0031 - val_loss: 1.1709 - val_rmse: 0.0703 - val_mse: 0.0049 - val_mae: 0.0071 - 42ms/epoch - 3ms/step\n",
      "Epoch 14/5000\n",
      "15/15 - 0s - loss: 1.1135 - rmse: 0.0034 - mse: 1.1334e-05 - mae: 0.0027 - val_loss: 1.0562 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0067 - 41ms/epoch - 3ms/step\n",
      "Epoch 15/5000\n",
      "15/15 - 0s - loss: 1.0039 - rmse: 0.0031 - mse: 9.5369e-06 - mae: 0.0024 - val_loss: 0.9527 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0064 - 42ms/epoch - 3ms/step\n",
      "Epoch 16/5000\n",
      "15/15 - 0s - loss: 0.9052 - rmse: 0.0026 - mse: 6.6254e-06 - mae: 0.0020 - val_loss: 0.8595 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0063 - 38ms/epoch - 3ms/step\n",
      "Epoch 17/5000\n",
      "15/15 - 0s - loss: 0.8161 - rmse: 0.0023 - mse: 5.4966e-06 - mae: 0.0019 - val_loss: 0.7754 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0061 - 46ms/epoch - 3ms/step\n",
      "Epoch 18/5000\n",
      "15/15 - 0s - loss: 0.7358 - rmse: 0.0020 - mse: 3.9836e-06 - mae: 0.0015 - val_loss: 0.6996 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0059 - 54ms/epoch - 4ms/step\n",
      "Epoch 19/5000\n",
      "15/15 - 0s - loss: 0.6634 - rmse: 0.0018 - mse: 3.3362e-06 - mae: 0.0015 - val_loss: 0.6313 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0058 - 41ms/epoch - 3ms/step\n",
      "Epoch 20/5000\n",
      "\n",
      "Epoch 20: val_loss improved from 1.59571 to 0.56966, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-2.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.5982 - rmse: 0.0015 - mse: 2.3838e-06 - mae: 0.0012 - val_loss: 0.5697 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0057 - 43ms/epoch - 3ms/step\n",
      "Epoch 21/5000\n",
      "15/15 - 0s - loss: 0.5393 - rmse: 0.0014 - mse: 1.9140e-06 - mae: 0.0011 - val_loss: 0.5141 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0056 - 34ms/epoch - 2ms/step\n",
      "Epoch 22/5000\n",
      "15/15 - 0s - loss: 0.4863 - rmse: 0.0012 - mse: 1.4825e-06 - mae: 9.7156e-04 - val_loss: 0.4640 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0055 - 42ms/epoch - 3ms/step\n",
      "Epoch 23/5000\n",
      "15/15 - 0s - loss: 0.4384 - rmse: 0.0011 - mse: 1.1507e-06 - mae: 8.4993e-04 - val_loss: 0.4188 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0054 - 41ms/epoch - 3ms/step\n",
      "Epoch 24/5000\n",
      "15/15 - 0s - loss: 0.3953 - rmse: 9.2116e-04 - mse: 8.4853e-07 - mae: 7.3776e-04 - val_loss: 0.3781 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0054 - 43ms/epoch - 3ms/step\n",
      "Epoch 25/5000\n",
      "15/15 - 0s - loss: 0.3564 - rmse: 8.2009e-04 - mse: 6.7255e-07 - mae: 6.5690e-04 - val_loss: 0.3414 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0053 - 49ms/epoch - 3ms/step\n",
      "Epoch 26/5000\n",
      "15/15 - 0s - loss: 0.3213 - rmse: 7.4504e-04 - mse: 5.5508e-07 - mae: 5.8767e-04 - val_loss: 0.3083 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0053 - 32ms/epoch - 2ms/step\n",
      "Epoch 27/5000\n",
      "15/15 - 0s - loss: 0.2897 - rmse: 6.2837e-04 - mse: 3.9484e-07 - mae: 5.0207e-04 - val_loss: 0.2785 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0052 - 34ms/epoch - 2ms/step\n",
      "Epoch 28/5000\n",
      "15/15 - 0s - loss: 0.2612 - rmse: 5.7320e-04 - mse: 3.2856e-07 - mae: 4.5983e-04 - val_loss: 0.2515 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0052 - 35ms/epoch - 2ms/step\n",
      "Epoch 29/5000\n",
      "15/15 - 0s - loss: 0.2355 - rmse: 4.8356e-04 - mse: 2.3383e-07 - mae: 3.8513e-04 - val_loss: 0.2273 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0051 - 36ms/epoch - 2ms/step\n",
      "Epoch 30/5000\n",
      "\n",
      "Epoch 30: val_loss improved from 0.56966 to 0.20541, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-2.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.2124 - rmse: 4.5270e-04 - mse: 2.0494e-07 - mae: 3.5534e-04 - val_loss: 0.2054 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0051 - 41ms/epoch - 3ms/step\n",
      "Epoch 31/5000\n",
      "15/15 - 0s - loss: 0.1915 - rmse: 3.9084e-04 - mse: 1.5276e-07 - mae: 3.1098e-04 - val_loss: 0.1857 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0051 - 37ms/epoch - 2ms/step\n",
      "Epoch 32/5000\n",
      "15/15 - 0s - loss: 0.1726 - rmse: 3.3803e-04 - mse: 1.1427e-07 - mae: 2.6901e-04 - val_loss: 0.1679 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0051 - 36ms/epoch - 2ms/step\n",
      "Epoch 33/5000\n",
      "15/15 - 0s - loss: 0.1556 - rmse: 2.8754e-04 - mse: 8.2677e-08 - mae: 2.2879e-04 - val_loss: 0.1519 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0050 - 47ms/epoch - 3ms/step\n",
      "Epoch 34/5000\n",
      "15/15 - 0s - loss: 0.1403 - rmse: 2.6150e-04 - mse: 6.8384e-08 - mae: 2.0600e-04 - val_loss: 0.1374 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0050 - 33ms/epoch - 2ms/step\n",
      "Epoch 35/5000\n",
      "15/15 - 0s - loss: 0.1265 - rmse: 2.3237e-04 - mse: 5.3995e-08 - mae: 1.8564e-04 - val_loss: 0.1244 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0050 - 34ms/epoch - 2ms/step\n",
      "Epoch 36/5000\n",
      "15/15 - 0s - loss: 0.1141 - rmse: 2.0257e-04 - mse: 4.1035e-08 - mae: 1.5993e-04 - val_loss: 0.1126 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0050 - 32ms/epoch - 2ms/step\n",
      "Epoch 37/5000\n",
      "15/15 - 0s - loss: 0.1029 - rmse: 1.8577e-04 - mse: 3.4509e-08 - mae: 1.4994e-04 - val_loss: 0.1020 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0050 - 33ms/epoch - 2ms/step\n",
      "Epoch 38/5000\n",
      "15/15 - 0s - loss: 0.0927 - rmse: 1.7220e-04 - mse: 2.9652e-08 - mae: 1.3656e-04 - val_loss: 0.0925 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0050 - 32ms/epoch - 2ms/step\n",
      "Epoch 39/5000\n",
      "15/15 - 0s - loss: 0.0836 - rmse: 1.4907e-04 - mse: 2.2222e-08 - mae: 1.1763e-04 - val_loss: 0.0839 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0050 - 32ms/epoch - 2ms/step\n",
      "Epoch 40/5000\n",
      "\n",
      "Epoch 40: val_loss improved from 0.20541 to 0.07610, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-2.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0754 - rmse: 1.3902e-04 - mse: 1.9328e-08 - mae: 1.1077e-04 - val_loss: 0.0761 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0050 - 45ms/epoch - 3ms/step\n",
      "Epoch 41/5000\n",
      "15/15 - 0s - loss: 0.0680 - rmse: 1.1940e-04 - mse: 1.4257e-08 - mae: 9.4175e-05 - val_loss: 0.0691 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0050 - 32ms/epoch - 2ms/step\n",
      "Epoch 42/5000\n",
      "15/15 - 0s - loss: 0.0613 - rmse: 1.1089e-04 - mse: 1.2296e-08 - mae: 8.8279e-05 - val_loss: 0.0628 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0050 - 43ms/epoch - 3ms/step\n",
      "Epoch 43/5000\n",
      "15/15 - 0s - loss: 0.0553 - rmse: 1.0112e-04 - mse: 1.0224e-08 - mae: 8.1321e-05 - val_loss: 0.0571 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0050 - 45ms/epoch - 3ms/step\n",
      "Epoch 44/5000\n",
      "15/15 - 0s - loss: 0.0498 - rmse: 9.4469e-05 - mse: 8.9244e-09 - mae: 7.5522e-05 - val_loss: 0.0520 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 31ms/epoch - 2ms/step\n",
      "Epoch 45/5000\n",
      "15/15 - 0s - loss: 0.0449 - rmse: 8.5705e-05 - mse: 7.3453e-09 - mae: 6.8176e-05 - val_loss: 0.0473 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 39ms/epoch - 3ms/step\n",
      "Epoch 46/5000\n",
      "15/15 - 0s - loss: 0.0405 - rmse: 8.0253e-05 - mse: 6.4406e-09 - mae: 6.3708e-05 - val_loss: 0.0432 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 33ms/epoch - 2ms/step\n",
      "Epoch 47/5000\n",
      "15/15 - 0s - loss: 0.0365 - rmse: 7.4845e-05 - mse: 5.6017e-09 - mae: 6.0693e-05 - val_loss: 0.0394 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 30ms/epoch - 2ms/step\n",
      "Epoch 48/5000\n",
      "15/15 - 0s - loss: 0.0329 - rmse: 6.8402e-05 - mse: 4.6789e-09 - mae: 5.4361e-05 - val_loss: 0.0360 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 33ms/epoch - 2ms/step\n",
      "Epoch 49/5000\n",
      "15/15 - 0s - loss: 0.0297 - rmse: 6.3486e-05 - mse: 4.0305e-09 - mae: 5.0739e-05 - val_loss: 0.0330 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 34ms/epoch - 2ms/step\n",
      "Epoch 50/5000\n",
      "\n",
      "Epoch 50: val_loss improved from 0.07610 to 0.03019, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-2.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0268 - rmse: 5.8993e-05 - mse: 3.4802e-09 - mae: 4.6222e-05 - val_loss: 0.0302 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 49ms/epoch - 3ms/step\n",
      "Epoch 51/5000\n",
      "15/15 - 0s - loss: 0.0241 - rmse: 5.2636e-05 - mse: 2.7705e-09 - mae: 4.1998e-05 - val_loss: 0.0277 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 36ms/epoch - 2ms/step\n",
      "Epoch 52/5000\n",
      "15/15 - 0s - loss: 0.0218 - rmse: 5.0721e-05 - mse: 2.5726e-09 - mae: 4.0561e-05 - val_loss: 0.0255 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 44ms/epoch - 3ms/step\n",
      "Epoch 53/5000\n",
      "15/15 - 0s - loss: 0.0196 - rmse: 4.7485e-05 - mse: 2.2548e-09 - mae: 3.7394e-05 - val_loss: 0.0234 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 41ms/epoch - 3ms/step\n",
      "Epoch 54/5000\n",
      "15/15 - 0s - loss: 0.0177 - rmse: 4.3866e-05 - mse: 1.9242e-09 - mae: 3.4660e-05 - val_loss: 0.0216 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 42ms/epoch - 3ms/step\n",
      "Epoch 55/5000\n",
      "15/15 - 0s - loss: 0.0159 - rmse: 4.1691e-05 - mse: 1.7382e-09 - mae: 3.3671e-05 - val_loss: 0.0200 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 38ms/epoch - 3ms/step\n",
      "Epoch 56/5000\n",
      "15/15 - 0s - loss: 0.0144 - rmse: 4.0531e-05 - mse: 1.6427e-09 - mae: 3.2585e-05 - val_loss: 0.0185 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 40ms/epoch - 3ms/step\n",
      "Epoch 57/5000\n",
      "15/15 - 0s - loss: 0.0130 - rmse: 3.6783e-05 - mse: 1.3530e-09 - mae: 2.9758e-05 - val_loss: 0.0172 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 43ms/epoch - 3ms/step\n",
      "Epoch 58/5000\n",
      "15/15 - 0s - loss: 0.0117 - rmse: 3.5336e-05 - mse: 1.2486e-09 - mae: 2.7649e-05 - val_loss: 0.0160 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 42ms/epoch - 3ms/step\n",
      "Epoch 59/5000\n",
      "15/15 - 0s - loss: 0.0105 - rmse: 3.1722e-05 - mse: 1.0063e-09 - mae: 2.5594e-05 - val_loss: 0.0149 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 43ms/epoch - 3ms/step\n",
      "Epoch 60/5000\n",
      "\n",
      "Epoch 60: val_loss improved from 0.03019 to 0.01390, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-2.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0095 - rmse: 3.1198e-05 - mse: 9.7334e-10 - mae: 2.4052e-05 - val_loss: 0.0139 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 44ms/epoch - 3ms/step\n",
      "Epoch 61/5000\n",
      "15/15 - 0s - loss: 0.0086 - rmse: 2.9299e-05 - mse: 8.5843e-10 - mae: 2.3406e-05 - val_loss: 0.0130 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 48ms/epoch - 3ms/step\n",
      "Epoch 62/5000\n",
      "15/15 - 0s - loss: 0.0077 - rmse: 2.6036e-05 - mse: 6.7790e-10 - mae: 2.1008e-05 - val_loss: 0.0122 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 52ms/epoch - 3ms/step\n",
      "Epoch 63/5000\n",
      "15/15 - 0s - loss: 0.0070 - rmse: 2.4317e-05 - mse: 5.9131e-10 - mae: 1.9568e-05 - val_loss: 0.0115 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 31ms/epoch - 2ms/step\n",
      "Epoch 64/5000\n",
      "15/15 - 0s - loss: 0.0063 - rmse: 2.3526e-05 - mse: 5.5347e-10 - mae: 1.9008e-05 - val_loss: 0.0109 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 31ms/epoch - 2ms/step\n",
      "Epoch 65/5000\n",
      "15/15 - 0s - loss: 0.0057 - rmse: 2.3008e-05 - mse: 5.2935e-10 - mae: 1.8253e-05 - val_loss: 0.0103 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 33ms/epoch - 2ms/step\n",
      "Epoch 66/5000\n",
      "15/15 - 0s - loss: 0.0051 - rmse: 2.1690e-05 - mse: 4.7044e-10 - mae: 1.7474e-05 - val_loss: 0.0097 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 36ms/epoch - 2ms/step\n",
      "Epoch 67/5000\n",
      "15/15 - 0s - loss: 0.0046 - rmse: 2.0197e-05 - mse: 4.0790e-10 - mae: 1.6034e-05 - val_loss: 0.0093 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 37ms/epoch - 2ms/step\n",
      "Epoch 68/5000\n",
      "15/15 - 0s - loss: 0.0041 - rmse: 2.0264e-05 - mse: 4.1065e-10 - mae: 1.6042e-05 - val_loss: 0.0088 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 42ms/epoch - 3ms/step\n",
      "Epoch 69/5000\n",
      "15/15 - 0s - loss: 0.0037 - rmse: 1.8368e-05 - mse: 3.3740e-10 - mae: 1.4628e-05 - val_loss: 0.0085 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 32ms/epoch - 2ms/step\n",
      "Epoch 70/5000\n",
      "\n",
      "Epoch 70: val_loss improved from 0.01390 to 0.00811, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-2.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0034 - rmse: 1.7755e-05 - mse: 3.1524e-10 - mae: 1.4046e-05 - val_loss: 0.0081 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 44ms/epoch - 3ms/step\n",
      "Epoch 71/5000\n",
      "15/15 - 0s - loss: 0.0030 - rmse: 1.5314e-05 - mse: 2.3451e-10 - mae: 1.2573e-05 - val_loss: 0.0078 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 32ms/epoch - 2ms/step\n",
      "Epoch 72/5000\n",
      "15/15 - 0s - loss: 0.0027 - rmse: 1.5965e-05 - mse: 2.5488e-10 - mae: 1.2956e-05 - val_loss: 0.0075 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 35ms/epoch - 2ms/step\n",
      "Epoch 73/5000\n",
      "15/15 - 0s - loss: 0.0025 - rmse: 1.5035e-05 - mse: 2.2604e-10 - mae: 1.2036e-05 - val_loss: 0.0073 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 31ms/epoch - 2ms/step\n",
      "Epoch 74/5000\n",
      "15/15 - 0s - loss: 0.0022 - rmse: 1.4222e-05 - mse: 2.0228e-10 - mae: 1.1499e-05 - val_loss: 0.0070 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 36ms/epoch - 2ms/step\n",
      "Epoch 75/5000\n",
      "15/15 - 0s - loss: 0.0020 - rmse: 1.3513e-05 - mse: 1.8260e-10 - mae: 1.0605e-05 - val_loss: 0.0068 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 55ms/epoch - 4ms/step\n",
      "Epoch 76/5000\n",
      "15/15 - 0s - loss: 0.0018 - rmse: 1.2543e-05 - mse: 1.5732e-10 - mae: 9.9912e-06 - val_loss: 0.0066 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 36ms/epoch - 2ms/step\n",
      "Epoch 77/5000\n",
      "15/15 - 0s - loss: 0.0016 - rmse: 1.2391e-05 - mse: 1.5352e-10 - mae: 9.7054e-06 - val_loss: 0.0065 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 41ms/epoch - 3ms/step\n",
      "Epoch 78/5000\n",
      "15/15 - 0s - loss: 0.0015 - rmse: 1.1216e-05 - mse: 1.2580e-10 - mae: 8.8782e-06 - val_loss: 0.0063 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 45ms/epoch - 3ms/step\n",
      "Epoch 79/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 1.0640e-05 - mse: 1.1320e-10 - mae: 8.3597e-06 - val_loss: 0.0062 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 39ms/epoch - 3ms/step\n",
      "Epoch 80/5000\n",
      "\n",
      "Epoch 80: val_loss improved from 0.00811 to 0.00606, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-2.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 1.0148e-05 - mse: 1.0298e-10 - mae: 8.0799e-06 - val_loss: 0.0061 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 41ms/epoch - 3ms/step\n",
      "Epoch 81/5000\n",
      "15/15 - 0s - loss: 0.0011 - rmse: 1.0178e-05 - mse: 1.0360e-10 - mae: 8.2397e-06 - val_loss: 0.0059 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 43ms/epoch - 3ms/step\n",
      "Epoch 82/5000\n",
      "15/15 - 0s - loss: 9.7344e-04 - rmse: 9.5231e-06 - mse: 9.0690e-11 - mae: 7.6589e-06 - val_loss: 0.0058 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 39ms/epoch - 3ms/step\n",
      "Epoch 83/5000\n",
      "15/15 - 0s - loss: 8.7767e-04 - rmse: 9.0517e-06 - mse: 8.1932e-11 - mae: 7.4353e-06 - val_loss: 0.0058 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 30ms/epoch - 2ms/step\n",
      "Epoch 84/5000\n",
      "15/15 - 0s - loss: 7.9133e-04 - rmse: 8.1506e-06 - mse: 6.6432e-11 - mae: 6.5825e-06 - val_loss: 0.0057 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 34ms/epoch - 2ms/step\n",
      "Epoch 85/5000\n",
      "15/15 - 0s - loss: 7.1348e-04 - rmse: 8.0621e-06 - mse: 6.4997e-11 - mae: 6.5223e-06 - val_loss: 0.0056 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 32ms/epoch - 2ms/step\n",
      "Epoch 86/5000\n",
      "15/15 - 0s - loss: 6.4329e-04 - rmse: 7.3981e-06 - mse: 5.4732e-11 - mae: 5.8872e-06 - val_loss: 0.0055 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 36ms/epoch - 2ms/step\n",
      "Epoch 87/5000\n",
      "15/15 - 0s - loss: 5.8000e-04 - rmse: 6.7947e-06 - mse: 4.6168e-11 - mae: 5.5012e-06 - val_loss: 0.0055 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 33ms/epoch - 2ms/step\n",
      "Epoch 88/5000\n",
      "15/15 - 0s - loss: 5.2294e-04 - rmse: 6.6767e-06 - mse: 4.4579e-11 - mae: 5.3483e-06 - val_loss: 0.0054 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 47ms/epoch - 3ms/step\n",
      "Epoch 89/5000\n",
      "15/15 - 0s - loss: 4.7149e-04 - rmse: 6.4021e-06 - mse: 4.0987e-11 - mae: 5.1398e-06 - val_loss: 0.0054 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 32ms/epoch - 2ms/step\n",
      "Epoch 90/5000\n",
      "\n",
      "Epoch 90: val_loss improved from 0.00606 to 0.00533, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-2.model.weights.hdf5\n",
      "15/15 - 0s - loss: 4.2511e-04 - rmse: 5.9790e-06 - mse: 3.5748e-11 - mae: 4.7839e-06 - val_loss: 0.0053 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 46ms/epoch - 3ms/step\n",
      "Epoch 91/5000\n",
      "15/15 - 0s - loss: 3.8329e-04 - rmse: 5.5635e-06 - mse: 3.0952e-11 - mae: 4.4248e-06 - val_loss: 0.0053 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 45ms/epoch - 3ms/step\n",
      "Epoch 92/5000\n",
      "15/15 - 0s - loss: 3.4558e-04 - rmse: 5.5429e-06 - mse: 3.0724e-11 - mae: 4.3992e-06 - val_loss: 0.0053 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 40ms/epoch - 3ms/step\n",
      "Epoch 93/5000\n",
      "15/15 - 0s - loss: 3.1158e-04 - rmse: 5.2786e-06 - mse: 2.7864e-11 - mae: 4.2053e-06 - val_loss: 0.0052 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 42ms/epoch - 3ms/step\n",
      "Epoch 94/5000\n",
      "15/15 - 0s - loss: 2.8093e-04 - rmse: 4.8552e-06 - mse: 2.3573e-11 - mae: 3.8334e-06 - val_loss: 0.0052 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 41ms/epoch - 3ms/step\n",
      "Epoch 95/5000\n",
      "15/15 - 0s - loss: 2.5329e-04 - rmse: 4.7863e-06 - mse: 2.2908e-11 - mae: 3.8336e-06 - val_loss: 0.0052 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 59ms/epoch - 4ms/step\n",
      "Epoch 96/5000\n",
      "15/15 - 0s - loss: 2.2837e-04 - rmse: 4.3810e-06 - mse: 1.9193e-11 - mae: 3.4221e-06 - val_loss: 0.0051 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 55ms/epoch - 4ms/step\n",
      "Epoch 97/5000\n",
      "15/15 - 0s - loss: 2.0591e-04 - rmse: 4.1021e-06 - mse: 1.6827e-11 - mae: 3.2748e-06 - val_loss: 0.0051 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 39ms/epoch - 3ms/step\n",
      "Epoch 98/5000\n",
      "15/15 - 0s - loss: 1.8565e-04 - rmse: 3.9178e-06 - mse: 1.5349e-11 - mae: 3.1195e-06 - val_loss: 0.0051 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 37ms/epoch - 2ms/step\n",
      "Epoch 99/5000\n",
      "15/15 - 0s - loss: 1.6739e-04 - rmse: 3.7727e-06 - mse: 1.4233e-11 - mae: 3.0410e-06 - val_loss: 0.0051 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 40ms/epoch - 3ms/step\n",
      "Epoch 100/5000\n",
      "\n",
      "Epoch 100: val_loss improved from 0.00533 to 0.00507, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-2.model.weights.hdf5\n",
      "15/15 - 0s - loss: 1.5092e-04 - rmse: 3.4626e-06 - mse: 1.1989e-11 - mae: 2.7592e-06 - val_loss: 0.0051 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 45ms/epoch - 3ms/step\n",
      "Epoch 101/5000\n",
      "15/15 - 0s - loss: 1.3607e-04 - rmse: 3.2581e-06 - mse: 1.0616e-11 - mae: 2.5862e-06 - val_loss: 0.0051 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 35ms/epoch - 2ms/step\n",
      "Epoch 102/5000\n",
      "15/15 - 0s - loss: 1.2268e-04 - rmse: 3.1508e-06 - mse: 9.9274e-12 - mae: 2.4597e-06 - val_loss: 0.0050 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 34ms/epoch - 2ms/step\n",
      "Epoch 103/5000\n",
      "15/15 - 0s - loss: 1.1062e-04 - rmse: 3.1278e-06 - mse: 9.7833e-12 - mae: 2.5532e-06 - val_loss: 0.0050 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 39ms/epoch - 3ms/step\n",
      "Epoch 104/5000\n",
      "15/15 - 0s - loss: 9.9733e-05 - rmse: 2.9329e-06 - mse: 8.6018e-12 - mae: 2.3689e-06 - val_loss: 0.0050 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 44ms/epoch - 3ms/step\n",
      "Epoch 105/5000\n",
      "15/15 - 0s - loss: 8.9921e-05 - rmse: 2.7727e-06 - mse: 7.6878e-12 - mae: 2.2177e-06 - val_loss: 0.0050 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 41ms/epoch - 3ms/step\n",
      "Epoch 106/5000\n",
      "15/15 - 0s - loss: 8.1075e-05 - rmse: 2.6719e-06 - mse: 7.1393e-12 - mae: 2.1546e-06 - val_loss: 0.0050 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 49ms/epoch - 3ms/step\n",
      "Epoch 107/5000\n",
      "15/15 - 0s - loss: 7.3099e-05 - rmse: 2.4601e-06 - mse: 6.0521e-12 - mae: 1.9598e-06 - val_loss: 0.0050 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 41ms/epoch - 3ms/step\n",
      "Epoch 108/5000\n",
      "15/15 - 0s - loss: 6.5908e-05 - rmse: 2.3433e-06 - mse: 5.4911e-12 - mae: 1.8487e-06 - val_loss: 0.0050 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 46ms/epoch - 3ms/step\n",
      "Epoch 109/5000\n",
      "15/15 - 0s - loss: 5.9424e-05 - rmse: 2.3105e-06 - mse: 5.3385e-12 - mae: 1.8689e-06 - val_loss: 0.0050 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 52ms/epoch - 3ms/step\n",
      "Epoch 110/5000\n",
      "\n",
      "Epoch 110: val_loss improved from 0.00507 to 0.00498, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-2.model.weights.hdf5\n",
      "15/15 - 0s - loss: 5.3578e-05 - rmse: 2.2196e-06 - mse: 4.9266e-12 - mae: 1.7479e-06 - val_loss: 0.0050 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 36ms/epoch - 2ms/step\n",
      "Epoch 111/5000\n",
      "15/15 - 0s - loss: 4.8307e-05 - rmse: 1.9953e-06 - mse: 3.9814e-12 - mae: 1.5952e-06 - val_loss: 0.0050 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 33ms/epoch - 2ms/step\n",
      "Epoch 112/5000\n",
      "15/15 - 0s - loss: 4.3554e-05 - rmse: 1.8245e-06 - mse: 3.3287e-12 - mae: 1.4461e-06 - val_loss: 0.0050 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 33ms/epoch - 2ms/step\n",
      "Epoch 113/5000\n",
      "15/15 - 0s - loss: 3.9270e-05 - rmse: 1.7739e-06 - mse: 3.1466e-12 - mae: 1.4282e-06 - val_loss: 0.0050 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 28ms/epoch - 2ms/step\n",
      "Epoch 114/5000\n",
      "15/15 - 0s - loss: 3.5406e-05 - rmse: 1.7227e-06 - mse: 2.9676e-12 - mae: 1.3590e-06 - val_loss: 0.0050 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 29ms/epoch - 2ms/step\n",
      "Epoch 115/5000\n",
      "15/15 - 0s - loss: 3.1923e-05 - rmse: 1.6291e-06 - mse: 2.6538e-12 - mae: 1.3098e-06 - val_loss: 0.0050 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 28ms/epoch - 2ms/step\n",
      "Epoch 116/5000\n",
      "15/15 - 0s - loss: 2.8782e-05 - rmse: 1.4602e-06 - mse: 2.1321e-12 - mae: 1.1587e-06 - val_loss: 0.0050 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 31ms/epoch - 2ms/step\n",
      "Epoch 117/5000\n",
      "15/15 - 0s - loss: 2.5951e-05 - rmse: 1.4368e-06 - mse: 2.0644e-12 - mae: 1.1254e-06 - val_loss: 0.0050 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 30ms/epoch - 2ms/step\n",
      "Epoch 118/5000\n",
      "15/15 - 0s - loss: 2.3398e-05 - rmse: 1.4160e-06 - mse: 2.0051e-12 - mae: 1.1322e-06 - val_loss: 0.0049 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 38ms/epoch - 3ms/step\n",
      "Epoch 119/5000\n",
      "15/15 - 0s - loss: 2.1096e-05 - rmse: 1.2574e-06 - mse: 1.5812e-12 - mae: 9.9439e-07 - val_loss: 0.0049 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 32ms/epoch - 2ms/step\n",
      "Epoch 120/5000\n",
      "\n",
      "Epoch 120: val_loss improved from 0.00498 to 0.00494, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-2.model.weights.hdf5\n",
      "15/15 - 0s - loss: 1.9021e-05 - rmse: 1.2678e-06 - mse: 1.6073e-12 - mae: 1.0274e-06 - val_loss: 0.0049 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 36ms/epoch - 2ms/step\n",
      "Epoch 121/5000\n",
      "15/15 - 0s - loss: 1.7149e-05 - rmse: 1.1600e-06 - mse: 1.3457e-12 - mae: 9.2786e-07 - val_loss: 0.0049 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 37ms/epoch - 2ms/step\n",
      "Epoch 122/5000\n",
      "15/15 - 0s - loss: 1.5462e-05 - rmse: 1.1557e-06 - mse: 1.3356e-12 - mae: 9.2980e-07 - val_loss: 0.0049 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 55ms/epoch - 4ms/step\n",
      "Epoch 123/5000\n",
      "15/15 - 0s - loss: 1.3941e-05 - rmse: 1.0830e-06 - mse: 1.1730e-12 - mae: 8.7370e-07 - val_loss: 0.0049 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 52ms/epoch - 3ms/step\n",
      "Epoch 124/5000\n",
      "15/15 - 0s - loss: 1.2570e-05 - rmse: 1.0380e-06 - mse: 1.0774e-12 - mae: 8.3563e-07 - val_loss: 0.0049 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 40ms/epoch - 3ms/step\n",
      "Epoch 125/5000\n",
      "15/15 - 0s - loss: 1.1333e-05 - rmse: 9.4513e-07 - mse: 8.9327e-13 - mae: 7.5401e-07 - val_loss: 0.0049 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 31ms/epoch - 2ms/step\n",
      "Epoch 126/5000\n",
      "15/15 - 0s - loss: 1.0218e-05 - rmse: 9.1489e-07 - mse: 8.3703e-13 - mae: 7.4904e-07 - val_loss: 0.0049 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 35ms/epoch - 2ms/step\n",
      "Epoch 127/5000\n",
      "15/15 - 0s - loss: 9.2128e-06 - rmse: 9.2751e-07 - mse: 8.6027e-13 - mae: 7.3509e-07 - val_loss: 0.0049 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 56ms/epoch - 4ms/step\n",
      "Epoch 128/5000\n",
      "15/15 - 0s - loss: 8.3065e-06 - rmse: 8.2552e-07 - mse: 6.8148e-13 - mae: 6.7408e-07 - val_loss: 0.0049 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 33ms/epoch - 2ms/step\n",
      "Epoch 129/5000\n",
      "15/15 - 0s - loss: 7.4893e-06 - rmse: 7.8022e-07 - mse: 6.0875e-13 - mae: 6.1886e-07 - val_loss: 0.0049 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 54ms/epoch - 4ms/step\n",
      "Epoch 130/5000\n",
      "\n",
      "Epoch 130: val_loss improved from 0.00494 to 0.00493, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-2.model.weights.hdf5\n",
      "15/15 - 0s - loss: 6.7525e-06 - rmse: 7.2705e-07 - mse: 5.2860e-13 - mae: 5.7923e-07 - val_loss: 0.0049 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 57ms/epoch - 4ms/step\n",
      "Epoch 131/5000\n",
      "15/15 - 0s - loss: 6.0882e-06 - rmse: 7.1443e-07 - mse: 5.1041e-13 - mae: 5.6421e-07 - val_loss: 0.0049 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 34ms/epoch - 2ms/step\n",
      "Epoch 132/5000\n",
      "15/15 - 0s - loss: 5.4893e-06 - rmse: 7.0339e-07 - mse: 4.9476e-13 - mae: 5.7597e-07 - val_loss: 0.0049 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 33ms/epoch - 2ms/step\n",
      "Epoch 133/5000\n",
      "15/15 - 0s - loss: 4.9492e-06 - rmse: 6.3117e-07 - mse: 3.9838e-13 - mae: 5.0833e-07 - val_loss: 0.0049 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 29ms/epoch - 2ms/step\n",
      "Epoch 134/5000\n",
      "15/15 - 0s - loss: 4.4623e-06 - rmse: 5.9090e-07 - mse: 3.4917e-13 - mae: 4.6593e-07 - val_loss: 0.0049 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 57ms/epoch - 4ms/step\n",
      "Epoch 135/5000\n",
      "15/15 - 0s - loss: 4.0233e-06 - rmse: 6.1335e-07 - mse: 3.7620e-13 - mae: 4.8780e-07 - val_loss: 0.0049 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 42ms/epoch - 3ms/step\n",
      "Epoch 136/5000\n",
      "Restoring model weights from the end of the best epoch: 116.\n",
      "15/15 - 0s - loss: 3.6275e-06 - rmse: 5.6020e-07 - mse: 3.1382e-13 - mae: 4.4851e-07 - val_loss: 0.0049 - val_rmse: 0.0702 - val_mse: 0.0049 - val_mae: 0.0049 - 60ms/epoch - 4ms/step\n",
      "Epoch 136: early stopping\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "INFO:tensorflow:Assets written to: data/output/fnn_compressed/activity-2_saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/output/fnn_compressed/activity-2_saved_model/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "551e0e165f514ae19cb710c1fb95bd7d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>loss</td><td>â–ˆâ–‡â–…â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>mae</td><td>â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>mse</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>rmse</td><td>â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val_loss</td><td>â–ˆâ–‡â–…â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val_mae</td><td>â–ˆâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val_mse</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val_rmse</td><td>â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>135</td></tr><tr><td>best_val_loss</td><td>0.00493</td></tr><tr><td>epoch</td><td>135</td></tr><tr><td>loss</td><td>0.0</td></tr><tr><td>mae</td><td>0.0</td></tr><tr><td>mse</td><td>0.0</td></tr><tr><td>rmse</td><td>0.0</td></tr><tr><td>val_loss</td><td>0.00493</td></tr><tr><td>val_mae</td><td>0.00493</td></tr><tr><td>val_mse</td><td>0.00493</td></tr><tr><td>val_rmse</td><td>0.07019</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">activity-2</strong> at: <a href='https://wandb.ai/dfpl_regression/FNN_0.5_random/runs/mnnd6teh' target=\"_blank\">https://wandb.ai/dfpl_regression/FNN_0.5_random/runs/mnnd6teh</a><br/> View project at: <a href='https://wandb.ai/dfpl_regression/FNN_0.5_random' target=\"_blank\">https://wandb.ai/dfpl_regression/FNN_0.5_random</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20240808_154254-mnnd6teh/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011113602044578228, max=1.0â€¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4d862042e1774dd4af806ff724558550"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.17.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/hertelj/git-hertelj/deepFPlearn/example/wandb/run-20240808_154310-za82jdu1</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dfpl_regression/FNN_0.5_random/runs/za82jdu1' target=\"_blank\">activity-3</a></strong> to <a href='https://wandb.ai/dfpl_regression/FNN_0.5_random' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/dfpl_regression/FNN_0.5_random' target=\"_blank\">https://wandb.ai/dfpl_regression/FNN_0.5_random</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/dfpl_regression/FNN_0.5_random/runs/za82jdu1' target=\"_blank\">https://wandb.ai/dfpl_regression/FNN_0.5_random/runs/za82jdu1</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hertelj/build/local/miniforge3/envs/dfpl/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "15/15 - 1s - loss: 4.4894 - rmse: 0.6278 - mse: 0.3942 - mae: 0.4883 - val_loss: 4.0264 - val_rmse: 0.2640 - val_mse: 0.0697 - val_mae: 0.2116 - 671ms/epoch - 45ms/step\n",
      "Epoch 2/5000\n",
      "15/15 - 0s - loss: 3.8701 - rmse: 0.2548 - mse: 0.0649 - mae: 0.2072 - val_loss: 3.6258 - val_rmse: 0.1149 - val_mse: 0.0132 - val_mae: 0.0967 - 52ms/epoch - 3ms/step\n",
      "Epoch 3/5000\n",
      "15/15 - 0s - loss: 3.4728 - rmse: 0.1330 - mse: 0.0177 - mae: 0.1047 - val_loss: 3.2686 - val_rmse: 0.0510 - val_mse: 0.0026 - val_mae: 0.0410 - 33ms/epoch - 2ms/step\n",
      "Epoch 4/5000\n",
      "15/15 - 0s - loss: 3.1240 - rmse: 0.0651 - mse: 0.0042 - mae: 0.0448 - val_loss: 2.9475 - val_rmse: 0.0354 - val_mse: 0.0013 - val_mae: 0.0283 - 32ms/epoch - 2ms/step\n",
      "Epoch 5/5000\n",
      "15/15 - 0s - loss: 2.8160 - rmse: 0.0491 - mse: 0.0024 - mae: 0.0297 - val_loss: 2.6570 - val_rmse: 0.0214 - val_mse: 4.5645e-04 - val_mae: 0.0175 - 32ms/epoch - 2ms/step\n",
      "Epoch 6/5000\n",
      "15/15 - 0s - loss: 2.5388 - rmse: 0.0447 - mse: 0.0020 - mae: 0.0233 - val_loss: 2.3957 - val_rmse: 0.0236 - val_mse: 5.5840e-04 - val_mae: 0.0193 - 33ms/epoch - 2ms/step\n",
      "Epoch 7/5000\n",
      "15/15 - 0s - loss: 2.2888 - rmse: 0.0402 - mse: 0.0016 - mae: 0.0171 - val_loss: 2.1597 - val_rmse: 0.0151 - val_mse: 2.2866e-04 - val_mae: 0.0125 - 29ms/epoch - 2ms/step\n",
      "Epoch 8/5000\n",
      "15/15 - 0s - loss: 2.0637 - rmse: 0.0400 - mse: 0.0016 - mae: 0.0178 - val_loss: 1.9471 - val_rmse: 0.0132 - val_mse: 1.7459e-04 - val_mae: 0.0107 - 31ms/epoch - 2ms/step\n",
      "Epoch 9/5000\n",
      "15/15 - 0s - loss: 1.8606 - rmse: 0.0382 - mse: 0.0015 - mae: 0.0142 - val_loss: 1.7555 - val_rmse: 0.0109 - val_mse: 1.1978e-04 - val_mae: 0.0089 - 34ms/epoch - 2ms/step\n",
      "Epoch 10/5000\n",
      "\n",
      "Epoch 10: val_loss improved from inf to 1.58278, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-3.model.weights.hdf5\n",
      "15/15 - 0s - loss: 1.6776 - rmse: 0.0376 - mse: 0.0014 - mae: 0.0147 - val_loss: 1.5828 - val_rmse: 0.0117 - val_mse: 1.3590e-04 - val_mae: 0.0093 - 44ms/epoch - 3ms/step\n",
      "Epoch 11/5000\n",
      "15/15 - 0s - loss: 1.5127 - rmse: 0.0369 - mse: 0.0014 - mae: 0.0128 - val_loss: 1.4270 - val_rmse: 0.0097 - val_mse: 9.3886e-05 - val_mae: 0.0078 - 33ms/epoch - 2ms/step\n",
      "Epoch 12/5000\n",
      "15/15 - 0s - loss: 1.3639 - rmse: 0.0357 - mse: 0.0013 - mae: 0.0106 - val_loss: 1.2866 - val_rmse: 0.0070 - val_mse: 4.8997e-05 - val_mae: 0.0055 - 31ms/epoch - 2ms/step\n",
      "Epoch 13/5000\n",
      "15/15 - 0s - loss: 1.2298 - rmse: 0.0356 - mse: 0.0013 - mae: 0.0085 - val_loss: 1.1600 - val_rmse: 0.0057 - val_mse: 3.3040e-05 - val_mae: 0.0045 - 29ms/epoch - 2ms/step\n",
      "Epoch 14/5000\n",
      "15/15 - 0s - loss: 1.1089 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0078 - val_loss: 1.0458 - val_rmse: 0.0059 - val_mse: 3.5259e-05 - val_mae: 0.0047 - 30ms/epoch - 2ms/step\n",
      "Epoch 15/5000\n",
      "15/15 - 0s - loss: 0.9999 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0073 - val_loss: 0.9429 - val_rmse: 0.0053 - val_mse: 2.8387e-05 - val_mae: 0.0043 - 29ms/epoch - 2ms/step\n",
      "Epoch 16/5000\n",
      "15/15 - 0s - loss: 0.9017 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0081 - val_loss: 0.8502 - val_rmse: 0.0052 - val_mse: 2.7224e-05 - val_mae: 0.0042 - 29ms/epoch - 2ms/step\n",
      "Epoch 17/5000\n",
      "15/15 - 0s - loss: 0.8131 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0067 - val_loss: 0.7666 - val_rmse: 0.0065 - val_mse: 4.2344e-05 - val_mae: 0.0054 - 33ms/epoch - 2ms/step\n",
      "Epoch 18/5000\n",
      "15/15 - 0s - loss: 0.7332 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0067 - val_loss: 0.6911 - val_rmse: 0.0039 - val_mse: 1.5076e-05 - val_mae: 0.0031 - 30ms/epoch - 2ms/step\n",
      "Epoch 19/5000\n",
      "15/15 - 0s - loss: 0.6612 - rmse: 0.0349 - mse: 0.0012 - mae: 0.0053 - val_loss: 0.6231 - val_rmse: 0.0053 - val_mse: 2.8212e-05 - val_mae: 0.0045 - 34ms/epoch - 2ms/step\n",
      "Epoch 20/5000\n",
      "\n",
      "Epoch 20: val_loss improved from 1.58278 to 0.56182, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-3.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.5962 - rmse: 0.0349 - mse: 0.0012 - mae: 0.0058 - val_loss: 0.5618 - val_rmse: 0.0032 - val_mse: 1.0077e-05 - val_mae: 0.0025 - 36ms/epoch - 2ms/step\n",
      "Epoch 21/5000\n",
      "15/15 - 0s - loss: 0.5377 - rmse: 0.0348 - mse: 0.0012 - mae: 0.0047 - val_loss: 0.5065 - val_rmse: 0.0028 - val_mse: 7.9177e-06 - val_mae: 0.0022 - 31ms/epoch - 2ms/step\n",
      "Epoch 22/5000\n",
      "15/15 - 0s - loss: 0.4849 - rmse: 0.0350 - mse: 0.0012 - mae: 0.0042 - val_loss: 0.4567 - val_rmse: 0.0037 - val_mse: 1.3560e-05 - val_mae: 0.0031 - 30ms/epoch - 2ms/step\n",
      "Epoch 23/5000\n",
      "15/15 - 0s - loss: 0.4373 - rmse: 0.0350 - mse: 0.0012 - mae: 0.0041 - val_loss: 0.4118 - val_rmse: 0.0022 - val_mse: 4.6514e-06 - val_mae: 0.0017 - 30ms/epoch - 2ms/step\n",
      "Epoch 24/5000\n",
      "15/15 - 0s - loss: 0.3945 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0067 - val_loss: 0.3713 - val_rmse: 0.0021 - val_mse: 4.3177e-06 - val_mae: 0.0017 - 33ms/epoch - 2ms/step\n",
      "Epoch 25/5000\n",
      "15/15 - 0s - loss: 0.3558 - rmse: 0.0350 - mse: 0.0012 - mae: 0.0043 - val_loss: 0.3348 - val_rmse: 0.0035 - val_mse: 1.2141e-05 - val_mae: 0.0030 - 31ms/epoch - 2ms/step\n",
      "Epoch 26/5000\n",
      "15/15 - 0s - loss: 0.3209 - rmse: 0.0349 - mse: 0.0012 - mae: 0.0036 - val_loss: 0.3018 - val_rmse: 0.0021 - val_mse: 4.6063e-06 - val_mae: 0.0017 - 31ms/epoch - 2ms/step\n",
      "Epoch 27/5000\n",
      "15/15 - 0s - loss: 0.2894 - rmse: 0.0348 - mse: 0.0012 - mae: 0.0034 - val_loss: 0.2721 - val_rmse: 0.0027 - val_mse: 7.2855e-06 - val_mae: 0.0023 - 48ms/epoch - 3ms/step\n",
      "Epoch 28/5000\n",
      "15/15 - 0s - loss: 0.2611 - rmse: 0.0349 - mse: 0.0012 - mae: 0.0031 - val_loss: 0.2454 - val_rmse: 0.0021 - val_mse: 4.3734e-06 - val_mae: 0.0017 - 32ms/epoch - 2ms/step\n",
      "Epoch 29/5000\n",
      "15/15 - 0s - loss: 0.2355 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0027 - val_loss: 0.2212 - val_rmse: 0.0018 - val_mse: 3.3648e-06 - val_mae: 0.0015 - 32ms/epoch - 2ms/step\n",
      "Epoch 30/5000\n",
      "\n",
      "Epoch 30: val_loss improved from 0.56182 to 0.19946, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-3.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.2125 - rmse: 0.0350 - mse: 0.0012 - mae: 0.0044 - val_loss: 0.1995 - val_rmse: 0.0012 - val_mse: 1.3802e-06 - val_mae: 9.4980e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 31/5000\n",
      "15/15 - 0s - loss: 0.1917 - rmse: 0.0350 - mse: 0.0012 - mae: 0.0029 - val_loss: 0.1798 - val_rmse: 0.0016 - val_mse: 2.6906e-06 - val_mae: 0.0014 - 40ms/epoch - 3ms/step\n",
      "Epoch 32/5000\n",
      "15/15 - 0s - loss: 0.1730 - rmse: 0.0350 - mse: 0.0012 - mae: 0.0042 - val_loss: 0.1622 - val_rmse: 0.0023 - val_mse: 5.4951e-06 - val_mae: 0.0022 - 53ms/epoch - 4ms/step\n",
      "Epoch 33/5000\n",
      "15/15 - 0s - loss: 0.1561 - rmse: 0.0350 - mse: 0.0012 - mae: 0.0026 - val_loss: 0.1462 - val_rmse: 7.0910e-04 - val_mse: 5.0282e-07 - val_mae: 5.7665e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 34/5000\n",
      "15/15 - 0s - loss: 0.1408 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0027 - val_loss: 0.1318 - val_rmse: 0.0025 - val_mse: 6.4737e-06 - val_mae: 0.0025 - 35ms/epoch - 2ms/step\n",
      "Epoch 35/5000\n",
      "15/15 - 0s - loss: 0.1271 - rmse: 0.0350 - mse: 0.0012 - mae: 0.0033 - val_loss: 0.1188 - val_rmse: 8.9765e-04 - val_mse: 8.0578e-07 - val_mae: 7.6483e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 36/5000\n",
      "15/15 - 0s - loss: 0.1147 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0024 - val_loss: 0.1072 - val_rmse: 0.0028 - val_mse: 7.6426e-06 - val_mae: 0.0027 - 37ms/epoch - 2ms/step\n",
      "Epoch 37/5000\n",
      "15/15 - 0s - loss: 0.1036 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0043 - val_loss: 0.0966 - val_rmse: 8.9218e-04 - val_mse: 7.9598e-07 - val_mae: 7.9884e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 38/5000\n",
      "15/15 - 0s - loss: 0.0935 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0021 - val_loss: 0.0871 - val_rmse: 0.0014 - val_mse: 1.9935e-06 - val_mae: 0.0014 - 37ms/epoch - 2ms/step\n",
      "Epoch 39/5000\n",
      "15/15 - 0s - loss: 0.0844 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0031 - val_loss: 0.0785 - val_rmse: 3.4906e-04 - val_mse: 1.2184e-07 - val_mae: 2.7734e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 40/5000\n",
      "\n",
      "Epoch 40: val_loss improved from 0.19946 to 0.07082, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-3.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0762 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0021 - val_loss: 0.0708 - val_rmse: 0.0020 - val_mse: 4.1360e-06 - val_mae: 0.0020 - 43ms/epoch - 3ms/step\n",
      "Epoch 41/5000\n",
      "15/15 - 0s - loss: 0.0689 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0049 - val_loss: 0.0639 - val_rmse: 8.4938e-04 - val_mse: 7.2145e-07 - val_mae: 8.1799e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 42/5000\n",
      "15/15 - 0s - loss: 0.0622 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0025 - val_loss: 0.0576 - val_rmse: 0.0016 - val_mse: 2.6175e-06 - val_mae: 0.0016 - 33ms/epoch - 2ms/step\n",
      "Epoch 43/5000\n",
      "15/15 - 0s - loss: 0.0562 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0029 - val_loss: 0.0519 - val_rmse: 9.6764e-04 - val_mse: 9.3632e-07 - val_mae: 9.5198e-04 - 30ms/epoch - 2ms/step\n",
      "Epoch 44/5000\n",
      "15/15 - 0s - loss: 0.0508 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0025 - val_loss: 0.0468 - val_rmse: 1.5257e-04 - val_mse: 2.3277e-08 - val_mae: 1.2425e-04 - 31ms/epoch - 2ms/step\n",
      "Epoch 45/5000\n",
      "15/15 - 0s - loss: 0.0459 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0024 - val_loss: 0.0422 - val_rmse: 0.0017 - val_mse: 2.7368e-06 - val_mae: 0.0016 - 31ms/epoch - 2ms/step\n",
      "Epoch 46/5000\n",
      "15/15 - 0s - loss: 0.0415 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0029 - val_loss: 0.0380 - val_rmse: 6.8310e-04 - val_mse: 4.6662e-07 - val_mae: 6.7393e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 47/5000\n",
      "15/15 - 0s - loss: 0.0376 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0025 - val_loss: 0.0343 - val_rmse: 0.0012 - val_mse: 1.3368e-06 - val_mae: 0.0012 - 31ms/epoch - 2ms/step\n",
      "Epoch 48/5000\n",
      "15/15 - 0s - loss: 0.0340 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0026 - val_loss: 0.0309 - val_rmse: 3.6428e-04 - val_mse: 1.3270e-07 - val_mae: 3.5472e-04 - 29ms/epoch - 2ms/step\n",
      "Epoch 49/5000\n",
      "15/15 - 0s - loss: 0.0308 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0018 - val_loss: 0.0279 - val_rmse: 0.0012 - val_mse: 1.5231e-06 - val_mae: 0.0012 - 38ms/epoch - 3ms/step\n",
      "Epoch 50/5000\n",
      "\n",
      "Epoch 50: val_loss improved from 0.07082 to 0.02514, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-3.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0279 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0032 - val_loss: 0.0251 - val_rmse: 9.4079e-04 - val_mse: 8.8509e-07 - val_mae: 9.3879e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 51/5000\n",
      "15/15 - 0s - loss: 0.0252 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0038 - val_loss: 0.0227 - val_rmse: 1.0161e-04 - val_mse: 1.0324e-08 - val_mae: 8.8358e-05 - 37ms/epoch - 2ms/step\n",
      "Epoch 52/5000\n",
      "15/15 - 0s - loss: 0.0229 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0024 - val_loss: 0.0204 - val_rmse: 0.0025 - val_mse: 6.1264e-06 - val_mae: 0.0025 - 39ms/epoch - 3ms/step\n",
      "Epoch 53/5000\n",
      "15/15 - 0s - loss: 0.0208 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0025 - val_loss: 0.0184 - val_rmse: 0.0015 - val_mse: 2.1992e-06 - val_mae: 0.0015 - 40ms/epoch - 3ms/step\n",
      "Epoch 54/5000\n",
      "15/15 - 0s - loss: 0.0188 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0037 - val_loss: 0.0166 - val_rmse: 1.6886e-04 - val_mse: 2.8513e-08 - val_mae: 1.6547e-04 - 45ms/epoch - 3ms/step\n",
      "Epoch 55/5000\n",
      "15/15 - 0s - loss: 0.0171 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0025 - val_loss: 0.0150 - val_rmse: 0.0027 - val_mse: 7.2915e-06 - val_mae: 0.0027 - 36ms/epoch - 2ms/step\n",
      "Epoch 56/5000\n",
      "15/15 - 0s - loss: 0.0155 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0029 - val_loss: 0.0135 - val_rmse: 0.0015 - val_mse: 2.2950e-06 - val_mae: 0.0015 - 30ms/epoch - 2ms/step\n",
      "Epoch 57/5000\n",
      "15/15 - 0s - loss: 0.0141 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0019 - val_loss: 0.0122 - val_rmse: 7.2846e-04 - val_mse: 5.3065e-07 - val_mae: 7.2815e-04 - 33ms/epoch - 2ms/step\n",
      "Epoch 58/5000\n",
      "15/15 - 0s - loss: 0.0129 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0042 - val_loss: 0.0110 - val_rmse: 0.0014 - val_mse: 2.0811e-06 - val_mae: 0.0014 - 27ms/epoch - 2ms/step\n",
      "Epoch 59/5000\n",
      "15/15 - 0s - loss: 0.0117 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0021 - val_loss: 0.0099 - val_rmse: 6.2943e-04 - val_mse: 3.9619e-07 - val_mae: 6.2924e-04 - 31ms/epoch - 2ms/step\n",
      "Epoch 60/5000\n",
      "\n",
      "Epoch 60: val_loss improved from 0.02514 to 0.00893, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-3.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0107 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0027 - val_loss: 0.0089 - val_rmse: 0.0023 - val_mse: 5.3976e-06 - val_mae: 0.0023 - 35ms/epoch - 2ms/step\n",
      "Epoch 61/5000\n",
      "15/15 - 0s - loss: 0.0098 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0021 - val_loss: 0.0081 - val_rmse: 0.0015 - val_mse: 2.2342e-06 - val_mae: 0.0015 - 31ms/epoch - 2ms/step\n",
      "Epoch 62/5000\n",
      "15/15 - 0s - loss: 0.0089 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0034 - val_loss: 0.0073 - val_rmse: 0.0017 - val_mse: 2.9668e-06 - val_mae: 0.0017 - 30ms/epoch - 2ms/step\n",
      "Epoch 63/5000\n",
      "15/15 - 0s - loss: 0.0082 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0024 - val_loss: 0.0065 - val_rmse: 4.8511e-04 - val_mse: 2.3533e-07 - val_mae: 4.8503e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 64/5000\n",
      "15/15 - 0s - loss: 0.0075 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0024 - val_loss: 0.0059 - val_rmse: 0.0014 - val_mse: 2.0925e-06 - val_mae: 0.0014 - 34ms/epoch - 2ms/step\n",
      "Epoch 65/5000\n",
      "15/15 - 0s - loss: 0.0069 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0019 - val_loss: 0.0053 - val_rmse: 0.0016 - val_mse: 2.6738e-06 - val_mae: 0.0016 - 37ms/epoch - 2ms/step\n",
      "Epoch 66/5000\n",
      "15/15 - 0s - loss: 0.0063 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0045 - val_loss: 0.0048 - val_rmse: 5.5970e-04 - val_mse: 3.1327e-07 - val_mae: 5.5968e-04 - 30ms/epoch - 2ms/step\n",
      "Epoch 67/5000\n",
      "15/15 - 0s - loss: 0.0058 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0027 - val_loss: 0.0043 - val_rmse: 0.0025 - val_mse: 6.3109e-06 - val_mae: 0.0025 - 40ms/epoch - 3ms/step\n",
      "Epoch 68/5000\n",
      "15/15 - 0s - loss: 0.0054 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0033 - val_loss: 0.0039 - val_rmse: 9.3090e-04 - val_mse: 8.6658e-07 - val_mae: 9.3090e-04 - 56ms/epoch - 4ms/step\n",
      "Epoch 69/5000\n",
      "15/15 - 0s - loss: 0.0050 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0021 - val_loss: 0.0035 - val_rmse: 0.0019 - val_mse: 3.5386e-06 - val_mae: 0.0019 - 39ms/epoch - 3ms/step\n",
      "Epoch 70/5000\n",
      "\n",
      "Epoch 70: val_loss improved from 0.00893 to 0.00317, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-3.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0046 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0028 - val_loss: 0.0032 - val_rmse: 0.0012 - val_mse: 1.4483e-06 - val_mae: 0.0012 - 59ms/epoch - 4ms/step\n",
      "Epoch 71/5000\n",
      "15/15 - 0s - loss: 0.0043 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0021 - val_loss: 0.0029 - val_rmse: 0.0018 - val_mse: 3.1188e-06 - val_mae: 0.0018 - 40ms/epoch - 3ms/step\n",
      "Epoch 72/5000\n",
      "15/15 - 0s - loss: 0.0040 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0020 - val_loss: 0.0026 - val_rmse: 8.1674e-04 - val_mse: 6.6706e-07 - val_mae: 8.1674e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 73/5000\n",
      "15/15 - 0s - loss: 0.0037 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0056 - val_loss: 0.0023 - val_rmse: 0.0025 - val_mse: 6.4922e-06 - val_mae: 0.0025 - 39ms/epoch - 3ms/step\n",
      "Epoch 74/5000\n",
      "15/15 - 0s - loss: 0.0034 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0025 - val_loss: 0.0021 - val_rmse: 0.0011 - val_mse: 1.2875e-06 - val_mae: 0.0011 - 39ms/epoch - 3ms/step\n",
      "Epoch 75/5000\n",
      "15/15 - 0s - loss: 0.0032 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0030 - val_loss: 0.0019 - val_rmse: 0.0018 - val_mse: 3.2905e-06 - val_mae: 0.0018 - 39ms/epoch - 3ms/step\n",
      "Epoch 76/5000\n",
      "15/15 - 0s - loss: 0.0030 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0021 - val_loss: 0.0017 - val_rmse: 0.0018 - val_mse: 3.2927e-06 - val_mae: 0.0018 - 40ms/epoch - 3ms/step\n",
      "Epoch 77/5000\n",
      "15/15 - 0s - loss: 0.0029 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0031 - val_loss: 0.0015 - val_rmse: 0.0016 - val_mse: 2.4170e-06 - val_mae: 0.0016 - 37ms/epoch - 2ms/step\n",
      "Epoch 78/5000\n",
      "15/15 - 0s - loss: 0.0027 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0027 - val_loss: 0.0014 - val_rmse: 2.3352e-04 - val_mse: 5.4532e-08 - val_mae: 2.3352e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 79/5000\n",
      "15/15 - 0s - loss: 0.0026 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0019 - val_loss: 0.0013 - val_rmse: 0.0020 - val_mse: 3.9508e-06 - val_mae: 0.0020 - 36ms/epoch - 2ms/step\n",
      "Epoch 80/5000\n",
      "\n",
      "Epoch 80: val_loss improved from 0.00317 to 0.00113, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-3.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0024 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0038 - val_loss: 0.0011 - val_rmse: 0.0019 - val_mse: 3.5517e-06 - val_mae: 0.0019 - 45ms/epoch - 3ms/step\n",
      "Epoch 81/5000\n",
      "15/15 - 0s - loss: 0.0023 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0021 - val_loss: 0.0010 - val_rmse: 0.0018 - val_mse: 3.2166e-06 - val_mae: 0.0018 - 38ms/epoch - 3ms/step\n",
      "Epoch 82/5000\n",
      "15/15 - 0s - loss: 0.0022 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0024 - val_loss: 9.1590e-04 - val_rmse: 0.0012 - val_mse: 1.3433e-06 - val_mae: 0.0012 - 44ms/epoch - 3ms/step\n",
      "Epoch 83/5000\n",
      "15/15 - 0s - loss: 0.0021 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0041 - val_loss: 8.2469e-04 - val_rmse: 3.3681e-04 - val_mse: 1.1344e-07 - val_mae: 3.3681e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 84/5000\n",
      "15/15 - 0s - loss: 0.0020 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0021 - val_loss: 7.4441e-04 - val_rmse: 9.7571e-04 - val_mse: 9.5201e-07 - val_mae: 9.7571e-04 - 52ms/epoch - 3ms/step\n",
      "Epoch 85/5000\n",
      "15/15 - 0s - loss: 0.0019 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0017 - val_loss: 6.7247e-04 - val_rmse: 0.0015 - val_mse: 2.1479e-06 - val_mae: 0.0015 - 44ms/epoch - 3ms/step\n",
      "Epoch 86/5000\n",
      "15/15 - 0s - loss: 0.0019 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0034 - val_loss: 6.0886e-04 - val_rmse: 0.0021 - val_mse: 4.4777e-06 - val_mae: 0.0021 - 72ms/epoch - 5ms/step\n",
      "Epoch 87/5000\n",
      "15/15 - 0s - loss: 0.0018 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0031 - val_loss: 5.4492e-04 - val_rmse: 6.2212e-05 - val_mse: 3.8703e-09 - val_mae: 6.2211e-05 - 64ms/epoch - 4ms/step\n",
      "Epoch 88/5000\n",
      "15/15 - 0s - loss: 0.0018 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0020 - val_loss: 4.9319e-04 - val_rmse: 0.0014 - val_mse: 1.8859e-06 - val_mae: 0.0014 - 50ms/epoch - 3ms/step\n",
      "Epoch 89/5000\n",
      "15/15 - 0s - loss: 0.0017 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0033 - val_loss: 4.4425e-04 - val_rmse: 0.0011 - val_mse: 1.2735e-06 - val_mae: 0.0011 - 42ms/epoch - 3ms/step\n",
      "Epoch 90/5000\n",
      "\n",
      "Epoch 90: val_loss improved from 0.00113 to 0.00040, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-3.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0017 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0055 - val_loss: 4.0130e-04 - val_rmse: 0.0014 - val_mse: 1.9072e-06 - val_mae: 0.0014 - 48ms/epoch - 3ms/step\n",
      "Epoch 91/5000\n",
      "15/15 - 0s - loss: 0.0016 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0018 - val_loss: 3.6042e-04 - val_rmse: 5.5602e-04 - val_mse: 3.0916e-07 - val_mae: 5.5602e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 92/5000\n",
      "15/15 - 0s - loss: 0.0016 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0018 - val_loss: 3.3007e-04 - val_rmse: 0.0023 - val_mse: 5.3836e-06 - val_mae: 0.0023 - 36ms/epoch - 2ms/step\n",
      "Epoch 93/5000\n",
      "15/15 - 0s - loss: 0.0015 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0034 - val_loss: 2.9454e-04 - val_rmse: 0.0013 - val_mse: 1.8037e-06 - val_mae: 0.0013 - 55ms/epoch - 4ms/step\n",
      "Epoch 94/5000\n",
      "15/15 - 0s - loss: 0.0015 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0026 - val_loss: 2.6396e-04 - val_rmse: 1.4264e-04 - val_mse: 2.0346e-08 - val_mae: 1.4264e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 95/5000\n",
      "15/15 - 0s - loss: 0.0015 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0023 - val_loss: 2.4359e-04 - val_rmse: 0.0024 - val_mse: 5.6118e-06 - val_mae: 0.0024 - 47ms/epoch - 3ms/step\n",
      "Epoch 96/5000\n",
      "15/15 - 0s - loss: 0.0015 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0035 - val_loss: 2.1546e-04 - val_rmse: 9.4851e-04 - val_mse: 8.9967e-07 - val_mae: 9.4851e-04 - 32ms/epoch - 2ms/step\n",
      "Epoch 97/5000\n",
      "15/15 - 0s - loss: 0.0014 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0027 - val_loss: 2.0083e-04 - val_rmse: 0.0027 - val_mse: 7.3704e-06 - val_mae: 0.0027 - 30ms/epoch - 2ms/step\n",
      "Epoch 98/5000\n",
      "15/15 - 0s - loss: 0.0014 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0027 - val_loss: 1.7621e-04 - val_rmse: 0.0013 - val_mse: 1.7872e-06 - val_mae: 0.0013 - 26ms/epoch - 2ms/step\n",
      "Epoch 99/5000\n",
      "15/15 - 0s - loss: 0.0014 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0026 - val_loss: 1.5933e-04 - val_rmse: 0.0014 - val_mse: 2.0620e-06 - val_mae: 0.0014 - 26ms/epoch - 2ms/step\n",
      "Epoch 100/5000\n",
      "\n",
      "Epoch 100: val_loss improved from 0.00040 to 0.00014, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-3.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0014 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0026 - val_loss: 1.4220e-04 - val_rmse: 6.3536e-04 - val_mse: 4.0369e-07 - val_mae: 6.3536e-04 - 33ms/epoch - 2ms/step\n",
      "Epoch 101/5000\n",
      "15/15 - 0s - loss: 0.0014 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0020 - val_loss: 1.3336e-04 - val_rmse: 0.0023 - val_mse: 5.5212e-06 - val_mae: 0.0023 - 33ms/epoch - 2ms/step\n",
      "Epoch 102/5000\n",
      "15/15 - 0s - loss: 0.0014 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0028 - val_loss: 1.1797e-04 - val_rmse: 0.0016 - val_mse: 2.7025e-06 - val_mae: 0.0016 - 30ms/epoch - 2ms/step\n",
      "Epoch 103/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0032 - val_loss: 1.0398e-04 - val_rmse: 2.3754e-04 - val_mse: 5.6427e-08 - val_mae: 2.3754e-04 - 32ms/epoch - 2ms/step\n",
      "Epoch 104/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0022 - val_loss: 9.9273e-05 - val_rmse: 0.0024 - val_mse: 5.5717e-06 - val_mae: 0.0024 - 25ms/epoch - 2ms/step\n",
      "Epoch 105/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0039 - val_loss: 8.7009e-05 - val_rmse: 0.0016 - val_mse: 2.5265e-06 - val_mae: 0.0016 - 29ms/epoch - 2ms/step\n",
      "Epoch 106/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0021 - val_loss: 7.6564e-05 - val_rmse: 6.2761e-04 - val_mse: 3.9389e-07 - val_mae: 6.2761e-04 - 31ms/epoch - 2ms/step\n",
      "Epoch 107/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0033 - val_loss: 7.3323e-05 - val_rmse: 0.0022 - val_mse: 4.6447e-06 - val_mae: 0.0022 - 38ms/epoch - 3ms/step\n",
      "Epoch 108/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0035 - val_loss: 6.1922e-05 - val_rmse: 5.0036e-05 - val_mse: 2.5036e-09 - val_mae: 5.0036e-05 - 34ms/epoch - 2ms/step\n",
      "Epoch 109/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0023 - val_loss: 6.2772e-05 - val_rmse: 0.0026 - val_mse: 6.9417e-06 - val_mae: 0.0026 - 34ms/epoch - 2ms/step\n",
      "Epoch 110/5000\n",
      "\n",
      "Epoch 110: val_loss improved from 0.00014 to 0.00005, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-3.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0032 - val_loss: 5.2323e-05 - val_rmse: 0.0014 - val_mse: 1.9860e-06 - val_mae: 0.0014 - 42ms/epoch - 3ms/step\n",
      "Epoch 111/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0028 - val_loss: 4.5447e-05 - val_rmse: 2.4802e-04 - val_mse: 6.1516e-08 - val_mae: 2.4802e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 112/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0023 - val_loss: 4.3305e-05 - val_rmse: 0.0015 - val_mse: 2.3847e-06 - val_mae: 0.0015 - 33ms/epoch - 2ms/step\n",
      "Epoch 113/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0030 - val_loss: 3.7248e-05 - val_rmse: 5.9514e-04 - val_mse: 3.5419e-07 - val_mae: 5.9514e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 114/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0024 - val_loss: 4.1691e-05 - val_rmse: 0.0029 - val_mse: 8.4257e-06 - val_mae: 0.0029 - 48ms/epoch - 3ms/step\n",
      "Epoch 115/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0043 - val_loss: 3.1269e-05 - val_rmse: 0.0011 - val_mse: 1.2779e-06 - val_mae: 0.0011 - 41ms/epoch - 3ms/step\n",
      "Epoch 116/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0028 - val_loss: 3.5974e-05 - val_rmse: 0.0030 - val_mse: 8.9317e-06 - val_mae: 0.0030 - 39ms/epoch - 3ms/step\n",
      "Epoch 117/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0040 - val_loss: 2.6070e-05 - val_rmse: 0.0013 - val_mse: 1.6880e-06 - val_mae: 0.0013 - 38ms/epoch - 3ms/step\n",
      "Epoch 118/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0020 - val_loss: 2.6140e-05 - val_rmse: 0.0020 - val_mse: 4.1567e-06 - val_mae: 0.0020 - 40ms/epoch - 3ms/step\n",
      "Epoch 119/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0025 - val_loss: 2.2625e-05 - val_rmse: 0.0017 - val_mse: 2.8041e-06 - val_mae: 0.0017 - 37ms/epoch - 2ms/step\n",
      "Epoch 120/5000\n",
      "\n",
      "Epoch 120: val_loss improved from 0.00005 to 0.00002, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-3.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0037 - val_loss: 1.7914e-05 - val_rmse: 2.1119e-04 - val_mse: 4.4602e-08 - val_mae: 2.1119e-04 - 51ms/epoch - 3ms/step\n",
      "Epoch 121/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0021 - val_loss: 1.6982e-05 - val_rmse: 9.3273e-04 - val_mse: 8.6999e-07 - val_mae: 9.3273e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 122/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0017 - val_loss: 1.8008e-05 - val_rmse: 0.0019 - val_mse: 3.4812e-06 - val_mae: 0.0019 - 40ms/epoch - 3ms/step\n",
      "Epoch 123/5000\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0034 - val_loss: 1.6761e-05 - val_rmse: 0.0019 - val_mse: 3.6626e-06 - val_mae: 0.0019 - 36ms/epoch - 2ms/step\n",
      "Epoch 124/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0020 - val_loss: 1.3823e-05 - val_rmse: 0.0014 - val_mse: 2.0128e-06 - val_mae: 0.0014 - 37ms/epoch - 2ms/step\n",
      "Epoch 125/5000\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0035 - val_loss: 1.4644e-05 - val_rmse: 0.0020 - val_mse: 3.9956e-06 - val_mae: 0.0020 - 36ms/epoch - 2ms/step\n",
      "Epoch 126/5000\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0026 - val_loss: 9.7366e-06 - val_rmse: 3.6902e-04 - val_mse: 1.3618e-07 - val_mae: 3.6902e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 127/5000\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0023 - val_loss: 1.2081e-05 - val_rmse: 0.0019 - val_mse: 3.4248e-06 - val_mae: 0.0019 - 39ms/epoch - 3ms/step\n",
      "Epoch 128/5000\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0023 - val_loss: 1.0702e-05 - val_rmse: 0.0017 - val_mse: 2.8968e-06 - val_mae: 0.0017 - 39ms/epoch - 3ms/step\n",
      "Epoch 129/5000\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0020 - val_loss: 7.4339e-06 - val_rmse: 6.2981e-04 - val_mse: 3.9666e-07 - val_mae: 6.2981e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 130/5000\n",
      "\n",
      "Epoch 130: val_loss improved from 0.00002 to 0.00001, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-3.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0033 - val_loss: 1.2612e-05 - val_rmse: 0.0025 - val_mse: 6.2671e-06 - val_mae: 0.0025 - 45ms/epoch - 3ms/step\n",
      "Epoch 131/5000\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0024 - val_loss: 7.7092e-06 - val_rmse: 0.0014 - val_mse: 1.9883e-06 - val_mae: 0.0014 - 38ms/epoch - 3ms/step\n",
      "Epoch 132/5000\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0018 - val_loss: 6.8032e-06 - val_rmse: 0.0013 - val_mse: 1.6452e-06 - val_mae: 0.0013 - 38ms/epoch - 3ms/step\n",
      "Epoch 133/5000\n",
      "Restoring model weights from the end of the best epoch: 113.\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0044 - val_loss: 4.6506e-06 - val_rmse: 2.1093e-05 - val_mse: 4.4493e-10 - val_mae: 2.1093e-05 - 40ms/epoch - 3ms/step\n",
      "Epoch 133: early stopping\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "INFO:tensorflow:Assets written to: data/output/fnn_compressed/activity-3_saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/output/fnn_compressed/activity-3_saved_model/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "65d36fbf51b645a3866475d5a15acc47"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>loss</td><td>â–ˆâ–‡â–…â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>mae</td><td>â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>mse</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>rmse</td><td>â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val_loss</td><td>â–ˆâ–‡â–…â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val_mae</td><td>â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val_mse</td><td>â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val_rmse</td><td>â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>132</td></tr><tr><td>best_val_loss</td><td>0.0</td></tr><tr><td>epoch</td><td>132</td></tr><tr><td>loss</td><td>0.00125</td></tr><tr><td>mae</td><td>0.0044</td></tr><tr><td>mse</td><td>0.00124</td></tr><tr><td>rmse</td><td>0.03524</td></tr><tr><td>val_loss</td><td>0.0</td></tr><tr><td>val_mae</td><td>2e-05</td></tr><tr><td>val_mse</td><td>0.0</td></tr><tr><td>val_rmse</td><td>2e-05</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">activity-3</strong> at: <a href='https://wandb.ai/dfpl_regression/FNN_0.5_random/runs/za82jdu1' target=\"_blank\">https://wandb.ai/dfpl_regression/FNN_0.5_random/runs/za82jdu1</a><br/> View project at: <a href='https://wandb.ai/dfpl_regression/FNN_0.5_random' target=\"_blank\">https://wandb.ai/dfpl_regression/FNN_0.5_random</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20240808_154310-za82jdu1/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011112667132531189, max=1.0â€¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "392f28a540254b559040f85517f47625"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.17.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/hertelj/git-hertelj/deepFPlearn/example/wandb/run-20240808_154327-bezufhoh</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dfpl_regression/FNN_0.5_random/runs/bezufhoh' target=\"_blank\">activity-4</a></strong> to <a href='https://wandb.ai/dfpl_regression/FNN_0.5_random' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/dfpl_regression/FNN_0.5_random' target=\"_blank\">https://wandb.ai/dfpl_regression/FNN_0.5_random</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/dfpl_regression/FNN_0.5_random/runs/bezufhoh' target=\"_blank\">https://wandb.ai/dfpl_regression/FNN_0.5_random/runs/bezufhoh</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hertelj/build/local/miniforge3/envs/dfpl/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "15/15 - 0s - loss: 4.4414 - rmse: 0.5960 - mse: 0.3553 - mae: 0.4650 - val_loss: 4.0380 - val_rmse: 0.3026 - val_mse: 0.0916 - val_mae: 0.2450 - 418ms/epoch - 28ms/step\n",
      "Epoch 2/5000\n",
      "15/15 - 0s - loss: 3.8428 - rmse: 0.2191 - mse: 0.0480 - mae: 0.1681 - val_loss: 3.6094 - val_rmse: 0.0855 - val_mse: 0.0073 - val_mae: 0.0663 - 40ms/epoch - 3ms/step\n",
      "Epoch 3/5000\n",
      "15/15 - 0s - loss: 3.4539 - rmse: 0.0946 - mse: 0.0090 - mae: 0.0701 - val_loss: 3.2596 - val_rmse: 0.0568 - val_mse: 0.0032 - val_mae: 0.0448 - 40ms/epoch - 3ms/step\n",
      "Epoch 4/5000\n",
      "15/15 - 0s - loss: 3.1142 - rmse: 0.0611 - mse: 0.0037 - mae: 0.0401 - val_loss: 2.9385 - val_rmse: 0.0337 - val_mse: 0.0011 - val_mae: 0.0264 - 39ms/epoch - 3ms/step\n",
      "Epoch 5/5000\n",
      "15/15 - 0s - loss: 2.8071 - rmse: 0.0451 - mse: 0.0020 - mae: 0.0243 - val_loss: 2.6490 - val_rmse: 0.0204 - val_mse: 4.1809e-04 - val_mae: 0.0159 - 31ms/epoch - 2ms/step\n",
      "Epoch 6/5000\n",
      "15/15 - 0s - loss: 2.5309 - rmse: 0.0420 - mse: 0.0018 - mae: 0.0181 - val_loss: 2.3882 - val_rmse: 0.0176 - val_mse: 3.0828e-04 - val_mae: 0.0142 - 40ms/epoch - 3ms/step\n",
      "Epoch 7/5000\n",
      "15/15 - 0s - loss: 2.2817 - rmse: 0.0383 - mse: 0.0015 - mae: 0.0143 - val_loss: 2.1531 - val_rmse: 0.0125 - val_mse: 1.5526e-04 - val_mae: 0.0101 - 38ms/epoch - 3ms/step\n",
      "Epoch 8/5000\n",
      "15/15 - 0s - loss: 2.0573 - rmse: 0.0384 - mse: 0.0015 - mae: 0.0140 - val_loss: 1.9412 - val_rmse: 0.0105 - val_mse: 1.1046e-04 - val_mae: 0.0086 - 34ms/epoch - 2ms/step\n",
      "Epoch 9/5000\n",
      "15/15 - 0s - loss: 1.8549 - rmse: 0.0370 - mse: 0.0014 - mae: 0.0109 - val_loss: 1.7502 - val_rmse: 0.0107 - val_mse: 1.1380e-04 - val_mae: 0.0087 - 37ms/epoch - 2ms/step\n",
      "Epoch 10/5000\n",
      "\n",
      "Epoch 10: val_loss improved from inf to 1.57791, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-4.model.weights.hdf5\n",
      "15/15 - 0s - loss: 1.6724 - rmse: 0.0360 - mse: 0.0013 - mae: 0.0093 - val_loss: 1.5779 - val_rmse: 0.0077 - val_mse: 5.9297e-05 - val_mae: 0.0063 - 46ms/epoch - 3ms/step\n",
      "Epoch 11/5000\n",
      "15/15 - 0s - loss: 1.5080 - rmse: 0.0356 - mse: 0.0013 - mae: 0.0080 - val_loss: 1.4227 - val_rmse: 0.0070 - val_mse: 4.8908e-05 - val_mae: 0.0057 - 40ms/epoch - 3ms/step\n",
      "Epoch 12/5000\n",
      "15/15 - 0s - loss: 1.3597 - rmse: 0.0356 - mse: 0.0013 - mae: 0.0072 - val_loss: 1.2827 - val_rmse: 0.0062 - val_mse: 3.7892e-05 - val_mae: 0.0050 - 42ms/epoch - 3ms/step\n",
      "Epoch 13/5000\n",
      "15/15 - 0s - loss: 1.2260 - rmse: 0.0350 - mse: 0.0012 - mae: 0.0065 - val_loss: 1.1565 - val_rmse: 0.0059 - val_mse: 3.4256e-05 - val_mae: 0.0048 - 39ms/epoch - 3ms/step\n",
      "Epoch 14/5000\n",
      "15/15 - 0s - loss: 1.1056 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0057 - val_loss: 1.0427 - val_rmse: 0.0054 - val_mse: 2.8662e-05 - val_mae: 0.0044 - 42ms/epoch - 3ms/step\n",
      "Epoch 15/5000\n",
      "15/15 - 0s - loss: 0.9969 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0055 - val_loss: 0.9401 - val_rmse: 0.0043 - val_mse: 1.8574e-05 - val_mae: 0.0035 - 39ms/epoch - 3ms/step\n",
      "Epoch 16/5000\n",
      "15/15 - 0s - loss: 0.8989 - rmse: 0.0350 - mse: 0.0012 - mae: 0.0050 - val_loss: 0.8476 - val_rmse: 0.0042 - val_mse: 1.7909e-05 - val_mae: 0.0035 - 37ms/epoch - 2ms/step\n",
      "Epoch 17/5000\n",
      "15/15 - 0s - loss: 0.8106 - rmse: 0.0350 - mse: 0.0012 - mae: 0.0048 - val_loss: 0.7642 - val_rmse: 0.0042 - val_mse: 1.7534e-05 - val_mae: 0.0035 - 42ms/epoch - 3ms/step\n",
      "Epoch 18/5000\n",
      "15/15 - 0s - loss: 0.7310 - rmse: 0.0348 - mse: 0.0012 - mae: 0.0047 - val_loss: 0.6890 - val_rmse: 0.0035 - val_mse: 1.2212e-05 - val_mae: 0.0029 - 42ms/epoch - 3ms/step\n",
      "Epoch 19/5000\n",
      "15/15 - 0s - loss: 0.6592 - rmse: 0.0349 - mse: 0.0012 - mae: 0.0041 - val_loss: 0.6213 - val_rmse: 0.0037 - val_mse: 1.3672e-05 - val_mae: 0.0031 - 40ms/epoch - 3ms/step\n",
      "Epoch 20/5000\n",
      "\n",
      "Epoch 20: val_loss improved from 1.57791 to 0.56014, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-4.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.5945 - rmse: 0.0350 - mse: 0.0012 - mae: 0.0044 - val_loss: 0.5601 - val_rmse: 0.0033 - val_mse: 1.0702e-05 - val_mae: 0.0027 - 46ms/epoch - 3ms/step\n",
      "Epoch 21/5000\n",
      "15/15 - 0s - loss: 0.5361 - rmse: 0.0350 - mse: 0.0012 - mae: 0.0036 - val_loss: 0.5050 - val_rmse: 0.0030 - val_mse: 8.7047e-06 - val_mae: 0.0025 - 35ms/epoch - 2ms/step\n",
      "Epoch 22/5000\n",
      "15/15 - 0s - loss: 0.4835 - rmse: 0.0349 - mse: 0.0012 - mae: 0.0045 - val_loss: 0.4553 - val_rmse: 0.0023 - val_mse: 5.4084e-06 - val_mae: 0.0019 - 36ms/epoch - 2ms/step\n",
      "Epoch 23/5000\n",
      "15/15 - 0s - loss: 0.4360 - rmse: 0.0349 - mse: 0.0012 - mae: 0.0033 - val_loss: 0.4106 - val_rmse: 0.0028 - val_mse: 8.0512e-06 - val_mae: 0.0024 - 48ms/epoch - 3ms/step\n",
      "Epoch 24/5000\n",
      "15/15 - 0s - loss: 0.3933 - rmse: 0.0348 - mse: 0.0012 - mae: 0.0037 - val_loss: 0.3702 - val_rmse: 0.0020 - val_mse: 3.8175e-06 - val_mae: 0.0016 - 35ms/epoch - 2ms/step\n",
      "Epoch 25/5000\n",
      "15/15 - 0s - loss: 0.3547 - rmse: 0.0349 - mse: 0.0012 - mae: 0.0029 - val_loss: 0.3337 - val_rmse: 0.0022 - val_mse: 4.8859e-06 - val_mae: 0.0018 - 40ms/epoch - 3ms/step\n",
      "Epoch 26/5000\n",
      "15/15 - 0s - loss: 0.3199 - rmse: 0.0349 - mse: 0.0012 - mae: 0.0041 - val_loss: 0.3009 - val_rmse: 0.0025 - val_mse: 6.3398e-06 - val_mae: 0.0022 - 39ms/epoch - 3ms/step\n",
      "Epoch 27/5000\n",
      "15/15 - 0s - loss: 0.2886 - rmse: 0.0349 - mse: 0.0012 - mae: 0.0028 - val_loss: 0.2713 - val_rmse: 0.0015 - val_mse: 2.3682e-06 - val_mae: 0.0013 - 49ms/epoch - 3ms/step\n",
      "Epoch 28/5000\n",
      "15/15 - 0s - loss: 0.2603 - rmse: 0.0350 - mse: 0.0012 - mae: 0.0027 - val_loss: 0.2446 - val_rmse: 0.0026 - val_mse: 6.7274e-06 - val_mae: 0.0023 - 43ms/epoch - 3ms/step\n",
      "Epoch 29/5000\n",
      "15/15 - 0s - loss: 0.2348 - rmse: 0.0350 - mse: 0.0012 - mae: 0.0027 - val_loss: 0.2206 - val_rmse: 0.0017 - val_mse: 2.8508e-06 - val_mae: 0.0014 - 43ms/epoch - 3ms/step\n",
      "Epoch 30/5000\n",
      "\n",
      "Epoch 30: val_loss improved from 0.56014 to 0.19886, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-4.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.2118 - rmse: 0.0350 - mse: 0.0012 - mae: 0.0026 - val_loss: 0.1989 - val_rmse: 0.0013 - val_mse: 1.6091e-06 - val_mae: 0.0011 - 50ms/epoch - 3ms/step\n",
      "Epoch 31/5000\n",
      "15/15 - 0s - loss: 0.1911 - rmse: 0.0350 - mse: 0.0012 - mae: 0.0037 - val_loss: 0.1793 - val_rmse: 0.0021 - val_mse: 4.4522e-06 - val_mae: 0.0019 - 33ms/epoch - 2ms/step\n",
      "Epoch 32/5000\n",
      "15/15 - 0s - loss: 0.1724 - rmse: 0.0350 - mse: 0.0012 - mae: 0.0026 - val_loss: 0.1617 - val_rmse: 8.2978e-04 - val_mse: 6.8854e-07 - val_mae: 6.4647e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 33/5000\n",
      "15/15 - 0s - loss: 0.1556 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0026 - val_loss: 0.1458 - val_rmse: 0.0016 - val_mse: 2.6931e-06 - val_mae: 0.0015 - 36ms/epoch - 2ms/step\n",
      "Epoch 34/5000\n",
      "15/15 - 0s - loss: 0.1404 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0029 - val_loss: 0.1314 - val_rmse: 7.7591e-04 - val_mse: 6.0203e-07 - val_mae: 6.2255e-04 - 25ms/epoch - 2ms/step\n",
      "Epoch 35/5000\n",
      "15/15 - 0s - loss: 0.1267 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0023 - val_loss: 0.1185 - val_rmse: 0.0027 - val_mse: 7.5541e-06 - val_mae: 0.0027 - 28ms/epoch - 2ms/step\n",
      "Epoch 36/5000\n",
      "15/15 - 0s - loss: 0.1144 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0031 - val_loss: 0.1068 - val_rmse: 0.0016 - val_mse: 2.4210e-06 - val_mae: 0.0015 - 29ms/epoch - 2ms/step\n",
      "Epoch 37/5000\n",
      "15/15 - 0s - loss: 0.1033 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0022 - val_loss: 0.0963 - val_rmse: 0.0019 - val_mse: 3.7193e-06 - val_mae: 0.0019 - 37ms/epoch - 2ms/step\n",
      "Epoch 38/5000\n",
      "15/15 - 0s - loss: 0.0932 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0034 - val_loss: 0.0869 - val_rmse: 0.0010 - val_mse: 1.0908e-06 - val_mae: 9.9081e-04 - 47ms/epoch - 3ms/step\n",
      "Epoch 39/5000\n",
      "15/15 - 0s - loss: 0.0842 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0024 - val_loss: 0.0783 - val_rmse: 4.1822e-04 - val_mse: 1.7490e-07 - val_mae: 3.4113e-04 - 31ms/epoch - 2ms/step\n",
      "Epoch 40/5000\n",
      "\n",
      "Epoch 40: val_loss improved from 0.19886 to 0.07061, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-4.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0760 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0024 - val_loss: 0.0706 - val_rmse: 0.0024 - val_mse: 5.7416e-06 - val_mae: 0.0024 - 42ms/epoch - 3ms/step\n",
      "Epoch 41/5000\n",
      "15/15 - 0s - loss: 0.0687 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0023 - val_loss: 0.0637 - val_rmse: 3.3590e-04 - val_mse: 1.1283e-07 - val_mae: 2.8362e-04 - 29ms/epoch - 2ms/step\n",
      "Epoch 42/5000\n",
      "15/15 - 0s - loss: 0.0620 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0041 - val_loss: 0.0574 - val_rmse: 0.0015 - val_mse: 2.3063e-06 - val_mae: 0.0015 - 30ms/epoch - 2ms/step\n",
      "Epoch 43/5000\n",
      "15/15 - 0s - loss: 0.0560 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0025 - val_loss: 0.0517 - val_rmse: 4.3777e-04 - val_mse: 1.9164e-07 - val_mae: 4.0721e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 44/5000\n",
      "15/15 - 0s - loss: 0.0507 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0048 - val_loss: 0.0467 - val_rmse: 0.0012 - val_mse: 1.3948e-06 - val_mae: 0.0012 - 34ms/epoch - 2ms/step\n",
      "Epoch 45/5000\n",
      "15/15 - 0s - loss: 0.0458 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0027 - val_loss: 0.0421 - val_rmse: 0.0014 - val_mse: 1.9209e-06 - val_mae: 0.0014 - 28ms/epoch - 2ms/step\n",
      "Epoch 46/5000\n",
      "15/15 - 0s - loss: 0.0414 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0045 - val_loss: 0.0379 - val_rmse: 0.0014 - val_mse: 2.0187e-06 - val_mae: 0.0014 - 31ms/epoch - 2ms/step\n",
      "Epoch 47/5000\n",
      "15/15 - 0s - loss: 0.0375 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0020 - val_loss: 0.0342 - val_rmse: 0.0012 - val_mse: 1.4038e-06 - val_mae: 0.0012 - 26ms/epoch - 2ms/step\n",
      "Epoch 48/5000\n",
      "15/15 - 0s - loss: 0.0339 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0018 - val_loss: 0.0308 - val_rmse: 8.1683e-04 - val_mse: 6.6721e-07 - val_mae: 8.1304e-04 - 31ms/epoch - 2ms/step\n",
      "Epoch 49/5000\n",
      "15/15 - 0s - loss: 0.0307 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0032 - val_loss: 0.0278 - val_rmse: 0.0024 - val_mse: 5.8952e-06 - val_mae: 0.0024 - 52ms/epoch - 3ms/step\n",
      "Epoch 50/5000\n",
      "\n",
      "Epoch 50: val_loss improved from 0.07061 to 0.02507, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-4.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0278 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0029 - val_loss: 0.0251 - val_rmse: 6.3339e-04 - val_mse: 4.0118e-07 - val_mae: 6.3067e-04 - 46ms/epoch - 3ms/step\n",
      "Epoch 51/5000\n",
      "15/15 - 0s - loss: 0.0252 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0020 - val_loss: 0.0226 - val_rmse: 0.0021 - val_mse: 4.4628e-06 - val_mae: 0.0021 - 40ms/epoch - 3ms/step\n",
      "Epoch 52/5000\n",
      "15/15 - 0s - loss: 0.0228 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0033 - val_loss: 0.0204 - val_rmse: 8.4218e-04 - val_mse: 7.0927e-07 - val_mae: 8.4105e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 53/5000\n",
      "15/15 - 0s - loss: 0.0207 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0021 - val_loss: 0.0184 - val_rmse: 0.0016 - val_mse: 2.4185e-06 - val_mae: 0.0016 - 35ms/epoch - 2ms/step\n",
      "Epoch 54/5000\n",
      "15/15 - 0s - loss: 0.0188 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0023 - val_loss: 0.0166 - val_rmse: 0.0018 - val_mse: 3.1336e-06 - val_mae: 0.0018 - 33ms/epoch - 2ms/step\n",
      "Epoch 55/5000\n",
      "15/15 - 0s - loss: 0.0171 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0028 - val_loss: 0.0149 - val_rmse: 0.0013 - val_mse: 1.5920e-06 - val_mae: 0.0013 - 48ms/epoch - 3ms/step\n",
      "Epoch 56/5000\n",
      "15/15 - 0s - loss: 0.0155 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0023 - val_loss: 0.0135 - val_rmse: 0.0014 - val_mse: 2.0031e-06 - val_mae: 0.0014 - 46ms/epoch - 3ms/step\n",
      "Epoch 57/5000\n",
      "15/15 - 0s - loss: 0.0141 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0029 - val_loss: 0.0121 - val_rmse: 3.5441e-04 - val_mse: 1.2560e-07 - val_mae: 3.5380e-04 - 26ms/epoch - 2ms/step\n",
      "Epoch 58/5000\n",
      "15/15 - 0s - loss: 0.0128 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0019 - val_loss: 0.0110 - val_rmse: 0.0022 - val_mse: 4.6344e-06 - val_mae: 0.0022 - 31ms/epoch - 2ms/step\n",
      "Epoch 59/5000\n",
      "15/15 - 0s - loss: 0.0117 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0039 - val_loss: 0.0099 - val_rmse: 0.0013 - val_mse: 1.6200e-06 - val_mae: 0.0013 - 31ms/epoch - 2ms/step\n",
      "Epoch 60/5000\n",
      "\n",
      "Epoch 60: val_loss improved from 0.02507 to 0.00890, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-4.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0107 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0022 - val_loss: 0.0089 - val_rmse: 0.0011 - val_mse: 1.1559e-06 - val_mae: 0.0011 - 40ms/epoch - 3ms/step\n",
      "Epoch 61/5000\n",
      "15/15 - 0s - loss: 0.0097 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0031 - val_loss: 0.0080 - val_rmse: 0.0013 - val_mse: 1.7387e-06 - val_mae: 0.0013 - 47ms/epoch - 3ms/step\n",
      "Epoch 62/5000\n",
      "15/15 - 0s - loss: 0.0089 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0057 - val_loss: 0.0072 - val_rmse: 0.0013 - val_mse: 1.6591e-06 - val_mae: 0.0013 - 34ms/epoch - 2ms/step\n",
      "Epoch 63/5000\n",
      "15/15 - 0s - loss: 0.0081 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0018 - val_loss: 0.0065 - val_rmse: 6.0997e-04 - val_mse: 3.7207e-07 - val_mae: 6.0992e-04 - 33ms/epoch - 2ms/step\n",
      "Epoch 64/5000\n",
      "15/15 - 0s - loss: 0.0075 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0029 - val_loss: 0.0059 - val_rmse: 0.0017 - val_mse: 2.8251e-06 - val_mae: 0.0017 - 37ms/epoch - 2ms/step\n",
      "Epoch 65/5000\n",
      "15/15 - 0s - loss: 0.0069 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0024 - val_loss: 0.0053 - val_rmse: 5.3775e-04 - val_mse: 2.8918e-07 - val_mae: 5.3772e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 66/5000\n",
      "15/15 - 0s - loss: 0.0063 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0021 - val_loss: 0.0048 - val_rmse: 0.0020 - val_mse: 3.9633e-06 - val_mae: 0.0020 - 33ms/epoch - 2ms/step\n",
      "Epoch 67/5000\n",
      "15/15 - 0s - loss: 0.0058 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0021 - val_loss: 0.0043 - val_rmse: 0.0013 - val_mse: 1.6442e-06 - val_mae: 0.0013 - 43ms/epoch - 3ms/step\n",
      "Epoch 68/5000\n",
      "15/15 - 0s - loss: 0.0054 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0036 - val_loss: 0.0039 - val_rmse: 0.0016 - val_mse: 2.7191e-06 - val_mae: 0.0016 - 36ms/epoch - 2ms/step\n",
      "Epoch 69/5000\n",
      "15/15 - 0s - loss: 0.0049 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0020 - val_loss: 0.0035 - val_rmse: 0.0017 - val_mse: 2.8420e-06 - val_mae: 0.0017 - 62ms/epoch - 4ms/step\n",
      "Epoch 70/5000\n",
      "\n",
      "Epoch 70: val_loss improved from 0.00890 to 0.00316, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-4.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0046 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0035 - val_loss: 0.0032 - val_rmse: 0.0011 - val_mse: 1.1932e-06 - val_mae: 0.0011 - 65ms/epoch - 4ms/step\n",
      "Epoch 71/5000\n",
      "15/15 - 0s - loss: 0.0043 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0023 - val_loss: 0.0028 - val_rmse: 2.8719e-05 - val_mse: 8.2476e-10 - val_mae: 2.8612e-05 - 49ms/epoch - 3ms/step\n",
      "Epoch 72/5000\n",
      "15/15 - 0s - loss: 0.0040 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0025 - val_loss: 0.0026 - val_rmse: 5.7593e-04 - val_mse: 3.3170e-07 - val_mae: 5.7593e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 73/5000\n",
      "15/15 - 0s - loss: 0.0037 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0024 - val_loss: 0.0023 - val_rmse: 6.7596e-04 - val_mse: 4.5692e-07 - val_mae: 6.7596e-04 - 55ms/epoch - 4ms/step\n",
      "Epoch 74/5000\n",
      "15/15 - 0s - loss: 0.0034 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0018 - val_loss: 0.0021 - val_rmse: 0.0011 - val_mse: 1.2804e-06 - val_mae: 0.0011 - 56ms/epoch - 4ms/step\n",
      "Epoch 75/5000\n",
      "15/15 - 0s - loss: 0.0032 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0056 - val_loss: 0.0019 - val_rmse: 0.0027 - val_mse: 7.3000e-06 - val_mae: 0.0027 - 50ms/epoch - 3ms/step\n",
      "Epoch 76/5000\n",
      "15/15 - 0s - loss: 0.0030 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0024 - val_loss: 0.0017 - val_rmse: 0.0011 - val_mse: 1.2926e-06 - val_mae: 0.0011 - 54ms/epoch - 4ms/step\n",
      "Epoch 77/5000\n",
      "15/15 - 0s - loss: 0.0029 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0029 - val_loss: 0.0015 - val_rmse: 0.0022 - val_mse: 4.8988e-06 - val_mae: 0.0022 - 45ms/epoch - 3ms/step\n",
      "Epoch 78/5000\n",
      "15/15 - 0s - loss: 0.0027 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0022 - val_loss: 0.0014 - val_rmse: 8.2180e-04 - val_mse: 6.7536e-07 - val_mae: 8.2180e-04 - 54ms/epoch - 4ms/step\n",
      "Epoch 79/5000\n",
      "15/15 - 0s - loss: 0.0026 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0030 - val_loss: 0.0012 - val_rmse: 0.0024 - val_mse: 5.7304e-06 - val_mae: 0.0024 - 40ms/epoch - 3ms/step\n",
      "Epoch 80/5000\n",
      "\n",
      "Epoch 80: val_loss improved from 0.00316 to 0.00112, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-4.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0024 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0033 - val_loss: 0.0011 - val_rmse: 4.2067e-05 - val_mse: 1.7697e-09 - val_mae: 4.2063e-05 - 47ms/epoch - 3ms/step\n",
      "Epoch 81/5000\n",
      "15/15 - 0s - loss: 0.0023 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0022 - val_loss: 0.0010 - val_rmse: 0.0013 - val_mse: 1.6436e-06 - val_mae: 0.0013 - 41ms/epoch - 3ms/step\n",
      "Epoch 82/5000\n",
      "15/15 - 0s - loss: 0.0022 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0018 - val_loss: 9.1320e-04 - val_rmse: 0.0012 - val_mse: 1.3927e-06 - val_mae: 0.0012 - 36ms/epoch - 2ms/step\n",
      "Epoch 83/5000\n",
      "15/15 - 0s - loss: 0.0021 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0045 - val_loss: 8.2210e-04 - val_rmse: 1.1395e-05 - val_mse: 1.2985e-10 - val_mae: 1.1388e-05 - 79ms/epoch - 5ms/step\n",
      "Epoch 84/5000\n",
      "15/15 - 0s - loss: 0.0020 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0025 - val_loss: 7.4621e-04 - val_rmse: 0.0022 - val_mse: 4.9789e-06 - val_mae: 0.0022 - 42ms/epoch - 3ms/step\n",
      "Epoch 85/5000\n",
      "15/15 - 0s - loss: 0.0019 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0025 - val_loss: 6.6915e-04 - val_rmse: 9.1952e-04 - val_mse: 8.4552e-07 - val_mae: 9.1952e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 86/5000\n",
      "15/15 - 0s - loss: 0.0019 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0030 - val_loss: 6.0794e-04 - val_rmse: 0.0023 - val_mse: 5.3740e-06 - val_mae: 0.0023 - 45ms/epoch - 3ms/step\n",
      "Epoch 87/5000\n",
      "15/15 - 0s - loss: 0.0018 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0022 - val_loss: 5.4550e-04 - val_rmse: 0.0015 - val_mse: 2.2139e-06 - val_mae: 0.0015 - 45ms/epoch - 3ms/step\n",
      "Epoch 88/5000\n",
      "15/15 - 0s - loss: 0.0018 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0027 - val_loss: 4.9381e-04 - val_rmse: 0.0020 - val_mse: 3.9787e-06 - val_mae: 0.0020 - 43ms/epoch - 3ms/step\n",
      "Epoch 89/5000\n",
      "15/15 - 0s - loss: 0.0017 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0034 - val_loss: 4.4199e-04 - val_rmse: 5.9118e-04 - val_mse: 3.4949e-07 - val_mae: 5.9118e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 90/5000\n",
      "\n",
      "Epoch 90: val_loss improved from 0.00112 to 0.00040, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-4.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0017 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0023 - val_loss: 4.0468e-04 - val_rmse: 0.0025 - val_mse: 6.4829e-06 - val_mae: 0.0025 - 43ms/epoch - 3ms/step\n",
      "Epoch 91/5000\n",
      "15/15 - 0s - loss: 0.0016 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0030 - val_loss: 3.5936e-04 - val_rmse: 5.8066e-04 - val_mse: 3.3717e-07 - val_mae: 5.8066e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 92/5000\n",
      "15/15 - 0s - loss: 0.0016 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0049 - val_loss: 3.3168e-04 - val_rmse: 0.0028 - val_mse: 7.9785e-06 - val_mae: 0.0028 - 34ms/epoch - 2ms/step\n",
      "Epoch 93/5000\n",
      "15/15 - 0s - loss: 0.0016 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0027 - val_loss: 2.9188e-04 - val_rmse: 1.4225e-04 - val_mse: 2.0236e-08 - val_mae: 1.4225e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 94/5000\n",
      "15/15 - 0s - loss: 0.0015 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0035 - val_loss: 2.7182e-04 - val_rmse: 0.0029 - val_mse: 8.6731e-06 - val_mae: 0.0029 - 40ms/epoch - 3ms/step\n",
      "Epoch 95/5000\n",
      "15/15 - 0s - loss: 0.0015 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0024 - val_loss: 2.3849e-04 - val_rmse: 0.0011 - val_mse: 1.2367e-06 - val_mae: 0.0011 - 41ms/epoch - 3ms/step\n",
      "Epoch 96/5000\n",
      "15/15 - 0s - loss: 0.0015 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0020 - val_loss: 2.1819e-04 - val_rmse: 0.0021 - val_mse: 4.2736e-06 - val_mae: 0.0021 - 39ms/epoch - 3ms/step\n",
      "Epoch 97/5000\n",
      "15/15 - 0s - loss: 0.0014 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0028 - val_loss: 1.9585e-04 - val_rmse: 0.0017 - val_mse: 2.9790e-06 - val_mae: 0.0017 - 36ms/epoch - 2ms/step\n",
      "Epoch 98/5000\n",
      "15/15 - 0s - loss: 0.0014 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0020 - val_loss: 1.7418e-04 - val_rmse: 5.3381e-04 - val_mse: 2.8495e-07 - val_mae: 5.3381e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 99/5000\n",
      "15/15 - 0s - loss: 0.0014 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0039 - val_loss: 1.6106e-04 - val_rmse: 0.0021 - val_mse: 4.2711e-06 - val_mae: 0.0021 - 36ms/epoch - 2ms/step\n",
      "Epoch 100/5000\n",
      "\n",
      "Epoch 100: val_loss improved from 0.00040 to 0.00014, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-4.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0014 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0023 - val_loss: 1.4251e-04 - val_rmse: 0.0011 - val_mse: 1.1461e-06 - val_mae: 0.0011 - 43ms/epoch - 3ms/step\n",
      "Epoch 101/5000\n",
      "15/15 - 0s - loss: 0.0014 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0043 - val_loss: 1.2883e-04 - val_rmse: 0.0012 - val_mse: 1.3720e-06 - val_mae: 0.0012 - 48ms/epoch - 3ms/step\n",
      "Epoch 102/5000\n",
      "15/15 - 0s - loss: 0.0014 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0021 - val_loss: 1.1791e-04 - val_rmse: 0.0017 - val_mse: 2.9880e-06 - val_mae: 0.0017 - 47ms/epoch - 3ms/step\n",
      "Epoch 103/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0023 - val_loss: 1.0489e-04 - val_rmse: 0.0011 - val_mse: 1.2756e-06 - val_mae: 0.0011 - 31ms/epoch - 2ms/step\n",
      "Epoch 104/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0026 - val_loss: 9.6805e-05 - val_rmse: 0.0018 - val_mse: 3.3861e-06 - val_mae: 0.0018 - 44ms/epoch - 3ms/step\n",
      "Epoch 105/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0038 - val_loss: 8.4230e-05 - val_rmse: 5.8927e-05 - val_mse: 3.4724e-09 - val_mae: 5.8927e-05 - 52ms/epoch - 3ms/step\n",
      "Epoch 106/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0023 - val_loss: 7.9993e-05 - val_rmse: 0.0020 - val_mse: 4.0523e-06 - val_mae: 0.0020 - 56ms/epoch - 4ms/step\n",
      "Epoch 107/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0032 - val_loss: 6.8924e-05 - val_rmse: 6.7430e-04 - val_mse: 4.5468e-07 - val_mae: 6.7430e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 108/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0034 - val_loss: 6.4214e-05 - val_rmse: 0.0016 - val_mse: 2.4807e-06 - val_mae: 0.0016 - 31ms/epoch - 2ms/step\n",
      "Epoch 109/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0021 - val_loss: 5.8118e-05 - val_rmse: 0.0016 - val_mse: 2.4578e-06 - val_mae: 0.0016 - 34ms/epoch - 2ms/step\n",
      "Epoch 110/5000\n",
      "\n",
      "Epoch 110: val_loss improved from 0.00014 to 0.00005, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-4.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0038 - val_loss: 5.2582e-05 - val_rmse: 0.0015 - val_mse: 2.3976e-06 - val_mae: 0.0015 - 37ms/epoch - 2ms/step\n",
      "Epoch 111/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0020 - val_loss: 4.6043e-05 - val_rmse: 8.9230e-04 - val_mse: 7.9620e-07 - val_mae: 8.9230e-04 - 33ms/epoch - 2ms/step\n",
      "Epoch 112/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0029 - val_loss: 4.0852e-05 - val_rmse: 2.3656e-04 - val_mse: 5.5959e-08 - val_mae: 2.3656e-04 - 31ms/epoch - 2ms/step\n",
      "Epoch 113/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0021 - val_loss: 4.2258e-05 - val_rmse: 0.0023 - val_mse: 5.4755e-06 - val_mae: 0.0023 - 33ms/epoch - 2ms/step\n",
      "Epoch 114/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0035 - val_loss: 3.4393e-05 - val_rmse: 0.0011 - val_mse: 1.2295e-06 - val_mae: 0.0011 - 40ms/epoch - 3ms/step\n",
      "Epoch 115/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0024 - val_loss: 2.9903e-05 - val_rmse: 4.3698e-05 - val_mse: 1.9095e-09 - val_mae: 4.3698e-05 - 60ms/epoch - 4ms/step\n",
      "Epoch 116/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0023 - val_loss: 2.9665e-05 - val_rmse: 0.0016 - val_mse: 2.7048e-06 - val_mae: 0.0016 - 53ms/epoch - 4ms/step\n",
      "Epoch 117/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0027 - val_loss: 2.4682e-05 - val_rmse: 6.1198e-04 - val_mse: 3.7452e-07 - val_mae: 6.1198e-04 - 57ms/epoch - 4ms/step\n",
      "Epoch 118/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0025 - val_loss: 2.2003e-05 - val_rmse: 2.9352e-04 - val_mse: 8.6156e-08 - val_mae: 2.9352e-04 - 35ms/epoch - 2ms/step\n",
      "Epoch 119/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0018 - val_loss: 2.0937e-05 - val_rmse: 0.0011 - val_mse: 1.1768e-06 - val_mae: 0.0011 - 36ms/epoch - 2ms/step\n",
      "Epoch 120/5000\n",
      "\n",
      "Epoch 120: val_loss improved from 0.00005 to 0.00002, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-4.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0033 - val_loss: 2.1784e-05 - val_rmse: 0.0020 - val_mse: 3.9672e-06 - val_mae: 0.0020 - 36ms/epoch - 2ms/step\n",
      "Epoch 121/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0021 - val_loss: 1.6971e-05 - val_rmse: 9.5256e-04 - val_mse: 9.0737e-07 - val_mae: 9.5256e-04 - 33ms/epoch - 2ms/step\n",
      "Epoch 122/5000\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0030 - val_loss: 1.9879e-05 - val_rmse: 0.0023 - val_mse: 5.3959e-06 - val_mae: 0.0023 - 33ms/epoch - 2ms/step\n",
      "Epoch 123/5000\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0026 - val_loss: 1.5141e-05 - val_rmse: 0.0014 - val_mse: 2.0830e-06 - val_mae: 0.0014 - 34ms/epoch - 2ms/step\n",
      "Epoch 124/5000\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0027 - val_loss: 1.3731e-05 - val_rmse: 0.0014 - val_mse: 1.9576e-06 - val_mae: 0.0014 - 34ms/epoch - 2ms/step\n",
      "Epoch 125/5000\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0023 - val_loss: 1.2461e-05 - val_rmse: 0.0014 - val_mse: 1.8457e-06 - val_mae: 0.0014 - 35ms/epoch - 2ms/step\n",
      "Epoch 126/5000\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0025 - val_loss: 1.1542e-05 - val_rmse: 0.0014 - val_mse: 1.9709e-06 - val_mae: 0.0014 - 51ms/epoch - 3ms/step\n",
      "Epoch 127/5000\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0025 - val_loss: 9.7637e-06 - val_rmse: 0.0011 - val_mse: 1.1339e-06 - val_mae: 0.0011 - 43ms/epoch - 3ms/step\n",
      "Epoch 128/5000\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0027 - val_loss: 7.8421e-06 - val_rmse: 2.4749e-04 - val_mse: 6.1253e-08 - val_mae: 2.4749e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 129/5000\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0024 - val_loss: 1.1257e-05 - val_rmse: 0.0021 - val_mse: 4.2412e-06 - val_mae: 0.0021 - 68ms/epoch - 5ms/step\n",
      "Epoch 130/5000\n",
      "\n",
      "Epoch 130: val_loss improved from 0.00002 to 0.00001, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-4.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0021 - val_loss: 7.8597e-06 - val_rmse: 0.0012 - val_mse: 1.5343e-06 - val_mae: 0.0012 - 48ms/epoch - 3ms/step\n",
      "Epoch 131/5000\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0036 - val_loss: 8.5137e-06 - val_rmse: 0.0017 - val_mse: 2.8105e-06 - val_mae: 0.0017 - 42ms/epoch - 3ms/step\n",
      "Epoch 132/5000\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0020 - val_loss: 7.9257e-06 - val_rmse: 0.0017 - val_mse: 2.7836e-06 - val_mae: 0.0017 - 67ms/epoch - 4ms/step\n",
      "Epoch 133/5000\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0030 - val_loss: 8.0203e-06 - val_rmse: 0.0018 - val_mse: 3.3841e-06 - val_mae: 0.0018 - 41ms/epoch - 3ms/step\n",
      "Epoch 134/5000\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0025 - val_loss: 5.5725e-06 - val_rmse: 0.0012 - val_mse: 1.3924e-06 - val_mae: 0.0012 - 46ms/epoch - 3ms/step\n",
      "Epoch 135/5000\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0019 - val_loss: 7.6624e-06 - val_rmse: 0.0020 - val_mse: 3.8935e-06 - val_mae: 0.0020 - 43ms/epoch - 3ms/step\n",
      "Epoch 136/5000\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0037 - val_loss: 3.7917e-06 - val_rmse: 6.2739e-04 - val_mse: 3.9362e-07 - val_mae: 6.2739e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 137/5000\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0020 - val_loss: 4.7380e-06 - val_rmse: 0.0013 - val_mse: 1.6742e-06 - val_mae: 0.0013 - 76ms/epoch - 5ms/step\n",
      "Epoch 138/5000\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0018 - val_loss: 5.2549e-06 - val_rmse: 0.0016 - val_mse: 2.4924e-06 - val_mae: 0.0016 - 60ms/epoch - 4ms/step\n",
      "Epoch 139/5000\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0042 - val_loss: 2.5107e-06 - val_rmse: 1.4060e-04 - val_mse: 1.9768e-08 - val_mae: 1.4060e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 140/5000\n",
      "\n",
      "Epoch 140: val_loss improved from 0.00001 to 0.00001, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-4.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0023 - val_loss: 6.3200e-06 - val_rmse: 0.0020 - val_mse: 4.0741e-06 - val_mae: 0.0020 - 45ms/epoch - 3ms/step\n",
      "Epoch 141/5000\n",
      "Restoring model weights from the end of the best epoch: 121.\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0029 - val_loss: 4.7345e-06 - val_rmse: 0.0016 - val_mse: 2.7095e-06 - val_mae: 0.0016 - 34ms/epoch - 2ms/step\n",
      "Epoch 141: early stopping\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "INFO:tensorflow:Assets written to: data/output/fnn_compressed/activity-4_saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/output/fnn_compressed/activity-4_saved_model/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92c363ef723e4912b0bc75996110c689"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>loss</td><td>â–ˆâ–‡â–…â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>mae</td><td>â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>mse</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>rmse</td><td>â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val_loss</td><td>â–ˆâ–‡â–…â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val_mae</td><td>â–ˆâ–„â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val_mse</td><td>â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val_rmse</td><td>â–ˆâ–„â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>138</td></tr><tr><td>best_val_loss</td><td>0.0</td></tr><tr><td>epoch</td><td>140</td></tr><tr><td>loss</td><td>0.00124</td></tr><tr><td>mae</td><td>0.00286</td></tr><tr><td>mse</td><td>0.00124</td></tr><tr><td>rmse</td><td>0.03515</td></tr><tr><td>val_loss</td><td>0.0</td></tr><tr><td>val_mae</td><td>0.00165</td></tr><tr><td>val_mse</td><td>0.0</td></tr><tr><td>val_rmse</td><td>0.00165</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">activity-4</strong> at: <a href='https://wandb.ai/dfpl_regression/FNN_0.5_random/runs/bezufhoh' target=\"_blank\">https://wandb.ai/dfpl_regression/FNN_0.5_random/runs/bezufhoh</a><br/> View project at: <a href='https://wandb.ai/dfpl_regression/FNN_0.5_random' target=\"_blank\">https://wandb.ai/dfpl_regression/FNN_0.5_random</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20240808_154327-bezufhoh/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01111352412133581, max=1.0)â€¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "182fe59ecc4143bdba983b6c9ecf08f6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.17.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/hertelj/git-hertelj/deepFPlearn/example/wandb/run-20240808_154343-9y85fgth</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dfpl_regression/FNN_0.5_random/runs/9y85fgth' target=\"_blank\">activity-5</a></strong> to <a href='https://wandb.ai/dfpl_regression/FNN_0.5_random' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/dfpl_regression/FNN_0.5_random' target=\"_blank\">https://wandb.ai/dfpl_regression/FNN_0.5_random</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/dfpl_regression/FNN_0.5_random/runs/9y85fgth' target=\"_blank\">https://wandb.ai/dfpl_regression/FNN_0.5_random/runs/9y85fgth</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hertelj/build/local/miniforge3/envs/dfpl/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:108: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(SGD, self).__init__(name, **kwargs)\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "15/15 - 0s - loss: 4.8909 - rmse: 0.8787 - mse: 0.7721 - mae: 0.6715 - val_loss: 4.1345 - val_rmse: 0.3652 - val_mse: 0.1334 - val_mae: 0.3000 - 242ms/epoch - 16ms/step\n",
      "Epoch 2/5000\n",
      "15/15 - 0s - loss: 3.9343 - rmse: 0.2752 - mse: 0.0757 - mae: 0.2211 - val_loss: 3.6893 - val_rmse: 0.1342 - val_mse: 0.0180 - val_mae: 0.1095 - 33ms/epoch - 2ms/step\n",
      "Epoch 3/5000\n",
      "15/15 - 0s - loss: 3.5305 - rmse: 0.1295 - mse: 0.0168 - mae: 0.1005 - val_loss: 3.3263 - val_rmse: 0.0546 - val_mse: 0.0030 - val_mae: 0.0435 - 36ms/epoch - 2ms/step\n",
      "Epoch 4/5000\n",
      "15/15 - 0s - loss: 3.1794 - rmse: 0.0665 - mse: 0.0044 - mae: 0.0463 - val_loss: 2.9996 - val_rmse: 0.0287 - val_mse: 8.2277e-04 - val_mae: 0.0231 - 39ms/epoch - 3ms/step\n",
      "Epoch 5/5000\n",
      "15/15 - 0s - loss: 2.8665 - rmse: 0.0508 - mse: 0.0026 - mae: 0.0306 - val_loss: 2.7045 - val_rmse: 0.0163 - val_mse: 2.6480e-04 - val_mae: 0.0130 - 46ms/epoch - 3ms/step\n",
      "Epoch 6/5000\n",
      "15/15 - 0s - loss: 2.5839 - rmse: 0.0399 - mse: 0.0016 - mae: 0.0186 - val_loss: 2.4384 - val_rmse: 0.0143 - val_mse: 2.0471e-04 - val_mae: 0.0113 - 31ms/epoch - 2ms/step\n",
      "Epoch 7/5000\n",
      "15/15 - 0s - loss: 2.3296 - rmse: 0.0365 - mse: 0.0013 - mae: 0.0124 - val_loss: 2.1984 - val_rmse: 0.0099 - val_mse: 9.8448e-05 - val_mae: 0.0079 - 33ms/epoch - 2ms/step\n",
      "Epoch 8/5000\n",
      "15/15 - 0s - loss: 2.1006 - rmse: 0.0368 - mse: 0.0014 - mae: 0.0109 - val_loss: 1.9821 - val_rmse: 0.0082 - val_mse: 6.7115e-05 - val_mae: 0.0066 - 55ms/epoch - 4ms/step\n",
      "Epoch 9/5000\n",
      "15/15 - 0s - loss: 1.8940 - rmse: 0.0361 - mse: 0.0013 - mae: 0.0095 - val_loss: 1.7871 - val_rmse: 0.0061 - val_mse: 3.6998e-05 - val_mae: 0.0049 - 62ms/epoch - 4ms/step\n",
      "Epoch 10/5000\n",
      "\n",
      "Epoch 10: val_loss improved from inf to 1.61130, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-5.model.weights.hdf5\n",
      "15/15 - 0s - loss: 1.7077 - rmse: 0.0356 - mse: 0.0013 - mae: 0.0074 - val_loss: 1.6113 - val_rmse: 0.0093 - val_mse: 8.6917e-05 - val_mae: 0.0083 - 49ms/epoch - 3ms/step\n",
      "Epoch 11/5000\n",
      "15/15 - 0s - loss: 1.5398 - rmse: 0.0355 - mse: 0.0013 - mae: 0.0068 - val_loss: 1.4527 - val_rmse: 0.0047 - val_mse: 2.1957e-05 - val_mae: 0.0036 - 40ms/epoch - 3ms/step\n",
      "Epoch 12/5000\n",
      "15/15 - 0s - loss: 1.3885 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0058 - val_loss: 1.3098 - val_rmse: 0.0061 - val_mse: 3.6859e-05 - val_mae: 0.0052 - 41ms/epoch - 3ms/step\n",
      "Epoch 13/5000\n",
      "15/15 - 0s - loss: 1.2520 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0059 - val_loss: 1.1809 - val_rmse: 0.0046 - val_mse: 2.1535e-05 - val_mae: 0.0038 - 47ms/epoch - 3ms/step\n",
      "Epoch 14/5000\n",
      "15/15 - 0s - loss: 1.1290 - rmse: 0.0357 - mse: 0.0013 - mae: 0.0095 - val_loss: 1.0648 - val_rmse: 0.0090 - val_mse: 8.1112e-05 - val_mae: 0.0075 - 53ms/epoch - 4ms/step\n",
      "Epoch 15/5000\n",
      "15/15 - 0s - loss: 1.0180 - rmse: 0.0357 - mse: 0.0013 - mae: 0.0080 - val_loss: 0.9600 - val_rmse: 0.0054 - val_mse: 2.8816e-05 - val_mae: 0.0041 - 44ms/epoch - 3ms/step\n",
      "Epoch 16/5000\n",
      "15/15 - 0s - loss: 0.9179 - rmse: 0.0348 - mse: 0.0012 - mae: 0.0063 - val_loss: 0.8656 - val_rmse: 0.0092 - val_mse: 8.5053e-05 - val_mae: 0.0082 - 43ms/epoch - 3ms/step\n",
      "Epoch 17/5000\n",
      "15/15 - 0s - loss: 0.8278 - rmse: 0.0350 - mse: 0.0012 - mae: 0.0065 - val_loss: 0.7804 - val_rmse: 0.0045 - val_mse: 2.0221e-05 - val_mae: 0.0036 - 41ms/epoch - 3ms/step\n",
      "Epoch 18/5000\n",
      "15/15 - 0s - loss: 0.7464 - rmse: 0.0350 - mse: 0.0012 - mae: 0.0055 - val_loss: 0.7036 - val_rmse: 0.0052 - val_mse: 2.6862e-05 - val_mae: 0.0043 - 45ms/epoch - 3ms/step\n",
      "Epoch 19/5000\n",
      "15/15 - 0s - loss: 0.6731 - rmse: 0.0349 - mse: 0.0012 - mae: 0.0047 - val_loss: 0.6344 - val_rmse: 0.0033 - val_mse: 1.0591e-05 - val_mae: 0.0025 - 61ms/epoch - 4ms/step\n",
      "Epoch 20/5000\n",
      "\n",
      "Epoch 20: val_loss improved from 1.61130 to 0.57200, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-5.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.6070 - rmse: 0.0349 - mse: 0.0012 - mae: 0.0040 - val_loss: 0.5720 - val_rmse: 0.0044 - val_mse: 1.9015e-05 - val_mae: 0.0037 - 49ms/epoch - 3ms/step\n",
      "Epoch 21/5000\n",
      "15/15 - 0s - loss: 0.5474 - rmse: 0.0350 - mse: 0.0012 - mae: 0.0042 - val_loss: 0.5157 - val_rmse: 0.0028 - val_mse: 8.0679e-06 - val_mae: 0.0022 - 34ms/epoch - 2ms/step\n",
      "Epoch 22/5000\n",
      "15/15 - 0s - loss: 0.4937 - rmse: 0.0350 - mse: 0.0012 - mae: 0.0050 - val_loss: 0.4650 - val_rmse: 0.0035 - val_mse: 1.2354e-05 - val_mae: 0.0030 - 33ms/epoch - 2ms/step\n",
      "Epoch 23/5000\n",
      "15/15 - 0s - loss: 0.4453 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0043 - val_loss: 0.4192 - val_rmse: 0.0024 - val_mse: 5.8414e-06 - val_mae: 0.0019 - 32ms/epoch - 2ms/step\n",
      "Epoch 24/5000\n",
      "15/15 - 0s - loss: 0.4016 - rmse: 0.0350 - mse: 0.0012 - mae: 0.0036 - val_loss: 0.3780 - val_rmse: 0.0044 - val_mse: 1.9273e-05 - val_mae: 0.0040 - 52ms/epoch - 3ms/step\n",
      "Epoch 25/5000\n",
      "15/15 - 0s - loss: 0.3622 - rmse: 0.0350 - mse: 0.0012 - mae: 0.0037 - val_loss: 0.3408 - val_rmse: 0.0025 - val_mse: 6.3192e-06 - val_mae: 0.0021 - 41ms/epoch - 3ms/step\n",
      "Epoch 26/5000\n",
      "15/15 - 0s - loss: 0.3267 - rmse: 0.0350 - mse: 0.0012 - mae: 0.0033 - val_loss: 0.3073 - val_rmse: 0.0024 - val_mse: 5.7738e-06 - val_mae: 0.0021 - 32ms/epoch - 2ms/step\n",
      "Epoch 27/5000\n",
      "15/15 - 0s - loss: 0.2947 - rmse: 0.0350 - mse: 0.0012 - mae: 0.0030 - val_loss: 0.2771 - val_rmse: 0.0028 - val_mse: 8.0367e-06 - val_mae: 0.0025 - 31ms/epoch - 2ms/step\n",
      "Epoch 28/5000\n",
      "15/15 - 0s - loss: 0.2658 - rmse: 0.0350 - mse: 0.0012 - mae: 0.0034 - val_loss: 0.2498 - val_rmse: 0.0012 - val_mse: 1.4641e-06 - val_mae: 9.4260e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 29/5000\n",
      "15/15 - 0s - loss: 0.2398 - rmse: 0.0350 - mse: 0.0012 - mae: 0.0030 - val_loss: 0.2252 - val_rmse: 0.0011 - val_mse: 1.1690e-06 - val_mae: 8.4391e-04 - 43ms/epoch - 3ms/step\n",
      "Epoch 30/5000\n",
      "\n",
      "Epoch 30: val_loss improved from 0.57200 to 0.20308, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-5.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.2163 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0026 - val_loss: 0.2031 - val_rmse: 0.0038 - val_mse: 1.4570e-05 - val_mae: 0.0037 - 39ms/epoch - 3ms/step\n",
      "Epoch 31/5000\n",
      "15/15 - 0s - loss: 0.1952 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0034 - val_loss: 0.1831 - val_rmse: 0.0013 - val_mse: 1.6758e-06 - val_mae: 0.0011 - 33ms/epoch - 2ms/step\n",
      "Epoch 32/5000\n",
      "15/15 - 0s - loss: 0.1761 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0040 - val_loss: 0.1651 - val_rmse: 0.0011 - val_mse: 1.2729e-06 - val_mae: 9.7456e-04 - 33ms/epoch - 2ms/step\n",
      "Epoch 33/5000\n",
      "15/15 - 0s - loss: 0.1589 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0022 - val_loss: 0.1488 - val_rmse: 6.2085e-04 - val_mse: 3.8545e-07 - val_mae: 4.7601e-04 - 30ms/epoch - 2ms/step\n",
      "Epoch 34/5000\n",
      "15/15 - 0s - loss: 0.1434 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0020 - val_loss: 0.1342 - val_rmse: 0.0029 - val_mse: 8.4351e-06 - val_mae: 0.0029 - 31ms/epoch - 2ms/step\n",
      "Epoch 35/5000\n",
      "15/15 - 0s - loss: 0.1294 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0033 - val_loss: 0.1210 - val_rmse: 0.0013 - val_mse: 1.6967e-06 - val_mae: 0.0012 - 30ms/epoch - 2ms/step\n",
      "Epoch 36/5000\n",
      "15/15 - 0s - loss: 0.1168 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0022 - val_loss: 0.1091 - val_rmse: 0.0019 - val_mse: 3.5648e-06 - val_mae: 0.0018 - 32ms/epoch - 2ms/step\n",
      "Epoch 37/5000\n",
      "15/15 - 0s - loss: 0.1054 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0044 - val_loss: 0.0984 - val_rmse: 0.0018 - val_mse: 3.1063e-06 - val_mae: 0.0017 - 41ms/epoch - 3ms/step\n",
      "Epoch 38/5000\n",
      "15/15 - 0s - loss: 0.0952 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0031 - val_loss: 0.0887 - val_rmse: 0.0042 - val_mse: 1.7962e-05 - val_mae: 0.0042 - 38ms/epoch - 3ms/step\n",
      "Epoch 39/5000\n",
      "15/15 - 0s - loss: 0.0859 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0053 - val_loss: 0.0800 - val_rmse: 0.0032 - val_mse: 1.0294e-05 - val_mae: 0.0032 - 50ms/epoch - 3ms/step\n",
      "Epoch 40/5000\n",
      "\n",
      "Epoch 40: val_loss improved from 0.20308 to 0.07212, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-5.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0776 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0034 - val_loss: 0.0721 - val_rmse: 0.0047 - val_mse: 2.2417e-05 - val_mae: 0.0047 - 50ms/epoch - 3ms/step\n",
      "Epoch 41/5000\n",
      "15/15 - 0s - loss: 0.0701 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0038 - val_loss: 0.0650 - val_rmse: 2.8722e-04 - val_mse: 8.2495e-08 - val_mae: 2.4314e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 42/5000\n",
      "15/15 - 0s - loss: 0.0633 - rmse: 0.0355 - mse: 0.0013 - mae: 0.0066 - val_loss: 0.0586 - val_rmse: 0.0010 - val_mse: 1.0797e-06 - val_mae: 0.0010 - 54ms/epoch - 4ms/step\n",
      "Epoch 43/5000\n",
      "15/15 - 0s - loss: 0.0572 - rmse: 0.0354 - mse: 0.0013 - mae: 0.0038 - val_loss: 0.0529 - val_rmse: 0.0034 - val_mse: 1.1572e-05 - val_mae: 0.0034 - 46ms/epoch - 3ms/step\n",
      "Epoch 44/5000\n",
      "15/15 - 0s - loss: 0.0517 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0027 - val_loss: 0.0476 - val_rmse: 0.0018 - val_mse: 3.2957e-06 - val_mae: 0.0018 - 46ms/epoch - 3ms/step\n",
      "Epoch 45/5000\n",
      "15/15 - 0s - loss: 0.0467 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0029 - val_loss: 0.0430 - val_rmse: 0.0019 - val_mse: 3.5059e-06 - val_mae: 0.0019 - 54ms/epoch - 4ms/step\n",
      "Epoch 46/5000\n",
      "15/15 - 0s - loss: 0.0423 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0028 - val_loss: 0.0387 - val_rmse: 4.8945e-04 - val_mse: 2.3957e-07 - val_mae: 4.8019e-04 - 44ms/epoch - 3ms/step\n",
      "Epoch 47/5000\n",
      "15/15 - 0s - loss: 0.0382 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0028 - val_loss: 0.0349 - val_rmse: 0.0033 - val_mse: 1.0731e-05 - val_mae: 0.0033 - 34ms/epoch - 2ms/step\n",
      "Epoch 48/5000\n",
      "15/15 - 0s - loss: 0.0346 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0026 - val_loss: 0.0315 - val_rmse: 0.0020 - val_mse: 3.9074e-06 - val_mae: 0.0020 - 32ms/epoch - 2ms/step\n",
      "Epoch 49/5000\n",
      "15/15 - 0s - loss: 0.0313 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0026 - val_loss: 0.0284 - val_rmse: 0.0022 - val_mse: 4.7097e-06 - val_mae: 0.0022 - 33ms/epoch - 2ms/step\n",
      "Epoch 50/5000\n",
      "\n",
      "Epoch 50: val_loss improved from 0.07212 to 0.02560, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-5.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0283 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0022 - val_loss: 0.0256 - val_rmse: 0.0015 - val_mse: 2.3725e-06 - val_mae: 0.0015 - 37ms/epoch - 2ms/step\n",
      "Epoch 51/5000\n",
      "15/15 - 0s - loss: 0.0257 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0029 - val_loss: 0.0231 - val_rmse: 6.1282e-04 - val_mse: 3.7554e-07 - val_mae: 6.1119e-04 - 49ms/epoch - 3ms/step\n",
      "Epoch 52/5000\n",
      "15/15 - 0s - loss: 0.0233 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0037 - val_loss: 0.0208 - val_rmse: 0.0016 - val_mse: 2.6072e-06 - val_mae: 0.0016 - 42ms/epoch - 3ms/step\n",
      "Epoch 53/5000\n",
      "15/15 - 0s - loss: 0.0211 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0024 - val_loss: 0.0188 - val_rmse: 0.0021 - val_mse: 4.4961e-06 - val_mae: 0.0021 - 55ms/epoch - 4ms/step\n",
      "Epoch 54/5000\n",
      "15/15 - 0s - loss: 0.0192 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0022 - val_loss: 0.0169 - val_rmse: 0.0023 - val_mse: 5.4511e-06 - val_mae: 0.0023 - 45ms/epoch - 3ms/step\n",
      "Epoch 55/5000\n",
      "15/15 - 0s - loss: 0.0174 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0043 - val_loss: 0.0153 - val_rmse: 0.0021 - val_mse: 4.4638e-06 - val_mae: 0.0021 - 38ms/epoch - 3ms/step\n",
      "Epoch 56/5000\n",
      "15/15 - 0s - loss: 0.0158 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0032 - val_loss: 0.0138 - val_rmse: 0.0045 - val_mse: 1.9814e-05 - val_mae: 0.0045 - 40ms/epoch - 3ms/step\n",
      "Epoch 57/5000\n",
      "15/15 - 0s - loss: 0.0144 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0036 - val_loss: 0.0124 - val_rmse: 3.4417e-04 - val_mse: 1.1845e-07 - val_mae: 3.4371e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 58/5000\n",
      "15/15 - 0s - loss: 0.0131 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0044 - val_loss: 0.0112 - val_rmse: 7.4411e-04 - val_mse: 5.5370e-07 - val_mae: 7.4395e-04 - 37ms/epoch - 2ms/step\n",
      "Epoch 59/5000\n",
      "15/15 - 0s - loss: 0.0119 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0016 - val_loss: 0.0101 - val_rmse: 1.6663e-05 - val_mse: 2.7764e-10 - val_mae: 1.3712e-05 - 39ms/epoch - 3ms/step\n",
      "Epoch 60/5000\n",
      "\n",
      "Epoch 60: val_loss improved from 0.02560 to 0.00909, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-5.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0109 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0027 - val_loss: 0.0091 - val_rmse: 0.0019 - val_mse: 3.6544e-06 - val_mae: 0.0019 - 44ms/epoch - 3ms/step\n",
      "Epoch 61/5000\n",
      "15/15 - 0s - loss: 0.0099 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0023 - val_loss: 0.0082 - val_rmse: 0.0013 - val_mse: 1.8081e-06 - val_mae: 0.0013 - 37ms/epoch - 2ms/step\n",
      "Epoch 62/5000\n",
      "15/15 - 0s - loss: 0.0091 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0050 - val_loss: 0.0074 - val_rmse: 6.9162e-04 - val_mse: 4.7834e-07 - val_mae: 6.9157e-04 - 36ms/epoch - 2ms/step\n",
      "Epoch 63/5000\n",
      "15/15 - 0s - loss: 0.0083 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0024 - val_loss: 0.0067 - val_rmse: 0.0011 - val_mse: 1.3057e-06 - val_mae: 0.0011 - 36ms/epoch - 2ms/step\n",
      "Epoch 64/5000\n",
      "15/15 - 0s - loss: 0.0076 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0022 - val_loss: 0.0060 - val_rmse: 0.0027 - val_mse: 7.3938e-06 - val_mae: 0.0027 - 37ms/epoch - 2ms/step\n",
      "Epoch 65/5000\n",
      "15/15 - 0s - loss: 0.0070 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0027 - val_loss: 0.0054 - val_rmse: 0.0016 - val_mse: 2.5229e-06 - val_mae: 0.0016 - 31ms/epoch - 2ms/step\n",
      "Epoch 66/5000\n",
      "15/15 - 0s - loss: 0.0064 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0020 - val_loss: 0.0049 - val_rmse: 0.0024 - val_mse: 5.5606e-06 - val_mae: 0.0024 - 33ms/epoch - 2ms/step\n",
      "Epoch 67/5000\n",
      "15/15 - 0s - loss: 0.0059 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0046 - val_loss: 0.0044 - val_rmse: 0.0022 - val_mse: 5.0527e-06 - val_mae: 0.0022 - 31ms/epoch - 2ms/step\n",
      "Epoch 68/5000\n",
      "15/15 - 0s - loss: 0.0055 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0038 - val_loss: 0.0040 - val_rmse: 0.0032 - val_mse: 1.0453e-05 - val_mae: 0.0032 - 30ms/epoch - 2ms/step\n",
      "Epoch 69/5000\n",
      "15/15 - 0s - loss: 0.0050 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0025 - val_loss: 0.0036 - val_rmse: 0.0016 - val_mse: 2.6713e-06 - val_mae: 0.0016 - 31ms/epoch - 2ms/step\n",
      "Epoch 70/5000\n",
      "\n",
      "Epoch 70: val_loss improved from 0.00909 to 0.00323, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-5.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0047 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0022 - val_loss: 0.0032 - val_rmse: 0.0025 - val_mse: 6.2127e-06 - val_mae: 0.0025 - 35ms/epoch - 2ms/step\n",
      "Epoch 71/5000\n",
      "15/15 - 0s - loss: 0.0043 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0029 - val_loss: 0.0029 - val_rmse: 0.0016 - val_mse: 2.5763e-06 - val_mae: 0.0016 - 32ms/epoch - 2ms/step\n",
      "Epoch 72/5000\n",
      "15/15 - 0s - loss: 0.0040 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0027 - val_loss: 0.0026 - val_rmse: 7.5332e-04 - val_mse: 5.6750e-07 - val_mae: 7.5332e-04 - 31ms/epoch - 2ms/step\n",
      "Epoch 73/5000\n",
      "15/15 - 0s - loss: 0.0037 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0020 - val_loss: 0.0024 - val_rmse: 0.0018 - val_mse: 3.1434e-06 - val_mae: 0.0018 - 37ms/epoch - 2ms/step\n",
      "Epoch 74/5000\n",
      "15/15 - 0s - loss: 0.0035 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0039 - val_loss: 0.0021 - val_rmse: 0.0017 - val_mse: 2.8770e-06 - val_mae: 0.0017 - 37ms/epoch - 2ms/step\n",
      "Epoch 75/5000\n",
      "15/15 - 0s - loss: 0.0033 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0027 - val_loss: 0.0019 - val_rmse: 1.8446e-04 - val_mse: 3.4027e-08 - val_mae: 1.8446e-04 - 33ms/epoch - 2ms/step\n",
      "Epoch 76/5000\n",
      "15/15 - 0s - loss: 0.0031 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0021 - val_loss: 0.0017 - val_rmse: 0.0031 - val_mse: 9.6828e-06 - val_mae: 0.0031 - 31ms/epoch - 2ms/step\n",
      "Epoch 77/5000\n",
      "15/15 - 0s - loss: 0.0029 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0038 - val_loss: 0.0016 - val_rmse: 9.7618e-04 - val_mse: 9.5293e-07 - val_mae: 9.7618e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 78/5000\n",
      "15/15 - 0s - loss: 0.0027 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0021 - val_loss: 0.0014 - val_rmse: 0.0030 - val_mse: 9.1150e-06 - val_mae: 0.0030 - 28ms/epoch - 2ms/step\n",
      "Epoch 79/5000\n",
      "15/15 - 0s - loss: 0.0026 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0031 - val_loss: 0.0013 - val_rmse: 0.0016 - val_mse: 2.4458e-06 - val_mae: 0.0016 - 33ms/epoch - 2ms/step\n",
      "Epoch 80/5000\n",
      "\n",
      "Epoch 80: val_loss improved from 0.00323 to 0.00115, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-5.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0024 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0028 - val_loss: 0.0011 - val_rmse: 0.0017 - val_mse: 2.7986e-06 - val_mae: 0.0017 - 47ms/epoch - 3ms/step\n",
      "Epoch 81/5000\n",
      "15/15 - 0s - loss: 0.0023 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0022 - val_loss: 0.0010 - val_rmse: 0.0027 - val_mse: 7.4005e-06 - val_mae: 0.0027 - 29ms/epoch - 2ms/step\n",
      "Epoch 82/5000\n",
      "15/15 - 0s - loss: 0.0022 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0032 - val_loss: 9.3298e-04 - val_rmse: 0.0014 - val_mse: 1.9597e-06 - val_mae: 0.0014 - 29ms/epoch - 2ms/step\n",
      "Epoch 83/5000\n",
      "15/15 - 0s - loss: 0.0021 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0020 - val_loss: 8.4140e-04 - val_rmse: 0.0014 - val_mse: 1.9710e-06 - val_mae: 0.0014 - 37ms/epoch - 2ms/step\n",
      "Epoch 84/5000\n",
      "15/15 - 0s - loss: 0.0020 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0036 - val_loss: 7.6018e-04 - val_rmse: 0.0018 - val_mse: 3.3382e-06 - val_mae: 0.0018 - 40ms/epoch - 3ms/step\n",
      "Epoch 85/5000\n",
      "15/15 - 0s - loss: 0.0020 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0025 - val_loss: 6.8657e-04 - val_rmse: 0.0020 - val_mse: 4.1824e-06 - val_mae: 0.0020 - 41ms/epoch - 3ms/step\n",
      "Epoch 86/5000\n",
      "15/15 - 0s - loss: 0.0019 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0022 - val_loss: 6.2116e-04 - val_rmse: 0.0024 - val_mse: 5.9044e-06 - val_mae: 0.0024 - 36ms/epoch - 2ms/step\n",
      "Epoch 87/5000\n",
      "15/15 - 0s - loss: 0.0018 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0028 - val_loss: 5.5819e-04 - val_rmse: 0.0019 - val_mse: 3.4602e-06 - val_mae: 0.0019 - 31ms/epoch - 2ms/step\n",
      "Epoch 88/5000\n",
      "15/15 - 0s - loss: 0.0018 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0021 - val_loss: 5.0133e-04 - val_rmse: 0.0011 - val_mse: 1.1726e-06 - val_mae: 0.0011 - 41ms/epoch - 3ms/step\n",
      "Epoch 89/5000\n",
      "15/15 - 0s - loss: 0.0017 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0045 - val_loss: 4.5144e-04 - val_rmse: 6.9768e-04 - val_mse: 4.8676e-07 - val_mae: 6.9768e-04 - 32ms/epoch - 2ms/step\n",
      "Epoch 90/5000\n",
      "\n",
      "Epoch 90: val_loss improved from 0.00115 to 0.00041, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-5.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0017 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0019 - val_loss: 4.0680e-04 - val_rmse: 4.6384e-04 - val_mse: 2.1515e-07 - val_mae: 4.6384e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 91/5000\n",
      "15/15 - 0s - loss: 0.0016 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0016 - val_loss: 3.7079e-04 - val_rmse: 0.0021 - val_mse: 4.2058e-06 - val_mae: 0.0021 - 37ms/epoch - 2ms/step\n",
      "Epoch 92/5000\n",
      "15/15 - 0s - loss: 0.0016 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0066 - val_loss: 3.3053e-04 - val_rmse: 1.1361e-04 - val_mse: 1.2907e-08 - val_mae: 1.1361e-04 - 30ms/epoch - 2ms/step\n",
      "Epoch 93/5000\n",
      "15/15 - 0s - loss: 0.0016 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0034 - val_loss: 3.0544e-04 - val_rmse: 0.0027 - val_mse: 7.4293e-06 - val_mae: 0.0027 - 40ms/epoch - 3ms/step\n",
      "Epoch 94/5000\n",
      "15/15 - 0s - loss: 0.0015 - rmse: 0.0354 - mse: 0.0013 - mae: 0.0042 - val_loss: 2.6869e-04 - val_rmse: 2.8647e-06 - val_mse: 8.2068e-12 - val_mae: 2.8642e-06 - 47ms/epoch - 3ms/step\n",
      "Epoch 95/5000\n",
      "15/15 - 0s - loss: 0.0015 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0057 - val_loss: 2.4227e-04 - val_rmse: 8.3432e-05 - val_mse: 6.9609e-09 - val_mae: 8.3432e-05 - 46ms/epoch - 3ms/step\n",
      "Epoch 96/5000\n",
      "15/15 - 0s - loss: 0.0015 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0035 - val_loss: 2.3475e-04 - val_rmse: 0.0040 - val_mse: 1.6322e-05 - val_mae: 0.0040 - 33ms/epoch - 2ms/step\n",
      "Epoch 97/5000\n",
      "15/15 - 0s - loss: 0.0015 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0036 - val_loss: 1.9694e-04 - val_rmse: 3.2187e-05 - val_mse: 1.0360e-09 - val_mae: 3.2187e-05 - 41ms/epoch - 3ms/step\n",
      "Epoch 98/5000\n",
      "15/15 - 0s - loss: 0.0014 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0054 - val_loss: 1.8060e-04 - val_rmse: 0.0017 - val_mse: 3.0333e-06 - val_mae: 0.0017 - 38ms/epoch - 3ms/step\n",
      "Epoch 99/5000\n",
      "15/15 - 0s - loss: 0.0014 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0026 - val_loss: 1.6907e-04 - val_rmse: 0.0030 - val_mse: 8.9704e-06 - val_mae: 0.0030 - 29ms/epoch - 2ms/step\n",
      "Epoch 100/5000\n",
      "\n",
      "Epoch 100: val_loss improved from 0.00041 to 0.00015, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-5.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0014 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0033 - val_loss: 1.4643e-04 - val_rmse: 0.0014 - val_mse: 2.0865e-06 - val_mae: 0.0014 - 52ms/epoch - 3ms/step\n",
      "Epoch 101/5000\n",
      "15/15 - 0s - loss: 0.0014 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0030 - val_loss: 1.3084e-04 - val_rmse: 8.3786e-04 - val_mse: 7.0200e-07 - val_mae: 8.3786e-04 - 34ms/epoch - 2ms/step\n",
      "Epoch 102/5000\n",
      "15/15 - 0s - loss: 0.0014 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0030 - val_loss: 1.2105e-04 - val_rmse: 0.0019 - val_mse: 3.7115e-06 - val_mae: 0.0019 - 36ms/epoch - 2ms/step\n",
      "Epoch 103/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0025 - val_loss: 1.0584e-04 - val_rmse: 1.9805e-04 - val_mse: 3.9222e-08 - val_mae: 1.9805e-04 - 42ms/epoch - 3ms/step\n",
      "Epoch 104/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0025 - val_loss: 1.0158e-04 - val_rmse: 0.0025 - val_mse: 6.1915e-06 - val_mae: 0.0025 - 50ms/epoch - 3ms/step\n",
      "Epoch 105/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0025 - val_loss: 8.8158e-05 - val_rmse: 0.0015 - val_mse: 2.1533e-06 - val_mae: 0.0015 - 36ms/epoch - 2ms/step\n",
      "Epoch 106/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0029 - val_loss: 7.7594e-05 - val_rmse: 2.2342e-04 - val_mse: 4.9915e-08 - val_mae: 2.2342e-04 - 30ms/epoch - 2ms/step\n",
      "Epoch 107/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0021 - val_loss: 7.9613e-05 - val_rmse: 0.0031 - val_mse: 9.6953e-06 - val_mae: 0.0031 - 45ms/epoch - 3ms/step\n",
      "Epoch 108/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0033 - val_loss: 6.3136e-05 - val_rmse: 3.1227e-04 - val_mse: 9.7516e-08 - val_mae: 3.1227e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 109/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0049 - val_loss: 5.8687e-05 - val_rmse: 0.0014 - val_mse: 1.8494e-06 - val_mae: 0.0014 - 45ms/epoch - 3ms/step\n",
      "Epoch 110/5000\n",
      "\n",
      "Epoch 110: val_loss improved from 0.00015 to 0.00005, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-5.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0020 - val_loss: 5.3380e-05 - val_rmse: 0.0015 - val_mse: 2.1337e-06 - val_mae: 0.0015 - 41ms/epoch - 3ms/step\n",
      "Epoch 111/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0048 - val_loss: 4.6208e-05 - val_rmse: 6.3581e-05 - val_mse: 4.0425e-09 - val_mae: 6.3581e-05 - 42ms/epoch - 3ms/step\n",
      "Epoch 112/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0353 - mse: 0.0012 - mae: 0.0027 - val_loss: 4.5518e-05 - val_rmse: 0.0020 - val_mse: 3.8588e-06 - val_mae: 0.0020 - 40ms/epoch - 3ms/step\n",
      "Epoch 113/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0351 - mse: 0.0012 - mae: 0.0030 - val_loss: 3.7858e-05 - val_rmse: 5.4576e-04 - val_mse: 2.9786e-07 - val_mae: 5.4576e-04 - 39ms/epoch - 3ms/step\n",
      "Epoch 114/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0029 - val_loss: 3.7156e-05 - val_rmse: 0.0018 - val_mse: 3.2907e-06 - val_mae: 0.0018 - 40ms/epoch - 3ms/step\n",
      "Epoch 115/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0024 - val_loss: 3.1181e-05 - val_rmse: 8.0412e-04 - val_mse: 6.4661e-07 - val_mae: 8.0412e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 116/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0019 - val_loss: 3.5219e-05 - val_rmse: 0.0028 - val_mse: 7.6878e-06 - val_mae: 0.0028 - 42ms/epoch - 3ms/step\n",
      "Epoch 117/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0041 - val_loss: 2.4869e-05 - val_rmse: 2.1624e-04 - val_mse: 4.6759e-08 - val_mae: 2.1624e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 118/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0022 - val_loss: 2.2653e-05 - val_rmse: 5.2303e-04 - val_mse: 2.7356e-07 - val_mae: 5.2303e-04 - 41ms/epoch - 3ms/step\n",
      "Epoch 119/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0018 - val_loss: 2.3387e-05 - val_rmse: 0.0018 - val_mse: 3.2090e-06 - val_mae: 0.0018 - 52ms/epoch - 3ms/step\n",
      "Epoch 120/5000\n",
      "\n",
      "Epoch 120: val_loss improved from 0.00005 to 0.00002, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-5.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0034 - val_loss: 2.0272e-05 - val_rmse: 0.0014 - val_mse: 2.0783e-06 - val_mae: 0.0014 - 47ms/epoch - 3ms/step\n",
      "Epoch 121/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0020 - val_loss: 1.9415e-05 - val_rmse: 0.0017 - val_mse: 3.0112e-06 - val_mae: 0.0017 - 42ms/epoch - 3ms/step\n",
      "Epoch 122/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0037 - val_loss: 1.7192e-05 - val_rmse: 0.0015 - val_mse: 2.4024e-06 - val_mae: 0.0015 - 38ms/epoch - 3ms/step\n",
      "Epoch 123/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0023 - val_loss: 1.4257e-05 - val_rmse: 9.6023e-04 - val_mse: 9.2205e-07 - val_mae: 9.6023e-04 - 40ms/epoch - 3ms/step\n",
      "Epoch 124/5000\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0027 - val_loss: 1.2024e-05 - val_rmse: 3.5298e-05 - val_mse: 1.2460e-09 - val_mae: 3.5298e-05 - 38ms/epoch - 3ms/step\n",
      "Epoch 125/5000\n",
      "15/15 - 0s - loss: 0.0013 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0025 - val_loss: 1.1060e-05 - val_rmse: 4.6926e-04 - val_mse: 2.2021e-07 - val_mae: 4.6926e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 126/5000\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0025 - val_loss: 1.0421e-05 - val_rmse: 8.0445e-04 - val_mse: 6.4715e-07 - val_mae: 8.0445e-04 - 38ms/epoch - 3ms/step\n",
      "Epoch 127/5000\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0022 - val_loss: 1.8542e-05 - val_rmse: 0.0031 - val_mse: 9.7292e-06 - val_mae: 0.0031 - 34ms/epoch - 2ms/step\n",
      "Epoch 128/5000\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0032 - val_loss: 9.4819e-06 - val_rmse: 0.0012 - val_mse: 1.5370e-06 - val_mae: 0.0012 - 37ms/epoch - 2ms/step\n",
      "Epoch 129/5000\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0024 - val_loss: 1.1126e-05 - val_rmse: 0.0020 - val_mse: 3.9629e-06 - val_mae: 0.0020 - 36ms/epoch - 2ms/step\n",
      "Epoch 130/5000\n",
      "\n",
      "Epoch 130: val_loss improved from 0.00002 to 0.00001, saving model to data/output/fnn_compressed/activity_random_single-labeled_Fold-5.model.weights.hdf5\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0022 - val_loss: 1.2750e-05 - val_rmse: 0.0025 - val_mse: 6.2913e-06 - val_mae: 0.0025 - 56ms/epoch - 4ms/step\n",
      "Epoch 131/5000\n",
      "Restoring model weights from the end of the best epoch: 111.\n",
      "15/15 - 0s - loss: 0.0012 - rmse: 0.0352 - mse: 0.0012 - mae: 0.0036 - val_loss: 5.8245e-06 - val_rmse: 3.8755e-05 - val_mse: 1.5019e-09 - val_mae: 3.8755e-05 - 38ms/epoch - 3ms/step\n",
      "Epoch 131: early stopping\n",
      "7/7 [==============================] - 0s 819us/step\n",
      "INFO:tensorflow:Assets written to: data/output/fnn_compressed/activity-5_saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/output/fnn_compressed/activity-5_saved_model/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a45bc8d91dc4ddcb35e4898b78097d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>loss</td><td>â–ˆâ–‡â–…â–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>mae</td><td>â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>mse</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>rmse</td><td>â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val_loss</td><td>â–ˆâ–‡â–…â–„â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val_mae</td><td>â–ˆâ–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val_mse</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>val_rmse</td><td>â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>130</td></tr><tr><td>best_val_loss</td><td>1e-05</td></tr><tr><td>epoch</td><td>130</td></tr><tr><td>loss</td><td>0.00124</td></tr><tr><td>mae</td><td>0.00363</td></tr><tr><td>mse</td><td>0.00124</td></tr><tr><td>rmse</td><td>0.03515</td></tr><tr><td>val_loss</td><td>1e-05</td></tr><tr><td>val_mae</td><td>4e-05</td></tr><tr><td>val_mse</td><td>0.0</td></tr><tr><td>val_rmse</td><td>4e-05</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">activity-5</strong> at: <a href='https://wandb.ai/dfpl_regression/FNN_0.5_random/runs/9y85fgth' target=\"_blank\">https://wandb.ai/dfpl_regression/FNN_0.5_random/runs/9y85fgth</a><br/> View project at: <a href='https://wandb.ai/dfpl_regression/FNN_0.5_random' target=\"_blank\">https://wandb.ai/dfpl_regression/FNN_0.5_random</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20240808_154343-9y85fgth/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Find best fold",
   "id": "abbeee8468714d20"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:43:59.034004Z",
     "start_time": "2024-08-08T13:43:59.027540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_files(directory, pattern):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for basename in files:\n",
    "            if fnmatch.fnmatch(basename, pattern):\n",
    "                filename = os.path.join(root, basename)\n",
    "                yield filename\n",
    "\n",
    "\n",
    "best_fold = 0\n",
    "for filename in find_files(base_out_dir, '*.best.model.weights*'):\n",
    "    filename_split = filename.split('.')\n",
    "    best_fold = int(filename_split[0][-1])\n",
    "    img_file = filename_split[0] + '.history.jpg'\n",
    "    img = Image(filename=img_file)\n",
    "    display(img)\n",
    "best_fold"
   ],
   "id": "c5c11dcf850c6153",
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:43:59.044435Z",
     "start_time": "2024-08-08T13:43:59.034738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_evaluation = pd.read_csv(\n",
    "    filepath_or_buffer=f'{base_out_dir}/single_label_model.evaluation.csv')\n",
    "model_evaluation[model_evaluation['fold'] == best_fold]"
   ],
   "id": "5ef940b2e61ad48a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Unnamed: 0 metric     value  fold    target\n",
       "6            6    MSE  0.038129     2  activity\n",
       "7            7    MAE  0.162599     2  activity\n",
       "8            8   MdAE  0.155774     2  activity\n",
       "9            9  ACPER  0.088670     2  activity\n",
       "10          10   MAPE       inf     2  activity\n",
       "11          11   RMSE  0.195267     2  activity"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "      <th>fold</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>MSE</td>\n",
       "      <td>0.038129</td>\n",
       "      <td>2</td>\n",
       "      <td>activity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>MAE</td>\n",
       "      <td>0.162599</td>\n",
       "      <td>2</td>\n",
       "      <td>activity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>MdAE</td>\n",
       "      <td>0.155774</td>\n",
       "      <td>2</td>\n",
       "      <td>activity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>ACPER</td>\n",
       "      <td>0.088670</td>\n",
       "      <td>2</td>\n",
       "      <td>activity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>MAPE</td>\n",
       "      <td>inf</td>\n",
       "      <td>2</td>\n",
       "      <td>activity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>0.195267</td>\n",
       "      <td>2</td>\n",
       "      <td>activity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Predict test dataset",
   "id": "d4b9cdb6567a7bdd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:43:59.047296Z",
     "start_time": "2024-08-08T13:43:59.045182Z"
    }
   },
   "cell_type": "code",
   "source": [
    "opts = options.Options(\n",
    "    inputFile='data/tox24_challenge_test.csv',\n",
    "    outputDir=f'{base_out_dir}',\n",
    "    outputFile=f'{base_out_dir}test.predictions.csv',\n",
    "    ecModelDir=f'{base_out_dir}/AE_encoder/',\n",
    "    fnnModelDir=f'{base_out_dir}/activity_saved_model',\n",
    "    compressFeatures=True,\n",
    ")"
   ],
   "id": "15340254e48af9e0",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:43:59.947629Z",
     "start_time": "2024-08-08T13:43:59.048045Z"
    }
   },
   "cell_type": "code",
   "source": "df = fp.importDataFile(opts.inputFile, import_function=fp.importSmilesCSV, fp_size=opts.fpSize)\n",
   "id": "2c3efbcb90e79072",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:44:00.080489Z",
     "start_time": "2024-08-08T13:43:59.948962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if opts.compressFeatures:\n",
    "    # load trained model for autoencoder\n",
    "    encoder = keras.models.load_model(opts.ecModelDir)\n",
    "\n",
    "    # compress the fingerprints using the autoencoder\n",
    "    df = ac.compress_fingerprints(df, encoder)"
   ],
   "id": "b8f45f2abcb33969",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 921us/step\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "5bc03dea35295afb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:44:00.357250Z",
     "start_time": "2024-08-08T13:44:00.081447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# predict\n",
    "df2 = predictions.predict_values(df=df, opts=opts)"
   ],
   "id": "6130da05f878e93f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 955us/step\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:51:47.478296Z",
     "start_time": "2024-08-08T13:51:47.474484Z"
    }
   },
   "cell_type": "code",
   "source": "df2.columns",
   "id": "630324579e74a5d3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SMILES', 'fp', 'fpcompressed', 'predicted'], dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Reverse the scaling of the predicted values",
   "id": "5be323d66d4f7d08"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T14:00:28.878357Z",
     "start_time": "2024-08-08T14:00:28.870889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "activity_predicted = df2['predicted']\n",
    "\n",
    "activity_predicted_rescaled = scaler.inverse_transform(activity_predicted.to_numpy().reshape(-1, 1))"
   ],
   "id": "e5ffe69737d1a20a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.22672510e+01],\n",
       "       [ 6.19363174e+01],\n",
       "       [ 3.54542999e+01],\n",
       "       [ 2.13824272e+01],\n",
       "       [ 5.21957474e+01],\n",
       "       [ 5.43165741e+01],\n",
       "       [ 2.22862587e+01],\n",
       "       [ 5.60308609e+01],\n",
       "       [ 3.54542999e+01],\n",
       "       [ 5.94043617e+01],\n",
       "       [ 6.19787369e+01],\n",
       "       [ 4.48969269e+01],\n",
       "       [ 3.12326775e+01],\n",
       "       [ 6.32182159e+01],\n",
       "       [ 3.64657898e+01],\n",
       "       [-1.35579002e+00],\n",
       "       [ 3.64657898e+01],\n",
       "       [ 3.64657898e+01],\n",
       "       [ 3.84133415e+01],\n",
       "       [-7.86982965e+00],\n",
       "       [ 2.29881496e+01],\n",
       "       [ 3.64657898e+01],\n",
       "       [ 2.03865986e+01],\n",
       "       [ 1.72654381e+01],\n",
       "       [ 5.53011360e+01],\n",
       "       [ 2.75154152e+01],\n",
       "       [ 1.61109543e+01],\n",
       "       [ 5.44109840e+01],\n",
       "       [ 2.64086380e+01],\n",
       "       [ 4.88262444e+01],\n",
       "       [ 5.05571136e+01],\n",
       "       [ 2.61357250e+01],\n",
       "       [ 2.69786377e+01],\n",
       "       [ 3.99063683e+01],\n",
       "       [ 5.03125038e+01],\n",
       "       [ 2.65471878e+01],\n",
       "       [ 3.81370163e+01],\n",
       "       [ 2.42454433e+01],\n",
       "       [ 2.20428162e+01],\n",
       "       [ 5.03654194e+00],\n",
       "       [ 2.08671093e+01],\n",
       "       [ 5.68971901e+01],\n",
       "       [ 3.98284798e+01],\n",
       "       [ 1.92836037e+01],\n",
       "       [ 6.08120155e+01],\n",
       "       [ 1.94866219e+01],\n",
       "       [ 4.03223343e+01],\n",
       "       [ 5.49817200e+01],\n",
       "       [ 1.17263556e+01],\n",
       "       [ 2.89912930e+01],\n",
       "       [ 1.96339703e+01],\n",
       "       [ 5.48013000e+01],\n",
       "       [ 1.85088024e+01],\n",
       "       [ 2.99488163e+01],\n",
       "       [ 9.74177933e+00],\n",
       "       [ 1.04441137e+01],\n",
       "       [ 3.95063400e+01],\n",
       "       [ 2.35259571e+01],\n",
       "       [ 5.90888252e+01],\n",
       "       [ 3.56258926e+01],\n",
       "       [ 3.28434448e+01],\n",
       "       [ 1.74508209e+01],\n",
       "       [ 2.70387344e+01],\n",
       "       [ 6.28396263e+01],\n",
       "       [ 5.25423508e+01],\n",
       "       [ 6.20601006e+01],\n",
       "       [ 7.50920258e+01],\n",
       "       [ 2.49539318e+01],\n",
       "       [ 2.95037079e+01],\n",
       "       [ 1.44944086e+01],\n",
       "       [ 5.62346802e+01],\n",
       "       [ 2.07213707e+01],\n",
       "       [ 1.67274418e+01],\n",
       "       [ 2.48600330e+01],\n",
       "       [ 1.70455418e+01],\n",
       "       [ 4.11811371e+01],\n",
       "       [ 5.41071053e+01],\n",
       "       [ 6.34332390e+01],\n",
       "       [ 5.72007637e+01],\n",
       "       [ 5.13650780e+01],\n",
       "       [ 5.76993904e+01],\n",
       "       [ 7.97673187e+01],\n",
       "       [ 6.47681122e+01],\n",
       "       [ 2.23600368e+01],\n",
       "       [ 4.51647682e+01],\n",
       "       [ 5.61621628e+01],\n",
       "       [ 5.53132782e+01],\n",
       "       [ 3.44526024e+01],\n",
       "       [ 3.27796173e+01],\n",
       "       [ 6.82435074e+01],\n",
       "       [ 5.35502434e+01],\n",
       "       [ 4.05698853e+01],\n",
       "       [-1.32734137e+01],\n",
       "       [ 3.26506691e+01],\n",
       "       [ 2.08804512e+01],\n",
       "       [ 3.04809093e+01],\n",
       "       [ 8.49524002e+01],\n",
       "       [ 3.30110207e+01],\n",
       "       [ 1.93880157e+01],\n",
       "       [ 2.35724373e+01],\n",
       "       [ 2.89631023e+01],\n",
       "       [ 2.35581970e+01],\n",
       "       [ 2.77313824e+01],\n",
       "       [ 1.26577148e+01],\n",
       "       [ 3.35933151e+01],\n",
       "       [ 5.44241142e+01],\n",
       "       [ 3.91544151e+01],\n",
       "       [ 3.87018318e+01],\n",
       "       [ 4.80266533e+01],\n",
       "       [ 6.65841141e+01],\n",
       "       [ 3.29507637e+01],\n",
       "       [ 4.90358696e+01],\n",
       "       [ 1.38253183e+01],\n",
       "       [ 1.48569450e+01],\n",
       "       [ 4.42318726e+01],\n",
       "       [ 6.99811630e+01],\n",
       "       [ 2.45412273e+01],\n",
       "       [ 3.51541367e+01],\n",
       "       [ 3.80948944e+01],\n",
       "       [ 8.91738701e+00],\n",
       "       [ 4.42392044e+01],\n",
       "       [ 5.93626976e+01],\n",
       "       [ 7.68013153e+01],\n",
       "       [ 6.17441559e+01],\n",
       "       [ 3.29119720e+01],\n",
       "       [ 5.54806061e+01],\n",
       "       [ 8.62330723e+00],\n",
       "       [ 2.27475090e+01],\n",
       "       [ 5.89916229e+01],\n",
       "       [ 7.27884750e+01],\n",
       "       [ 4.88829002e+01],\n",
       "       [ 9.81625519e+01],\n",
       "       [ 4.53345528e+01],\n",
       "       [ 6.99059296e+01],\n",
       "       [ 5.87886429e+01],\n",
       "       [-2.93679261e+00],\n",
       "       [-5.07930946e+00],\n",
       "       [ 3.85400200e+01],\n",
       "       [ 3.73017693e+01],\n",
       "       [ 6.05141754e+01],\n",
       "       [ 6.59423218e+01],\n",
       "       [ 5.69066143e+00],\n",
       "       [ 1.20263767e+01],\n",
       "       [ 2.68007488e+01],\n",
       "       [ 2.62214603e+01],\n",
       "       [ 4.30653191e+01],\n",
       "       [ 5.75832443e+01],\n",
       "       [ 3.21253319e+01],\n",
       "       [ 8.56878662e+01],\n",
       "       [ 3.71762466e+01],\n",
       "       [ 2.11080856e+01],\n",
       "       [ 2.86844845e+01],\n",
       "       [ 6.43509598e+01],\n",
       "       [ 2.25675964e+01],\n",
       "       [ 4.16300621e+01],\n",
       "       [ 3.04528198e+01],\n",
       "       [ 6.42848587e+01],\n",
       "       [ 2.68282623e+01],\n",
       "       [ 2.60227146e+01],\n",
       "       [ 1.81123600e+01],\n",
       "       [ 4.36993332e+01],\n",
       "       [ 1.38286963e+01],\n",
       "       [ 1.57570229e+01],\n",
       "       [ 2.77095394e+01],\n",
       "       [ 3.47471008e+01],\n",
       "       [ 2.12906952e+01],\n",
       "       [ 3.78954582e+01],\n",
       "       [ 1.07916889e+01],\n",
       "       [ 1.22672510e+01],\n",
       "       [ 2.98190045e+00],\n",
       "       [ 2.33969994e+01],\n",
       "       [ 1.73907757e+01],\n",
       "       [ 4.85999184e+01],\n",
       "       [ 3.56158066e+01],\n",
       "       [ 5.43914833e+01],\n",
       "       [ 8.06699848e+00],\n",
       "       [ 4.15314713e+01],\n",
       "       [ 5.97851944e+01],\n",
       "       [ 6.69017639e+01],\n",
       "       [ 3.80993996e+01],\n",
       "       [ 2.06361904e+01],\n",
       "       [ 2.54129772e+01],\n",
       "       [ 3.42672348e+01],\n",
       "       [ 7.00872803e+01],\n",
       "       [ 3.97074432e+01],\n",
       "       [ 7.88959198e+01],\n",
       "       [ 4.58617134e+01],\n",
       "       [ 2.92731953e+01],\n",
       "       [ 2.92731953e+01],\n",
       "       [ 4.83987503e+01],\n",
       "       [ 4.73251953e+01],\n",
       "       [ 7.52605724e+00],\n",
       "       [ 2.66414776e+01],\n",
       "       [ 6.84239273e+01],\n",
       "       [ 3.82572098e+01],\n",
       "       [ 2.69101200e+01],\n",
       "       [ 4.10678749e+01],\n",
       "       [ 4.10394707e+01],\n",
       "       [ 4.79028511e+01],\n",
       "       [ 5.44811401e+01],\n",
       "       [ 5.81091928e+00],\n",
       "       [ 5.81091928e+00],\n",
       "       [ 2.02522125e+01],\n",
       "       [ 4.01179390e+01],\n",
       "       [ 9.19031906e+01],\n",
       "       [ 1.10883835e+02],\n",
       "       [ 1.09585388e+02],\n",
       "       [ 1.10257248e+02],\n",
       "       [ 7.45987625e+01],\n",
       "       [ 3.87588844e+01],\n",
       "       [ 6.75089417e+01],\n",
       "       [ 9.33659668e+01],\n",
       "       [ 1.41787233e+01],\n",
       "       [ 2.15413113e+01],\n",
       "       [ 4.34003410e+01],\n",
       "       [ 5.00953331e+01],\n",
       "       [ 4.52281113e+01],\n",
       "       [ 4.08888054e+01],\n",
       "       [ 6.50769806e+01],\n",
       "       [ 2.89199066e+01],\n",
       "       [ 1.91784916e+01],\n",
       "       [ 5.76483536e+01],\n",
       "       [ 3.30767593e+01],\n",
       "       [ 2.05418072e+01],\n",
       "       [ 3.05939846e+01],\n",
       "       [ 6.20742989e+01],\n",
       "       [ 4.61954308e+01],\n",
       "       [ 4.40269928e+01],\n",
       "       [ 3.31854706e+01],\n",
       "       [ 4.07155991e+01],\n",
       "       [ 5.06980553e+01],\n",
       "       [ 6.85861359e+01],\n",
       "       [ 2.98795376e+01],\n",
       "       [ 4.20018959e+01],\n",
       "       [ 5.24064865e+01],\n",
       "       [ 3.91094933e+01],\n",
       "       [ 2.75555916e+01],\n",
       "       [ 3.39392395e+01],\n",
       "       [ 4.93278503e+01],\n",
       "       [ 1.90231667e+01],\n",
       "       [ 1.87876186e+01],\n",
       "       [ 1.99916210e+01],\n",
       "       [ 3.67510300e+01],\n",
       "       [ 2.47643204e+01],\n",
       "       [ 1.85215397e+01],\n",
       "       [ 1.93051052e+01],\n",
       "       [ 1.64974766e+01],\n",
       "       [ 1.64974766e+01],\n",
       "       [ 8.06699848e+00],\n",
       "       [ 3.14054394e+01],\n",
       "       [ 1.92922096e+01],\n",
       "       [ 3.53484268e+01],\n",
       "       [ 3.18757153e+01],\n",
       "       [ 4.02905045e+01],\n",
       "       [ 5.05863457e+01],\n",
       "       [ 4.02572517e+01],\n",
       "       [ 2.16835728e+01],\n",
       "       [ 5.44601593e+01],\n",
       "       [ 2.65020123e+01],\n",
       "       [ 3.61735878e+01],\n",
       "       [ 2.30450554e+01],\n",
       "       [ 1.36297188e+01],\n",
       "       [ 6.29814720e+00],\n",
       "       [ 3.75100098e+01],\n",
       "       [ 2.39649792e+01],\n",
       "       [ 3.45996742e+01],\n",
       "       [ 1.79208317e+01],\n",
       "       [ 2.11495590e+01],\n",
       "       [ 3.21744194e+01],\n",
       "       [ 2.72276440e+01],\n",
       "       [ 1.21573858e+01],\n",
       "       [ 1.38121014e+01],\n",
       "       [ 1.87748260e+01],\n",
       "       [-6.04846440e-02],\n",
       "       [ 6.93176460e+00],\n",
       "       [ 2.73568096e+01],\n",
       "       [ 2.39518890e+01],\n",
       "       [ 6.51763082e-01],\n",
       "       [ 3.15818863e+01],\n",
       "       [ 2.56043758e+01],\n",
       "       [ 3.71967354e+01],\n",
       "       [ 5.11526070e+01],\n",
       "       [ 9.84768581e+00],\n",
       "       [ 9.51204300e+00],\n",
       "       [ 5.11790276e+01],\n",
       "       [ 3.72296333e+01],\n",
       "       [ 5.22270203e+00],\n",
       "       [ 2.34586678e+01],\n",
       "       [ 2.64013615e+01],\n",
       "       [ 6.46732330e+01],\n",
       "       [ 2.60638027e+01],\n",
       "       [ 4.45419655e+01],\n",
       "       [ 3.12686672e+01],\n",
       "       [ 2.60057526e+01],\n",
       "       [ 3.58256989e+01],\n",
       "       [ 4.83514748e+01],\n",
       "       [ 3.85152054e+01],\n",
       "       [ 3.28513794e+01],\n",
       "       [ 4.45546684e+01],\n",
       "       [ 4.63559113e+01],\n",
       "       [ 2.71051426e+01],\n",
       "       [ 2.79930191e+01],\n",
       "       [ 2.88357582e+01],\n",
       "       [ 3.00373287e+01],\n",
       "       [ 2.93721142e+01],\n",
       "       [ 1.09745045e+01],\n",
       "       [ 3.41418953e+01],\n",
       "       [ 3.54095497e+01],\n",
       "       [ 8.47283020e+01],\n",
       "       [ 4.03324661e+01],\n",
       "       [ 5.01552315e+01],\n",
       "       [ 5.46248817e+01],\n",
       "       [ 5.46248817e+01],\n",
       "       [ 3.32629395e+01],\n",
       "       [ 6.49443741e+01],\n",
       "       [ 2.30503960e+01],\n",
       "       [ 4.86185913e+01],\n",
       "       [ 6.47127991e+01],\n",
       "       [ 2.11552677e+01],\n",
       "       [ 5.67898293e+01],\n",
       "       [ 4.20425110e+01],\n",
       "       [ 3.68279686e+01],\n",
       "       [ 6.39329338e+01],\n",
       "       [ 1.73202229e+01],\n",
       "       [ 2.45803890e+01],\n",
       "       [ 4.44704552e+01],\n",
       "       [ 1.07916889e+01],\n",
       "       [ 4.16300621e+01],\n",
       "       [ 1.06704731e+01],\n",
       "       [ 3.60666275e+01],\n",
       "       [ 4.02496758e+01],\n",
       "       [ 4.76782837e+01],\n",
       "       [ 1.68811665e+01],\n",
       "       [ 2.48563538e+01],\n",
       "       [ 3.45952911e+01],\n",
       "       [ 2.76304855e+01],\n",
       "       [ 1.64011364e+01],\n",
       "       [ 1.48477478e+01],\n",
       "       [ 5.62411728e+01],\n",
       "       [ 2.17612686e+01],\n",
       "       [ 2.26462555e+01],\n",
       "       [ 2.08946114e+01],\n",
       "       [ 3.27647057e+01],\n",
       "       [ 2.24656124e+01],\n",
       "       [ 1.36867123e+01],\n",
       "       [ 3.24097366e+01],\n",
       "       [ 2.46347351e+01],\n",
       "       [ 3.11690693e+01],\n",
       "       [ 4.71953621e+01],\n",
       "       [ 4.02870712e+01],\n",
       "       [ 4.20622520e+01],\n",
       "       [ 3.69751129e+01],\n",
       "       [ 1.64974766e+01],\n",
       "       [ 1.93941383e+01],\n",
       "       [ 7.39157791e+01],\n",
       "       [ 1.50185928e+01],\n",
       "       [ 3.35195312e+01],\n",
       "       [ 9.51204300e+00],\n",
       "       [ 1.87277374e+01],\n",
       "       [ 7.78342361e+01],\n",
       "       [ 2.99022999e+01],\n",
       "       [ 2.73450489e+01],\n",
       "       [ 3.23782806e+01],\n",
       "       [ 2.05860405e+01],\n",
       "       [ 2.42855721e+01],\n",
       "       [ 5.54481316e+01],\n",
       "       [ 2.16381493e+01],\n",
       "       [ 2.75928879e+01],\n",
       "       [ 3.51502838e+01],\n",
       "       [ 2.27730083e+01],\n",
       "       [ 3.91546364e+01],\n",
       "       [ 3.96264839e+01],\n",
       "       [ 4.41791191e+01],\n",
       "       [ 3.36592903e+01],\n",
       "       [ 3.27301826e+01],\n",
       "       [ 2.77854996e+01],\n",
       "       [ 2.79243259e+01],\n",
       "       [ 5.90360985e+01],\n",
       "       [ 4.20245247e+01],\n",
       "       [ 3.69723320e+01],\n",
       "       [ 2.03898029e+01],\n",
       "       [ 3.58579407e+01],\n",
       "       [ 1.82830944e+01],\n",
       "       [ 5.07004213e+00],\n",
       "       [ 1.96504936e+01],\n",
       "       [ 3.62792015e+01],\n",
       "       [ 2.01424351e+01],\n",
       "       [ 1.94247303e+01],\n",
       "       [ 2.81054935e+01],\n",
       "       [ 1.32360878e+01],\n",
       "       [ 1.32360878e+01],\n",
       "       [ 3.56065750e+01],\n",
       "       [ 3.51154404e+01],\n",
       "       [ 2.31124878e+01],\n",
       "       [ 1.50638447e+01],\n",
       "       [ 4.78930359e+01],\n",
       "       [ 3.97032738e+01],\n",
       "       [ 4.69768047e+00],\n",
       "       [ 7.17577133e+01],\n",
       "       [ 5.86894684e+01],\n",
       "       [ 8.57704544e+00],\n",
       "       [ 3.53484268e+01],\n",
       "       [ 7.39157791e+01],\n",
       "       [ 5.83926506e+01],\n",
       "       [ 7.10819473e+01],\n",
       "       [ 4.67674942e+01],\n",
       "       [ 4.09052582e+01],\n",
       "       [ 4.60434380e+01],\n",
       "       [ 2.20010681e+01],\n",
       "       [ 1.40043840e+01],\n",
       "       [ 3.87151566e+01],\n",
       "       [ 2.53798447e+01],\n",
       "       [ 2.09373932e+01],\n",
       "       [ 2.78546638e+01],\n",
       "       [ 4.85237274e+01],\n",
       "       [ 7.03855286e+01],\n",
       "       [ 7.06868134e+01],\n",
       "       [ 4.93181267e+01],\n",
       "       [ 6.04075699e+01],\n",
       "       [ 6.26861095e+00],\n",
       "       [ 4.28107452e+01],\n",
       "       [ 5.53996964e+01],\n",
       "       [ 2.69936275e+01],\n",
       "       [ 6.98504562e+01],\n",
       "       [ 2.23105850e+01],\n",
       "       [ 2.19120770e+01],\n",
       "       [ 2.52889004e+01],\n",
       "       [ 4.65668945e+01],\n",
       "       [ 3.08518028e+01],\n",
       "       [ 2.55246849e+01],\n",
       "       [ 3.18490810e+01],\n",
       "       [ 5.16744003e+01],\n",
       "       [ 4.33044701e+01],\n",
       "       [ 4.57414932e+01],\n",
       "       [ 1.74996700e+01],\n",
       "       [ 3.36856766e+01],\n",
       "       [ 5.71906853e+01],\n",
       "       [ 8.12605057e+01],\n",
       "       [ 2.12906952e+01],\n",
       "       [ 3.48304672e+01],\n",
       "       [ 3.74208908e+01],\n",
       "       [ 5.55684738e+01],\n",
       "       [ 2.84819450e+01],\n",
       "       [ 3.80304527e+01],\n",
       "       [ 6.06080551e+01],\n",
       "       [ 3.34765091e+01],\n",
       "       [ 8.89495850e+01],\n",
       "       [ 6.03284912e+01],\n",
       "       [ 4.20944939e+01],\n",
       "       [ 5.86894684e+01],\n",
       "       [ 5.86894684e+01],\n",
       "       [ 3.22754326e+01],\n",
       "       [ 3.95761566e+01],\n",
       "       [ 3.92122307e+01],\n",
       "       [ 5.37201309e+01],\n",
       "       [ 3.68494415e+01],\n",
       "       [ 6.81680145e+01],\n",
       "       [ 1.74848576e+01],\n",
       "       [ 7.93099821e-01],\n",
       "       [ 2.35146656e+01],\n",
       "       [ 4.08020897e+01],\n",
       "       [ 8.15223618e+01],\n",
       "       [ 2.62280521e+01],\n",
       "       [ 6.90314560e+01],\n",
       "       [ 5.96269302e+01],\n",
       "       [ 2.53760357e+01],\n",
       "       [ 4.39713364e+01],\n",
       "       [ 3.50839920e+01],\n",
       "       [ 2.92295666e+01],\n",
       "       [ 7.92867813e+01],\n",
       "       [ 4.34741249e+01],\n",
       "       [ 5.11790276e+01],\n",
       "       [ 9.90773582e+00],\n",
       "       [ 4.00918579e+01],\n",
       "       [ 3.94169617e+01],\n",
       "       [ 2.22831554e+01],\n",
       "       [ 3.05192337e+01],\n",
       "       [ 5.17478371e+01],\n",
       "       [ 2.65577946e+01],\n",
       "       [ 5.79486122e+01],\n",
       "       [ 4.89716263e+01],\n",
       "       [ 1.92158489e+01],\n",
       "       [ 2.06220989e+01],\n",
       "       [ 1.78992596e+01],\n",
       "       [ 6.29814720e+00],\n",
       "       [ 4.78850136e+01],\n",
       "       [ 4.32556496e+01],\n",
       "       [ 2.37246037e+01],\n",
       "       [ 5.70627441e+01],\n",
       "       [ 2.15705128e+01],\n",
       "       [ 2.58401413e+01],\n",
       "       [ 2.37765312e+01],\n",
       "       [ 3.83279190e+01],\n",
       "       [ 4.82938919e+01],\n",
       "       [ 8.11105919e+00],\n",
       "       [ 3.71530228e+01],\n",
       "       [ 4.91970139e+01],\n",
       "       [ 4.99140015e+01],\n",
       "       [ 3.50322952e+01],\n",
       "       [ 5.43886528e+01]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T13:57:59.788588Z",
     "start_time": "2024-08-08T13:57:59.782748Z"
    }
   },
   "cell_type": "code",
   "source": "activity_trained = pd.read_csv('data/tox24_challenge_train.csv')['activity']",
   "id": "5f80642144e06767",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.366863\n",
       "1      0.685050\n",
       "2      0.515402\n",
       "3      0.425256\n",
       "4      0.622651\n",
       "         ...   \n",
       "495    0.526285\n",
       "496    0.603440\n",
       "497    0.608033\n",
       "498    0.512699\n",
       "499    0.636699\n",
       "Name: predicted, Length: 500, dtype: float32"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T14:02:39.908472Z",
     "start_time": "2024-08-08T14:02:39.792826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(activity_trained, bins=100, alpha=0.5, color='r', label='train')\n",
    "plt.hist(activity_predicted_rescaled, bins=50, alpha=0.5, color='b', label='predict')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Distribution of target values')\n",
    "plt.xlabel('Mean % activity')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ],
   "id": "6699b94f5e24876e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Save for submission",
   "id": "234e267b0172dbd9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-08T14:01:31.411151Z",
     "start_time": "2024-08-08T14:01:31.407321Z"
    }
   },
   "cell_type": "code",
   "source": "pd.DataFrame(activity_predicted_rescaled, columns=[\"prediction\"]).to_csv(f'{base_out_dir}/tox24_challenge_test_predicted.csv')",
   "id": "e3ace5aab0824a38",
   "outputs": [],
   "execution_count": 40
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
