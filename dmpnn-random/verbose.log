Command line
python /home/shanavas/PycharmProjects/deepFPlearn/dfpl/__main__.py traingnn -f /home/shanavas/PycharmProjects/deepFPlearn/example/traingnn.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': 'tests/data/S_dataset.csv',
 'data_weights_path': None,
 'dataset_type': 'classification',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'dynamic_depth': None,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 2,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': ['balanced_accuracy',
                   'auc',
                   'f1',
                   'mcc',
                   'recall',
                   'specificity',
                   'precision'],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 256,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 256,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'binary_cross_entropy',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'accuracy',
 'metrics': ['accuracy',
             'balanced_accuracy',
             'auc',
             'f1',
             'mcc',
             'recall',
             'specificity',
             'precision'],
 'minimize_score': False,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 2,
 'num_lrs': 1,
 'num_tasks': 7,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'dmpnn-random/',
 'save_preds': True,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['AR', 'ER', 'GR', 'Aromatase', 'TR', 'PPARg', 'ED'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'wabTracking': '',
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Number of tasks = 7
Fold 0
Splitting data with seed 0
Class sizes
AR 0: 82.11%, 1: 17.89%
ER 0: 76.06%, 1: 23.94%
GR 0: 90.07%, 1: 9.93%
Aromatase 0: 88.67%, 1: 11.33%
TR 0: 93.06%, 1: 6.94%
PPARg 0: 89.44%, 1: 10.56%
ED 0: 69.43%, 1: 30.57%
Total size = 7,248 | train size = 5,798 | val size = 725 | test size = 725
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=256, bias=False)
        (W_h): Linear(in_features=256, out_features=256, bias=False)
        (W_o): Linear(in_features=389, out_features=256, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=256, out_features=256, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=256, out_features=7, bias=True)
  )
)
Number of parameters = 270,855
Epoch 0
Loss = 6.4909e-01, PNorm = 31.9933, GNorm = 0.8125, lr_0 = 1.4304e-04
Loss = 5.3888e-01, PNorm = 32.0019, GNorm = 0.3192, lr_0 = 1.8217e-04
Loss = 4.4220e-01, PNorm = 32.0134, GNorm = 0.2726, lr_0 = 2.2130e-04
Loss = 4.7649e-01, PNorm = 32.0175, GNorm = 0.3259, lr_0 = 2.6043e-04
Loss = 4.2296e-01, PNorm = 32.0235, GNorm = 0.3356, lr_0 = 2.9957e-04
Loss = 4.3571e-01, PNorm = 32.0346, GNorm = 0.2325, lr_0 = 3.3870e-04
Loss = 4.1731e-01, PNorm = 32.0477, GNorm = 0.3255, lr_0 = 3.7783e-04
Loss = 4.0172e-01, PNorm = 32.0674, GNorm = 0.1901, lr_0 = 4.1696e-04
Loss = 3.7821e-01, PNorm = 32.0908, GNorm = 0.2900, lr_0 = 4.5609e-04
Loss = 3.7955e-01, PNorm = 32.1048, GNorm = 0.3238, lr_0 = 4.9522e-04
Loss = 3.9392e-01, PNorm = 32.1263, GNorm = 0.2289, lr_0 = 5.3435e-04
Validation true_positives = 5.142857
Validation false_positives = 4.571429
Validation true_negatives = 488.571429
Validation false_negatives = 95.571429
Validation accuracy = 0.836093
Validation balanced_accuracy = 0.510009
Validation auc = 0.704815
Validation f1 = 0.051038
Validation mcc = 0.047855
Validation recall = 0.029479
Validation specificity = 0.990540
Validation precision = 0.220497
Training true_positives = 41.857143
Training false_positives = 30.857143
Training true_negatives = 3969.285714
Training false_negatives = 736.714286
Training accuracy = 0.844329
Training balanced_accuracy = 0.511130
Training auc = 0.730097
Training f1 = 0.052552
Training mcc = 0.054382
Training recall = 0.030187
Training specificity = 0.992073
Training precision = 0.238661
Epoch 1
Loss = 3.6431e-01, PNorm = 32.1445, GNorm = 0.3079, lr_0 = 5.7739e-04
Loss = 4.0649e-01, PNorm = 32.1536, GNorm = 0.3061, lr_0 = 6.1652e-04
Loss = 3.9108e-01, PNorm = 32.1794, GNorm = 0.5255, lr_0 = 6.5565e-04
Loss = 3.5874e-01, PNorm = 32.2050, GNorm = 0.1812, lr_0 = 6.9478e-04
Loss = 3.8692e-01, PNorm = 32.2210, GNorm = 0.3115, lr_0 = 7.3391e-04
Loss = 4.0061e-01, PNorm = 32.2424, GNorm = 0.7246, lr_0 = 7.7304e-04
Loss = 3.7100e-01, PNorm = 32.2675, GNorm = 0.2595, lr_0 = 8.1217e-04
Loss = 3.6572e-01, PNorm = 32.2981, GNorm = 0.4630, lr_0 = 8.5130e-04
Loss = 3.6699e-01, PNorm = 32.3345, GNorm = 0.4971, lr_0 = 8.9043e-04
Loss = 3.4394e-01, PNorm = 32.3594, GNorm = 0.2386, lr_0 = 9.2957e-04
Loss = 3.7762e-01, PNorm = 32.3891, GNorm = 0.8502, lr_0 = 9.6870e-04
Loss = 3.4830e-01, PNorm = 32.4127, GNorm = 0.4493, lr_0 = 1.0000e-04
Validation true_positives = 14.428571
Validation false_positives = 8.000000
Validation true_negatives = 485.142857
Validation false_negatives = 86.285714
Validation accuracy = 0.845552
Validation balanced_accuracy = 0.532516
Validation auc = 0.762635
Validation f1 = 0.118524
Validation mcc = 0.104205
Validation recall = 0.081907
Validation specificity = 0.983125
Validation precision = 0.283454
Training true_positives = 111.571429
Training false_positives = 57.714286
Training true_negatives = 3942.428571
Training false_negatives = 667.000000
Training accuracy = 0.852701
Training balanced_accuracy = 0.532864
Training auc = 0.784754
Training f1 = 0.120594
Training mcc = 0.118359
Training recall = 0.080704
Training specificity = 0.985024
Training precision = 0.389090
Model 0 best validation accuracy = 0.845552 on epoch 1
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test true_positives = 14.714286
Model 0 test false_positives = 9.571429
Model 0 test true_negatives = 487.714286
Model 0 test false_negatives = 86.000000
Model 0 test accuracy = 0.845786
Model 0 test balanced_accuracy = 0.530612
Model 0 test auc = 0.757105
Model 0 test f1 = 0.120522
Model 0 test mcc = 0.097442
Model 0 test recall = 0.081186
Model 0 test specificity = 0.980038
Model 0 test precision = 0.284581
Ensemble test true_positives = 14.714286
Ensemble test false_positives = 9.571429
Ensemble test true_negatives = 487.714286
Ensemble test false_negatives = 86.000000
Ensemble test accuracy = 0.845786
Ensemble test balanced_accuracy = 0.530612
Ensemble test auc = 0.757105
Ensemble test f1 = 0.120522
Ensemble test mcc = 0.097442
Ensemble test recall = 0.081186
Ensemble test specificity = 0.980038
Ensemble test precision = 0.284581
Fold 1
Splitting data with seed 1
Class sizes
AR 0: 82.11%, 1: 17.89%
ER 0: 76.06%, 1: 23.94%
GR 0: 90.07%, 1: 9.93%
Aromatase 0: 88.67%, 1: 11.33%
TR 0: 93.06%, 1: 6.94%
PPARg 0: 89.44%, 1: 10.56%
ED 0: 69.43%, 1: 30.57%
Total size = 7,248 | train size = 5,798 | val size = 725 | test size = 725
Building model 0
MoleculeModel(
  (sigmoid): Sigmoid()
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=256, bias=False)
        (W_h): Linear(in_features=256, out_features=256, bias=False)
        (W_o): Linear(in_features=389, out_features=256, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=256, out_features=256, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=256, out_features=7, bias=True)
  )
)
Number of parameters = 270,855
Epoch 0
Loss = 6.5238e-01, PNorm = 31.9932, GNorm = 0.5828, lr_0 = 1.4304e-04
Loss = 5.1844e-01, PNorm = 32.0023, GNorm = 0.3026, lr_0 = 1.8217e-04
Loss = 4.7280e-01, PNorm = 32.0121, GNorm = 0.4167, lr_0 = 2.2130e-04
Loss = 4.5024e-01, PNorm = 32.0169, GNorm = 0.4412, lr_0 = 2.6043e-04
Loss = 4.2502e-01, PNorm = 32.0231, GNorm = 0.2842, lr_0 = 2.9957e-04
Loss = 4.3620e-01, PNorm = 32.0366, GNorm = 0.5807, lr_0 = 3.3870e-04
Loss = 3.7975e-01, PNorm = 32.0564, GNorm = 0.6790, lr_0 = 3.7783e-04
Loss = 4.2488e-01, PNorm = 32.0706, GNorm = 0.2602, lr_0 = 4.1696e-04
Loss = 4.1342e-01, PNorm = 32.0916, GNorm = 1.0656, lr_0 = 4.5609e-04
Loss = 3.7398e-01, PNorm = 32.1094, GNorm = 0.2959, lr_0 = 4.9522e-04
Loss = 3.9363e-01, PNorm = 32.1204, GNorm = 0.5924, lr_0 = 5.3435e-04
Command line
python /home/shanavas/PycharmProjects/deepFPlearn/dfpl/__main__.py traingnn -f /home/shanavas/PycharmProjects/deepFPlearn/example/traingnn.json
Args
{'activation': 'ReLU',
 'adding_bond_types': True,
 'adding_h': False,
 'aggregation': 'mean',
 'aggregation_norm': 100,
 'atom_constraints': [],
 'atom_descriptor_scaling': True,
 'atom_descriptors': None,
 'atom_descriptors_path': None,
 'atom_descriptors_size': 0,
 'atom_features_size': 0,
 'atom_messages': False,
 'atom_targets': [],
 'batch_size': 50,
 'bias': False,
 'bias_solvent': False,
 'bond_constraints': [],
 'bond_descriptor_scaling': True,
 'bond_descriptors': None,
 'bond_descriptors_path': None,
 'bond_descriptors_size': 0,
 'bond_features_size': 0,
 'bond_targets': [],
 'cache_cutoff': 10000,
 'checkpoint_dir': None,
 'checkpoint_frzn': None,
 'checkpoint_path': None,
 'checkpoint_paths': None,
 'class_balance': False,
 'config_path': None,
 'constraints_path': None,
 'crossval_index_dir': None,
 'crossval_index_file': None,
 'crossval_index_sets': None,
 'cuda': False,
 'data_path': 'example/data/modified_zscore_dilshana-ar.csv',
 'data_weights_path': None,
 'dataset_type': 'regression',
 'depth': 3,
 'depth_solvent': 3,
 'device': device(type='cpu'),
 'dropout': 0.0,
 'dynamic_depth': None,
 'empty_cache': False,
 'ensemble_size': 1,
 'epochs': 2,
 'evidential_regularization': 0,
 'explicit_h': False,
 'extra_metrics': [],
 'features_generator': None,
 'features_only': False,
 'features_path': None,
 'features_scaling': True,
 'features_size': None,
 'ffn_hidden_size': 256,
 'ffn_num_layers': 2,
 'final_lr': 0.0001,
 'folds_file': None,
 'freeze_first_only': False,
 'frzn_ffn_layers': 0,
 'gpu': None,
 'grad_clip': None,
 'hidden_size': 256,
 'hidden_size_solvent': 300,
 'ignore_columns': None,
 'init_lr': 0.0001,
 'is_atom_bond_targets': False,
 'keeping_atom_map': False,
 'log_frequency': 10,
 'loss_function': 'mse',
 'max_data_size': None,
 'max_lr': 0.001,
 'metric': 'rmse',
 'metrics': ['rmse'],
 'minimize_score': True,
 'mpn_shared': False,
 'multiclass_num_classes': 3,
 'no_adding_bond_types': False,
 'no_atom_descriptor_scaling': False,
 'no_bond_descriptor_scaling': False,
 'no_cache_mol': False,
 'no_cuda': False,
 'no_features_scaling': False,
 'no_shared_atom_bond_ffn': False,
 'num_folds': 2,
 'num_lrs': 1,
 'num_tasks': 1,
 'num_workers': 8,
 'number_of_molecules': 1,
 'overwrite_default_atom_features': False,
 'overwrite_default_bond_features': False,
 'phase_features_path': None,
 'pytorch_seed': 0,
 'quiet': False,
 'reaction': False,
 'reaction_mode': 'reac_diff',
 'reaction_solvent': False,
 'resume_experiment': False,
 'save_dir': 'dmpnn-random/',
 'save_preds': True,
 'save_smiles_splits': False,
 'seed': 0,
 'separate_test_atom_descriptors_path': None,
 'separate_test_bond_descriptors_path': None,
 'separate_test_constraints_path': None,
 'separate_test_features_path': None,
 'separate_test_path': None,
 'separate_test_phase_features_path': None,
 'separate_val_atom_descriptors_path': None,
 'separate_val_bond_descriptors_path': None,
 'separate_val_constraints_path': None,
 'separate_val_features_path': None,
 'separate_val_path': None,
 'separate_val_phase_features_path': None,
 'shared_atom_bond_ffn': True,
 'show_individual_scores': False,
 'smiles_columns': ['smiles'],
 'spectra_activation': 'exp',
 'spectra_phase_mask_path': None,
 'spectra_target_floor': 1e-08,
 'split_key_molecule': 0,
 'split_sizes': [0.8, 0.1, 0.1],
 'split_type': 'random',
 'target_columns': None,
 'target_weights': None,
 'task_names': ['AR'],
 'test': False,
 'test_fold_index': None,
 'train_data_size': None,
 'undirected': False,
 'use_input_features': False,
 'val_fold_index': None,
 'wabTracking': '',
 'warmup_epochs': 2.0,
 'weights_ffn_num_layers': 2}
Setting molecule featurization parameters to default.
Loading data
Warning: 11 SMILES are invalid.
Number of tasks = 1
Fold 0
Splitting data with seed 0
Total size = 4,128 | train size = 3,302 | val size = 413 | test size = 413
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=256, bias=False)
        (W_h): Linear(in_features=256, out_features=256, bias=False)
        (W_o): Linear(in_features=389, out_features=256, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=256, out_features=256, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=256, out_features=1, bias=True)
  )
)
Number of parameters = 269,313
Epoch 0
Loss = 9.5155e-01, PNorm = 31.8272, GNorm = 3.8902, lr_0 = 1.7500e-04
Loss = 9.7685e-01, PNorm = 31.8289, GNorm = 1.0580, lr_0 = 2.4318e-04
Loss = 1.0261e+00, PNorm = 31.8311, GNorm = 2.0214, lr_0 = 3.1136e-04
Loss = 7.9818e-01, PNorm = 31.8341, GNorm = 5.0965, lr_0 = 3.7955e-04
Loss = 1.0083e+00, PNorm = 31.8367, GNorm = 2.9935, lr_0 = 4.4773e-04
Loss = 1.0499e+00, PNorm = 31.8450, GNorm = 0.9827, lr_0 = 5.1591e-04
Validation true_positives = 0.000000
Validation false_positives = 0.000000
Validation true_negatives = 0.000000
Validation false_negatives = 0.000000
Validation rmse = 29.979773
Training true_positives = 0.000000
Training false_positives = 0.000000
Training true_negatives = 0.000000
Training false_negatives = 0.000000
Training rmse = 41.454534
Epoch 1
Loss = 8.8135e-01, PNorm = 31.8560, GNorm = 5.1399, lr_0 = 5.9091e-04
Loss = 8.5886e-01, PNorm = 31.8651, GNorm = 0.7600, lr_0 = 6.5909e-04
Loss = 8.9317e-01, PNorm = 31.8788, GNorm = 2.3715, lr_0 = 7.2727e-04
Loss = 9.9609e-01, PNorm = 31.8930, GNorm = 0.8604, lr_0 = 7.9545e-04
Loss = 1.0367e+00, PNorm = 31.9151, GNorm = 1.6338, lr_0 = 8.6364e-04
Loss = 8.9827e-01, PNorm = 31.9351, GNorm = 1.8426, lr_0 = 9.3182e-04
Loss = 9.4957e-01, PNorm = 31.9563, GNorm = 1.7118, lr_0 = 1.0000e-03
Validation true_positives = 0.000000
Validation false_positives = 0.000000
Validation true_negatives = 0.000000
Validation false_negatives = 0.000000
Validation rmse = 29.867419
Training true_positives = 0.000000
Training false_positives = 0.000000
Training true_negatives = 0.000000
Training false_negatives = 0.000000
Training rmse = 35.805787
Model 0 best validation rmse = 29.867419 on epoch 1
Loading pretrained parameter "encoder.encoder.0.cached_zero_vector".
Loading pretrained parameter "encoder.encoder.0.W_i.weight".
Loading pretrained parameter "encoder.encoder.0.W_h.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.weight".
Loading pretrained parameter "encoder.encoder.0.W_o.bias".
Loading pretrained parameter "readout.1.weight".
Loading pretrained parameter "readout.1.bias".
Loading pretrained parameter "readout.4.weight".
Loading pretrained parameter "readout.4.bias".
Model 0 test true_positives = 0.000000
Model 0 test false_positives = 0.000000
Model 0 test true_negatives = 0.000000
Model 0 test false_negatives = 0.000000
Model 0 test rmse = 30.719911
Ensemble test true_positives = 0.000000
Ensemble test false_positives = 0.000000
Ensemble test true_negatives = 0.000000
Ensemble test false_negatives = 0.000000
Ensemble test rmse = 30.719911
Fold 1
Splitting data with seed 1
Total size = 4,128 | train size = 3,302 | val size = 413 | test size = 413
Fitting scaler
Building model 0
MoleculeModel(
  (encoder): MPN(
    (encoder): ModuleList(
      (0): MPNEncoder(
        (dropout): Dropout(p=0.0, inplace=False)
        (act_func): ReLU()
        (W_i): Linear(in_features=147, out_features=256, bias=False)
        (W_h): Linear(in_features=256, out_features=256, bias=False)
        (W_o): Linear(in_features=389, out_features=256, bias=True)
      )
    )
  )
  (readout): Sequential(
    (0): Dropout(p=0.0, inplace=False)
    (1): Linear(in_features=256, out_features=256, bias=True)
    (2): ReLU()
    (3): Dropout(p=0.0, inplace=False)
    (4): Linear(in_features=256, out_features=1, bias=True)
  )
)
Number of parameters = 269,313
Epoch 0
Loss = 1.0668e+00, PNorm = 31.8264, GNorm = 1.9013, lr_0 = 1.7500e-04
Loss = 9.2229e-01, PNorm = 31.8282, GNorm = 1.1568, lr_0 = 2.4318e-04
Loss = 9.5942e-01, PNorm = 31.8309, GNorm = 1.8999, lr_0 = 3.1136e-04
Loss = 1.0946e+00, PNorm = 31.8340, GNorm = 1.7033, lr_0 = 3.7955e-04
Loss = 8.8857e-01, PNorm = 31.8377, GNorm = 2.9700, lr_0 = 4.4773e-04
